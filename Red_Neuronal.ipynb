{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "3781fa31-be96-487b-bb2d-c07bf3ed08ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Se importan las librerías a utilizar en todo el proyecto\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "bfffb5c4-a7e5-4dc6-8dd8-8b9954fd698d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23058 entries, 0 to 23057\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sum_click          23058 non-null  float64\n",
      " 1   gender             23058 non-null  float64\n",
      " 2   region             23058 non-null  float64\n",
      " 3   highest_education  23058 non-null  float64\n",
      " 4   studied_credits    23058 non-null  float64\n",
      " 5   code_module        23058 non-null  int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Se carga el Dataframe preparado en la etapa de Análisis con información del estudiante\n",
    "\n",
    "students = pd.read_csv('res/students_balanced.csv', sep=';')\n",
    "del students['Unnamed: 0']\n",
    "\n",
    "students.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "dc23b686-fb47-4a46-9981-f2b38dac87cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  clases: [1 2 3 4 5 6 7]  ocurrencias:  [2661 2598 2651 2655 2655 2606 2620]\n",
      "Test:  clases: [1 2 3 4 5 6 7]  ocurrencias:  [633 696 643 639 639 688 674]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_click</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>studied_credits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>-1.023614</td>\n",
       "      <td>0.928989</td>\n",
       "      <td>1.113127</td>\n",
       "      <td>0.236378</td>\n",
       "      <td>1.549062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>1.901206</td>\n",
       "      <td>0.928989</td>\n",
       "      <td>1.621804</td>\n",
       "      <td>0.236378</td>\n",
       "      <td>-0.342115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>-1.007619</td>\n",
       "      <td>-1.076439</td>\n",
       "      <td>-0.412902</td>\n",
       "      <td>-1.162380</td>\n",
       "      <td>-0.342115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13868</th>\n",
       "      <td>0.379386</td>\n",
       "      <td>0.928989</td>\n",
       "      <td>1.113127</td>\n",
       "      <td>-1.162380</td>\n",
       "      <td>-1.287704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>0.436511</td>\n",
       "      <td>-1.076439</td>\n",
       "      <td>1.367466</td>\n",
       "      <td>-1.162380</td>\n",
       "      <td>-0.342115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sum_click    gender    region  highest_education  studied_credits\n",
       "2935   -1.023614  0.928989  1.113127           0.236378         1.549062\n",
       "7719    1.901206  0.928989  1.621804           0.236378        -0.342115\n",
       "5405   -1.007619 -1.076439 -0.412902          -1.162380        -0.342115\n",
       "13868   0.379386  0.928989  1.113127          -1.162380        -1.287704\n",
       "3948    0.436511 -1.076439  1.367466          -1.162380        -0.342115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18446, 5)\n"
     ]
    }
   ],
   "source": [
    "#Partición de datos externa\n",
    "\n",
    "X = students.copy()\n",
    "del X['code_module']\n",
    "y = students['code_module']\n",
    "\n",
    "X_training, X_test, y_training, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "valores_training, ocur_training = np.unique(y_training, return_counts=True)\n",
    "print('Training: ', 'clases:', valores_training, ' ocurrencias: ', ocur_training)\n",
    "valores_test, ocur_test = np.unique(y_test, return_counts=True)\n",
    "print('Test: ', 'clases:', valores_test, ' ocurrencias: ', ocur_test)\n",
    "display(X_training.head(5))\n",
    "print(X_training.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "24223082-8a9d-48fd-80ec-72b395daba97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serie original:\n",
      "2935     1\n",
      "7719     3\n",
      "5405     2\n",
      "13868    5\n",
      "3948     2\n",
      "        ..\n",
      "11964    4\n",
      "21575    7\n",
      "5390     2\n",
      "860      1\n",
      "15795    5\n",
      "Name: code_module, Length: 18446, dtype: int64\n",
      "\n",
      "One-hot encoding:\n",
      "           1      2      3      4      5      6      7\n",
      "2935    True  False  False  False  False  False  False\n",
      "7719   False  False   True  False  False  False  False\n",
      "5405   False   True  False  False  False  False  False\n",
      "13868  False  False  False  False   True  False  False\n",
      "3948   False   True  False  False  False  False  False\n",
      "...      ...    ...    ...    ...    ...    ...    ...\n",
      "11964  False  False  False   True  False  False  False\n",
      "21575  False  False  False  False  False  False   True\n",
      "5390   False   True  False  False  False  False  False\n",
      "860     True  False  False  False  False  False  False\n",
      "15795  False  False  False  False   True  False  False\n",
      "\n",
      "[18446 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convertir la serie a one-hot encoding\n",
    "y_test_oh = pd.get_dummies(y_test)\n",
    "y_training_oh = pd.get_dummies(y_training)\n",
    "\n",
    "# Imprimir la representación one-hot encoding resultante\n",
    "print(\"Serie original:\")\n",
    "print(y_training)\n",
    "print(\"\\nOne-hot encoding:\")\n",
    "print(y_training_oh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "6c22fb63-8385-4093-a747-05d88b76b89b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "577/577 [==============================] - 1s 987us/step - loss: 0.3354 - accuracy: 0.3962 - val_loss: 0.2966 - val_accuracy: 0.4792\n",
      "Epoch 2/500\n",
      "577/577 [==============================] - 0s 853us/step - loss: 0.3034 - accuracy: 0.4554 - val_loss: 0.2926 - val_accuracy: 0.4768\n",
      "Epoch 3/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2997 - accuracy: 0.4601 - val_loss: 0.2912 - val_accuracy: 0.4835\n",
      "Epoch 4/500\n",
      "577/577 [==============================] - 0s 851us/step - loss: 0.2977 - accuracy: 0.4648 - val_loss: 0.2901 - val_accuracy: 0.4846\n",
      "Epoch 5/500\n",
      "577/577 [==============================] - 0s 860us/step - loss: 0.2968 - accuracy: 0.4653 - val_loss: 0.2898 - val_accuracy: 0.4848\n",
      "Epoch 6/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2966 - accuracy: 0.4627 - val_loss: 0.2882 - val_accuracy: 0.4926\n",
      "Epoch 7/500\n",
      "577/577 [==============================] - 0s 864us/step - loss: 0.2956 - accuracy: 0.4659 - val_loss: 0.2893 - val_accuracy: 0.4853\n",
      "Epoch 8/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2944 - accuracy: 0.4676 - val_loss: 0.2883 - val_accuracy: 0.4863\n",
      "Epoch 9/500\n",
      "577/577 [==============================] - 1s 1ms/step - loss: 0.2946 - accuracy: 0.4718 - val_loss: 0.2883 - val_accuracy: 0.4859\n",
      "Epoch 10/500\n",
      "577/577 [==============================] - 1s 1ms/step - loss: 0.2942 - accuracy: 0.4690 - val_loss: 0.2887 - val_accuracy: 0.4816\n",
      "Epoch 11/500\n",
      "577/577 [==============================] - 1s 885us/step - loss: 0.2938 - accuracy: 0.4692 - val_loss: 0.2876 - val_accuracy: 0.4814\n",
      "Epoch 12/500\n",
      "577/577 [==============================] - 0s 847us/step - loss: 0.2930 - accuracy: 0.4685 - val_loss: 0.2867 - val_accuracy: 0.4831\n",
      "Epoch 13/500\n",
      "577/577 [==============================] - 1s 881us/step - loss: 0.2935 - accuracy: 0.4698 - val_loss: 0.2876 - val_accuracy: 0.4809\n",
      "Epoch 14/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2927 - accuracy: 0.4720 - val_loss: 0.2858 - val_accuracy: 0.4902\n",
      "Epoch 15/500\n",
      "577/577 [==============================] - 1s 882us/step - loss: 0.2918 - accuracy: 0.4708 - val_loss: 0.2867 - val_accuracy: 0.4915\n",
      "Epoch 16/500\n",
      "577/577 [==============================] - 0s 853us/step - loss: 0.2918 - accuracy: 0.4756 - val_loss: 0.2857 - val_accuracy: 0.4896\n",
      "Epoch 17/500\n",
      "577/577 [==============================] - 0s 846us/step - loss: 0.2915 - accuracy: 0.4747 - val_loss: 0.2854 - val_accuracy: 0.4898\n",
      "Epoch 18/500\n",
      "577/577 [==============================] - 0s 817us/step - loss: 0.2909 - accuracy: 0.4752 - val_loss: 0.2858 - val_accuracy: 0.4835\n",
      "Epoch 19/500\n",
      "577/577 [==============================] - 0s 854us/step - loss: 0.2904 - accuracy: 0.4737 - val_loss: 0.2854 - val_accuracy: 0.4807\n",
      "Epoch 20/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2909 - accuracy: 0.4745 - val_loss: 0.2854 - val_accuracy: 0.4879\n",
      "Epoch 21/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2906 - accuracy: 0.4767 - val_loss: 0.2851 - val_accuracy: 0.4883\n",
      "Epoch 22/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2908 - accuracy: 0.4737 - val_loss: 0.2845 - val_accuracy: 0.4926\n",
      "Epoch 23/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2901 - accuracy: 0.4752 - val_loss: 0.2839 - val_accuracy: 0.4872\n",
      "Epoch 24/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2897 - accuracy: 0.4755 - val_loss: 0.2849 - val_accuracy: 0.4818\n",
      "Epoch 25/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2890 - accuracy: 0.4774 - val_loss: 0.2862 - val_accuracy: 0.4857\n",
      "Epoch 26/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2890 - accuracy: 0.4798 - val_loss: 0.2851 - val_accuracy: 0.4872\n",
      "Epoch 27/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2895 - accuracy: 0.4789 - val_loss: 0.2844 - val_accuracy: 0.4926\n",
      "Epoch 28/500\n",
      "577/577 [==============================] - 0s 794us/step - loss: 0.2889 - accuracy: 0.4769 - val_loss: 0.2847 - val_accuracy: 0.4844\n",
      "Epoch 29/500\n",
      "577/577 [==============================] - 0s 813us/step - loss: 0.2889 - accuracy: 0.4784 - val_loss: 0.2842 - val_accuracy: 0.4902\n",
      "Epoch 30/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2885 - accuracy: 0.4778 - val_loss: 0.2846 - val_accuracy: 0.4881\n",
      "Epoch 31/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2880 - accuracy: 0.4844 - val_loss: 0.2853 - val_accuracy: 0.4855\n",
      "Epoch 32/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2885 - accuracy: 0.4793 - val_loss: 0.2836 - val_accuracy: 0.4920\n",
      "Epoch 33/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2885 - accuracy: 0.4774 - val_loss: 0.2835 - val_accuracy: 0.4909\n",
      "Epoch 34/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2885 - accuracy: 0.4787 - val_loss: 0.2850 - val_accuracy: 0.4894\n",
      "Epoch 35/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2880 - accuracy: 0.4797 - val_loss: 0.2834 - val_accuracy: 0.4950\n",
      "Epoch 36/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2880 - accuracy: 0.4807 - val_loss: 0.2846 - val_accuracy: 0.4879\n",
      "Epoch 37/500\n",
      "577/577 [==============================] - 0s 800us/step - loss: 0.2871 - accuracy: 0.4816 - val_loss: 0.2832 - val_accuracy: 0.4920\n",
      "Epoch 38/500\n",
      "577/577 [==============================] - 1s 886us/step - loss: 0.2872 - accuracy: 0.4836 - val_loss: 0.2832 - val_accuracy: 0.4954\n",
      "Epoch 39/500\n",
      "577/577 [==============================] - 0s 804us/step - loss: 0.2871 - accuracy: 0.4820 - val_loss: 0.2837 - val_accuracy: 0.4941\n",
      "Epoch 40/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2872 - accuracy: 0.4816 - val_loss: 0.2826 - val_accuracy: 0.4892\n",
      "Epoch 41/500\n",
      "577/577 [==============================] - 0s 801us/step - loss: 0.2867 - accuracy: 0.4841 - val_loss: 0.2844 - val_accuracy: 0.4889\n",
      "Epoch 42/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2872 - accuracy: 0.4814 - val_loss: 0.2818 - val_accuracy: 0.4928\n",
      "Epoch 43/500\n",
      "577/577 [==============================] - 1s 937us/step - loss: 0.2871 - accuracy: 0.4816 - val_loss: 0.2831 - val_accuracy: 0.4926\n",
      "Epoch 44/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2867 - accuracy: 0.4813 - val_loss: 0.2832 - val_accuracy: 0.4950\n",
      "Epoch 45/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2867 - accuracy: 0.4823 - val_loss: 0.2846 - val_accuracy: 0.4863\n",
      "Epoch 46/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2866 - accuracy: 0.4814 - val_loss: 0.2827 - val_accuracy: 0.4972\n",
      "Epoch 47/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2866 - accuracy: 0.4854 - val_loss: 0.2833 - val_accuracy: 0.4913\n",
      "Epoch 48/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2861 - accuracy: 0.4869 - val_loss: 0.2835 - val_accuracy: 0.4907\n",
      "Epoch 49/500\n",
      "577/577 [==============================] - 0s 803us/step - loss: 0.2859 - accuracy: 0.4838 - val_loss: 0.2831 - val_accuracy: 0.4976\n",
      "Epoch 50/500\n",
      "577/577 [==============================] - 0s 796us/step - loss: 0.2862 - accuracy: 0.4847 - val_loss: 0.2832 - val_accuracy: 0.4872\n",
      "Epoch 51/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2859 - accuracy: 0.4850 - val_loss: 0.2824 - val_accuracy: 0.4911\n",
      "Epoch 52/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2855 - accuracy: 0.4844 - val_loss: 0.2836 - val_accuracy: 0.4881\n",
      "Epoch 53/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2860 - accuracy: 0.4822 - val_loss: 0.2823 - val_accuracy: 0.4905\n",
      "Epoch 54/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2856 - accuracy: 0.4869 - val_loss: 0.2814 - val_accuracy: 0.4961\n",
      "Epoch 55/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2856 - accuracy: 0.4851 - val_loss: 0.2830 - val_accuracy: 0.4939\n",
      "Epoch 56/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2850 - accuracy: 0.4859 - val_loss: 0.2822 - val_accuracy: 0.4948\n",
      "Epoch 57/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2856 - accuracy: 0.4841 - val_loss: 0.2816 - val_accuracy: 0.4944\n",
      "Epoch 58/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2854 - accuracy: 0.4873 - val_loss: 0.2831 - val_accuracy: 0.4918\n",
      "Epoch 59/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2856 - accuracy: 0.4847 - val_loss: 0.2827 - val_accuracy: 0.4959\n",
      "Epoch 60/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2850 - accuracy: 0.4866 - val_loss: 0.2829 - val_accuracy: 0.4866\n",
      "Epoch 61/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2853 - accuracy: 0.4892 - val_loss: 0.2830 - val_accuracy: 0.4902\n",
      "Epoch 62/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2847 - accuracy: 0.4878 - val_loss: 0.2814 - val_accuracy: 0.4978\n",
      "Epoch 63/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2845 - accuracy: 0.4877 - val_loss: 0.2824 - val_accuracy: 0.4892\n",
      "Epoch 64/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2846 - accuracy: 0.4858 - val_loss: 0.2821 - val_accuracy: 0.4965\n",
      "Epoch 65/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2846 - accuracy: 0.4877 - val_loss: 0.2815 - val_accuracy: 0.4939\n",
      "Epoch 66/500\n",
      "577/577 [==============================] - 1s 961us/step - loss: 0.2844 - accuracy: 0.4894 - val_loss: 0.2817 - val_accuracy: 0.4941\n",
      "Epoch 67/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2843 - accuracy: 0.4899 - val_loss: 0.2806 - val_accuracy: 0.4972\n",
      "Epoch 68/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2843 - accuracy: 0.4862 - val_loss: 0.2817 - val_accuracy: 0.4967\n",
      "Epoch 69/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2847 - accuracy: 0.4893 - val_loss: 0.2814 - val_accuracy: 0.4950\n",
      "Epoch 70/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2847 - accuracy: 0.4888 - val_loss: 0.2823 - val_accuracy: 0.4952\n",
      "Epoch 71/500\n",
      "577/577 [==============================] - 1s 900us/step - loss: 0.2845 - accuracy: 0.4933 - val_loss: 0.2815 - val_accuracy: 0.4961\n",
      "Epoch 72/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2838 - accuracy: 0.4864 - val_loss: 0.2809 - val_accuracy: 0.4974\n",
      "Epoch 73/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2840 - accuracy: 0.4872 - val_loss: 0.2828 - val_accuracy: 0.4939\n",
      "Epoch 74/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2840 - accuracy: 0.4891 - val_loss: 0.2830 - val_accuracy: 0.4918\n",
      "Epoch 75/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2841 - accuracy: 0.4897 - val_loss: 0.2807 - val_accuracy: 0.5000\n",
      "Epoch 76/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2840 - accuracy: 0.4918 - val_loss: 0.2809 - val_accuracy: 0.4963\n",
      "Epoch 77/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2836 - accuracy: 0.4900 - val_loss: 0.2804 - val_accuracy: 0.4978\n",
      "Epoch 78/500\n",
      "577/577 [==============================] - 0s 813us/step - loss: 0.2836 - accuracy: 0.4888 - val_loss: 0.2819 - val_accuracy: 0.4987\n",
      "Epoch 79/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2838 - accuracy: 0.4908 - val_loss: 0.2810 - val_accuracy: 0.5063\n",
      "Epoch 80/500\n",
      "577/577 [==============================] - 0s 859us/step - loss: 0.2829 - accuracy: 0.4947 - val_loss: 0.2812 - val_accuracy: 0.5065\n",
      "Epoch 81/500\n",
      "577/577 [==============================] - 0s 839us/step - loss: 0.2839 - accuracy: 0.4886 - val_loss: 0.2807 - val_accuracy: 0.4970\n",
      "Epoch 82/500\n",
      "577/577 [==============================] - 0s 860us/step - loss: 0.2837 - accuracy: 0.4931 - val_loss: 0.2802 - val_accuracy: 0.5039\n",
      "Epoch 83/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2836 - accuracy: 0.4908 - val_loss: 0.2801 - val_accuracy: 0.5054\n",
      "Epoch 84/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2827 - accuracy: 0.4942 - val_loss: 0.2802 - val_accuracy: 0.5020\n",
      "Epoch 85/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2830 - accuracy: 0.4930 - val_loss: 0.2805 - val_accuracy: 0.5020\n",
      "Epoch 86/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2831 - accuracy: 0.4918 - val_loss: 0.2807 - val_accuracy: 0.5020\n",
      "Epoch 87/500\n",
      "577/577 [==============================] - 0s 813us/step - loss: 0.2833 - accuracy: 0.4919 - val_loss: 0.2806 - val_accuracy: 0.5015\n",
      "Epoch 88/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2837 - accuracy: 0.4887 - val_loss: 0.2801 - val_accuracy: 0.4952\n",
      "Epoch 89/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2829 - accuracy: 0.4931 - val_loss: 0.2806 - val_accuracy: 0.4983\n",
      "Epoch 90/500\n",
      "577/577 [==============================] - 1s 978us/step - loss: 0.2830 - accuracy: 0.4911 - val_loss: 0.2806 - val_accuracy: 0.5020\n",
      "Epoch 91/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2831 - accuracy: 0.4928 - val_loss: 0.2818 - val_accuracy: 0.4989\n",
      "Epoch 92/500\n",
      "577/577 [==============================] - 0s 821us/step - loss: 0.2831 - accuracy: 0.4917 - val_loss: 0.2812 - val_accuracy: 0.4954\n",
      "Epoch 93/500\n",
      "577/577 [==============================] - 0s 845us/step - loss: 0.2833 - accuracy: 0.4926 - val_loss: 0.2800 - val_accuracy: 0.5056\n",
      "Epoch 94/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2827 - accuracy: 0.4942 - val_loss: 0.2809 - val_accuracy: 0.4976\n",
      "Epoch 95/500\n",
      "577/577 [==============================] - 1s 891us/step - loss: 0.2827 - accuracy: 0.4946 - val_loss: 0.2810 - val_accuracy: 0.5009\n",
      "Epoch 96/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2826 - accuracy: 0.4944 - val_loss: 0.2803 - val_accuracy: 0.5050\n",
      "Epoch 97/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2830 - accuracy: 0.4894 - val_loss: 0.2799 - val_accuracy: 0.5022\n",
      "Epoch 98/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2825 - accuracy: 0.4909 - val_loss: 0.2803 - val_accuracy: 0.5043\n",
      "Epoch 99/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2824 - accuracy: 0.4958 - val_loss: 0.2806 - val_accuracy: 0.5000\n",
      "Epoch 100/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2823 - accuracy: 0.4928 - val_loss: 0.2806 - val_accuracy: 0.5009\n",
      "Epoch 101/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2830 - accuracy: 0.4913 - val_loss: 0.2810 - val_accuracy: 0.4983\n",
      "Epoch 102/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2826 - accuracy: 0.4940 - val_loss: 0.2806 - val_accuracy: 0.4967\n",
      "Epoch 103/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2826 - accuracy: 0.4928 - val_loss: 0.2805 - val_accuracy: 0.5039\n",
      "Epoch 104/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2825 - accuracy: 0.4917 - val_loss: 0.2805 - val_accuracy: 0.4978\n",
      "Epoch 105/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2823 - accuracy: 0.4940 - val_loss: 0.2797 - val_accuracy: 0.4998\n",
      "Epoch 106/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2824 - accuracy: 0.4935 - val_loss: 0.2810 - val_accuracy: 0.4991\n",
      "Epoch 107/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2824 - accuracy: 0.4964 - val_loss: 0.2801 - val_accuracy: 0.5050\n",
      "Epoch 108/500\n",
      "577/577 [==============================] - 0s 845us/step - loss: 0.2826 - accuracy: 0.4950 - val_loss: 0.2794 - val_accuracy: 0.5082\n",
      "Epoch 109/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2829 - accuracy: 0.4937 - val_loss: 0.2794 - val_accuracy: 0.5054\n",
      "Epoch 110/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2820 - accuracy: 0.4943 - val_loss: 0.2799 - val_accuracy: 0.5013\n",
      "Epoch 111/500\n",
      "577/577 [==============================] - 1s 961us/step - loss: 0.2817 - accuracy: 0.4963 - val_loss: 0.2800 - val_accuracy: 0.5007\n",
      "Epoch 112/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2815 - accuracy: 0.4977 - val_loss: 0.2803 - val_accuracy: 0.5000\n",
      "Epoch 113/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2819 - accuracy: 0.4967 - val_loss: 0.2791 - val_accuracy: 0.5022\n",
      "Epoch 114/500\n",
      "577/577 [==============================] - 0s 814us/step - loss: 0.2822 - accuracy: 0.4943 - val_loss: 0.2811 - val_accuracy: 0.4970\n",
      "Epoch 115/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2818 - accuracy: 0.4969 - val_loss: 0.2806 - val_accuracy: 0.4983\n",
      "Epoch 116/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2822 - accuracy: 0.4973 - val_loss: 0.2797 - val_accuracy: 0.5104\n",
      "Epoch 117/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2813 - accuracy: 0.4985 - val_loss: 0.2798 - val_accuracy: 0.5050\n",
      "Epoch 118/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2820 - accuracy: 0.4940 - val_loss: 0.2795 - val_accuracy: 0.4998\n",
      "Epoch 119/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2822 - accuracy: 0.4959 - val_loss: 0.2803 - val_accuracy: 0.4978\n",
      "Epoch 120/500\n",
      "577/577 [==============================] - 0s 817us/step - loss: 0.2815 - accuracy: 0.4962 - val_loss: 0.2796 - val_accuracy: 0.5030\n",
      "Epoch 121/500\n",
      "577/577 [==============================] - 0s 844us/step - loss: 0.2814 - accuracy: 0.4958 - val_loss: 0.2790 - val_accuracy: 0.5024\n",
      "Epoch 122/500\n",
      "577/577 [==============================] - 0s 856us/step - loss: 0.2814 - accuracy: 0.4966 - val_loss: 0.2790 - val_accuracy: 0.5035\n",
      "Epoch 123/500\n",
      "577/577 [==============================] - 0s 850us/step - loss: 0.2814 - accuracy: 0.4948 - val_loss: 0.2797 - val_accuracy: 0.5052\n",
      "Epoch 124/500\n",
      "577/577 [==============================] - 0s 849us/step - loss: 0.2813 - accuracy: 0.4969 - val_loss: 0.2798 - val_accuracy: 0.5046\n",
      "Epoch 125/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2814 - accuracy: 0.4963 - val_loss: 0.2795 - val_accuracy: 0.5020\n",
      "Epoch 126/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2816 - accuracy: 0.4974 - val_loss: 0.2790 - val_accuracy: 0.5093\n",
      "Epoch 127/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2809 - accuracy: 0.5001 - val_loss: 0.2799 - val_accuracy: 0.5022\n",
      "Epoch 128/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2812 - accuracy: 0.4982 - val_loss: 0.2795 - val_accuracy: 0.5033\n",
      "Epoch 129/500\n",
      "577/577 [==============================] - 1s 985us/step - loss: 0.2812 - accuracy: 0.5025 - val_loss: 0.2805 - val_accuracy: 0.4987\n",
      "Epoch 130/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2811 - accuracy: 0.4976 - val_loss: 0.2802 - val_accuracy: 0.4987\n",
      "Epoch 131/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2813 - accuracy: 0.4957 - val_loss: 0.2798 - val_accuracy: 0.5028\n",
      "Epoch 132/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2811 - accuracy: 0.4966 - val_loss: 0.2795 - val_accuracy: 0.5030\n",
      "Epoch 133/500\n",
      "577/577 [==============================] - 0s 812us/step - loss: 0.2817 - accuracy: 0.4956 - val_loss: 0.2796 - val_accuracy: 0.5035\n",
      "Epoch 134/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2809 - accuracy: 0.4988 - val_loss: 0.2793 - val_accuracy: 0.5011\n",
      "Epoch 135/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2814 - accuracy: 0.4952 - val_loss: 0.2792 - val_accuracy: 0.5015\n",
      "Epoch 136/500\n",
      "577/577 [==============================] - 1s 878us/step - loss: 0.2810 - accuracy: 0.4966 - val_loss: 0.2789 - val_accuracy: 0.5013\n",
      "Epoch 137/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2813 - accuracy: 0.4960 - val_loss: 0.2783 - val_accuracy: 0.5061\n",
      "Epoch 138/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2817 - accuracy: 0.4964 - val_loss: 0.2800 - val_accuracy: 0.5020\n",
      "Epoch 139/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2815 - accuracy: 0.4969 - val_loss: 0.2800 - val_accuracy: 0.5007\n",
      "Epoch 140/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2812 - accuracy: 0.4992 - val_loss: 0.2786 - val_accuracy: 0.5020\n",
      "Epoch 141/500\n",
      "577/577 [==============================] - 0s 811us/step - loss: 0.2807 - accuracy: 0.4989 - val_loss: 0.2808 - val_accuracy: 0.5013\n",
      "Epoch 142/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2815 - accuracy: 0.4945 - val_loss: 0.2782 - val_accuracy: 0.4998\n",
      "Epoch 143/500\n",
      "577/577 [==============================] - 0s 821us/step - loss: 0.2807 - accuracy: 0.4992 - val_loss: 0.2793 - val_accuracy: 0.5065\n",
      "Epoch 144/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2809 - accuracy: 0.4985 - val_loss: 0.2787 - val_accuracy: 0.5037\n",
      "Epoch 145/500\n",
      "577/577 [==============================] - 1s 940us/step - loss: 0.2812 - accuracy: 0.5014 - val_loss: 0.2786 - val_accuracy: 0.4972\n",
      "Epoch 146/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2808 - accuracy: 0.4980 - val_loss: 0.2792 - val_accuracy: 0.5030\n",
      "Epoch 147/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2808 - accuracy: 0.5014 - val_loss: 0.2786 - val_accuracy: 0.5035\n",
      "Epoch 148/500\n",
      "577/577 [==============================] - 0s 821us/step - loss: 0.2809 - accuracy: 0.5012 - val_loss: 0.2785 - val_accuracy: 0.5074\n",
      "Epoch 149/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2803 - accuracy: 0.4997 - val_loss: 0.2801 - val_accuracy: 0.4985\n",
      "Epoch 150/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2808 - accuracy: 0.5010 - val_loss: 0.2788 - val_accuracy: 0.5020\n",
      "Epoch 151/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2808 - accuracy: 0.4979 - val_loss: 0.2794 - val_accuracy: 0.5015\n",
      "Epoch 152/500\n",
      "577/577 [==============================] - 0s 847us/step - loss: 0.2810 - accuracy: 0.4997 - val_loss: 0.2780 - val_accuracy: 0.5037\n",
      "Epoch 153/500\n",
      "577/577 [==============================] - 1s 876us/step - loss: 0.2809 - accuracy: 0.4963 - val_loss: 0.2783 - val_accuracy: 0.5033\n",
      "Epoch 154/500\n",
      "577/577 [==============================] - 0s 845us/step - loss: 0.2800 - accuracy: 0.4973 - val_loss: 0.2798 - val_accuracy: 0.4948\n",
      "Epoch 155/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2804 - accuracy: 0.5002 - val_loss: 0.2782 - val_accuracy: 0.5054\n",
      "Epoch 156/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2808 - accuracy: 0.4973 - val_loss: 0.2781 - val_accuracy: 0.5072\n",
      "Epoch 157/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2804 - accuracy: 0.4987 - val_loss: 0.2797 - val_accuracy: 0.4976\n",
      "Epoch 158/500\n",
      "577/577 [==============================] - 0s 857us/step - loss: 0.2797 - accuracy: 0.5020 - val_loss: 0.2789 - val_accuracy: 0.5035\n",
      "Epoch 159/500\n",
      "577/577 [==============================] - 1s 1ms/step - loss: 0.2808 - accuracy: 0.4993 - val_loss: 0.2783 - val_accuracy: 0.5024\n",
      "Epoch 160/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2803 - accuracy: 0.5018 - val_loss: 0.2782 - val_accuracy: 0.5037\n",
      "Epoch 161/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2806 - accuracy: 0.5020 - val_loss: 0.2789 - val_accuracy: 0.4993\n",
      "Epoch 162/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2805 - accuracy: 0.5015 - val_loss: 0.2791 - val_accuracy: 0.5030\n",
      "Epoch 163/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2804 - accuracy: 0.4983 - val_loss: 0.2786 - val_accuracy: 0.4998\n",
      "Epoch 164/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2798 - accuracy: 0.5018 - val_loss: 0.2801 - val_accuracy: 0.5000\n",
      "Epoch 165/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2797 - accuracy: 0.4996 - val_loss: 0.2779 - val_accuracy: 0.5076\n",
      "Epoch 166/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2805 - accuracy: 0.5004 - val_loss: 0.2788 - val_accuracy: 0.5007\n",
      "Epoch 167/500\n",
      "577/577 [==============================] - 0s 817us/step - loss: 0.2802 - accuracy: 0.5014 - val_loss: 0.2782 - val_accuracy: 0.5033\n",
      "Epoch 168/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2810 - accuracy: 0.4993 - val_loss: 0.2789 - val_accuracy: 0.5007\n",
      "Epoch 169/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2805 - accuracy: 0.5018 - val_loss: 0.2780 - val_accuracy: 0.5011\n",
      "Epoch 170/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2798 - accuracy: 0.5025 - val_loss: 0.2784 - val_accuracy: 0.5028\n",
      "Epoch 171/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2799 - accuracy: 0.4992 - val_loss: 0.2782 - val_accuracy: 0.5089\n",
      "Epoch 172/500\n",
      "577/577 [==============================] - 1s 948us/step - loss: 0.2806 - accuracy: 0.5002 - val_loss: 0.2787 - val_accuracy: 0.5046\n",
      "Epoch 173/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2800 - accuracy: 0.4991 - val_loss: 0.2783 - val_accuracy: 0.5069\n",
      "Epoch 174/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2805 - accuracy: 0.5007 - val_loss: 0.2789 - val_accuracy: 0.4985\n",
      "Epoch 175/500\n",
      "577/577 [==============================] - 0s 801us/step - loss: 0.2800 - accuracy: 0.5012 - val_loss: 0.2786 - val_accuracy: 0.5000\n",
      "Epoch 176/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2799 - accuracy: 0.5005 - val_loss: 0.2805 - val_accuracy: 0.4970\n",
      "Epoch 177/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2801 - accuracy: 0.5021 - val_loss: 0.2795 - val_accuracy: 0.5011\n",
      "Epoch 178/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2802 - accuracy: 0.4997 - val_loss: 0.2791 - val_accuracy: 0.5054\n",
      "Epoch 179/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2800 - accuracy: 0.4999 - val_loss: 0.2778 - val_accuracy: 0.5013\n",
      "Epoch 180/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2799 - accuracy: 0.5021 - val_loss: 0.2786 - val_accuracy: 0.5026\n",
      "Epoch 181/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2798 - accuracy: 0.5028 - val_loss: 0.2779 - val_accuracy: 0.4987\n",
      "Epoch 182/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2796 - accuracy: 0.4967 - val_loss: 0.2783 - val_accuracy: 0.5002\n",
      "Epoch 183/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2802 - accuracy: 0.5014 - val_loss: 0.2785 - val_accuracy: 0.5000\n",
      "Epoch 184/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2795 - accuracy: 0.5016 - val_loss: 0.2781 - val_accuracy: 0.5056\n",
      "Epoch 185/500\n",
      "577/577 [==============================] - 1s 966us/step - loss: 0.2800 - accuracy: 0.5026 - val_loss: 0.2802 - val_accuracy: 0.5000\n",
      "Epoch 186/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2797 - accuracy: 0.5013 - val_loss: 0.2785 - val_accuracy: 0.5015\n",
      "Epoch 187/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2801 - accuracy: 0.5000 - val_loss: 0.2785 - val_accuracy: 0.5026\n",
      "Epoch 188/500\n",
      "577/577 [==============================] - 0s 798us/step - loss: 0.2803 - accuracy: 0.5004 - val_loss: 0.2787 - val_accuracy: 0.4989\n",
      "Epoch 189/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2799 - accuracy: 0.5027 - val_loss: 0.2789 - val_accuracy: 0.5013\n",
      "Epoch 190/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2792 - accuracy: 0.5008 - val_loss: 0.2783 - val_accuracy: 0.4978\n",
      "Epoch 191/500\n",
      "577/577 [==============================] - 0s 801us/step - loss: 0.2793 - accuracy: 0.5035 - val_loss: 0.2794 - val_accuracy: 0.4976\n",
      "Epoch 192/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2794 - accuracy: 0.5025 - val_loss: 0.2784 - val_accuracy: 0.5041\n",
      "Epoch 193/500\n",
      "577/577 [==============================] - 1s 883us/step - loss: 0.2797 - accuracy: 0.5024 - val_loss: 0.2781 - val_accuracy: 0.4993\n",
      "Epoch 194/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2801 - accuracy: 0.4998 - val_loss: 0.2790 - val_accuracy: 0.5033\n",
      "Epoch 195/500\n",
      "577/577 [==============================] - 0s 855us/step - loss: 0.2800 - accuracy: 0.5034 - val_loss: 0.2797 - val_accuracy: 0.5026\n",
      "Epoch 196/500\n",
      "577/577 [==============================] - 0s 842us/step - loss: 0.2791 - accuracy: 0.5036 - val_loss: 0.2783 - val_accuracy: 0.5067\n",
      "Epoch 197/500\n",
      "577/577 [==============================] - 1s 934us/step - loss: 0.2791 - accuracy: 0.5015 - val_loss: 0.2773 - val_accuracy: 0.5089\n",
      "Epoch 198/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2793 - accuracy: 0.4998 - val_loss: 0.2787 - val_accuracy: 0.5015\n",
      "Epoch 199/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2794 - accuracy: 0.5010 - val_loss: 0.2800 - val_accuracy: 0.5013\n",
      "Epoch 200/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2792 - accuracy: 0.5018 - val_loss: 0.2785 - val_accuracy: 0.5048\n",
      "Epoch 201/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2799 - accuracy: 0.5011 - val_loss: 0.2784 - val_accuracy: 0.5022\n",
      "Epoch 202/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2798 - accuracy: 0.5003 - val_loss: 0.2787 - val_accuracy: 0.5009\n",
      "Epoch 203/500\n",
      "577/577 [==============================] - 0s 857us/step - loss: 0.2792 - accuracy: 0.5040 - val_loss: 0.2789 - val_accuracy: 0.4965\n",
      "Epoch 204/500\n",
      "577/577 [==============================] - 1s 874us/step - loss: 0.2795 - accuracy: 0.5047 - val_loss: 0.2783 - val_accuracy: 0.5035\n",
      "Epoch 205/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2798 - accuracy: 0.5002 - val_loss: 0.2779 - val_accuracy: 0.5033\n",
      "Epoch 206/500\n",
      "577/577 [==============================] - 0s 843us/step - loss: 0.2790 - accuracy: 0.5027 - val_loss: 0.2770 - val_accuracy: 0.5065\n",
      "Epoch 207/500\n",
      "577/577 [==============================] - 0s 848us/step - loss: 0.2794 - accuracy: 0.5066 - val_loss: 0.2769 - val_accuracy: 0.5056\n",
      "Epoch 208/500\n",
      "577/577 [==============================] - 1s 932us/step - loss: 0.2795 - accuracy: 0.5023 - val_loss: 0.2776 - val_accuracy: 0.5033\n",
      "Epoch 209/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2796 - accuracy: 0.5025 - val_loss: 0.2784 - val_accuracy: 0.5048\n",
      "Epoch 210/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2789 - accuracy: 0.5023 - val_loss: 0.2779 - val_accuracy: 0.5000\n",
      "Epoch 211/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2795 - accuracy: 0.5007 - val_loss: 0.2776 - val_accuracy: 0.5041\n",
      "Epoch 212/500\n",
      "577/577 [==============================] - 0s 846us/step - loss: 0.2801 - accuracy: 0.5002 - val_loss: 0.2791 - val_accuracy: 0.4993\n",
      "Epoch 213/500\n",
      "577/577 [==============================] - 0s 850us/step - loss: 0.2789 - accuracy: 0.5068 - val_loss: 0.2784 - val_accuracy: 0.5046\n",
      "Epoch 214/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2791 - accuracy: 0.5030 - val_loss: 0.2786 - val_accuracy: 0.5020\n",
      "Epoch 215/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2789 - accuracy: 0.5056 - val_loss: 0.2783 - val_accuracy: 0.5039\n",
      "Epoch 216/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2792 - accuracy: 0.5022 - val_loss: 0.2779 - val_accuracy: 0.5069\n",
      "Epoch 217/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2797 - accuracy: 0.5017 - val_loss: 0.2771 - val_accuracy: 0.5046\n",
      "Epoch 218/500\n",
      "577/577 [==============================] - 0s 817us/step - loss: 0.2797 - accuracy: 0.5027 - val_loss: 0.2771 - val_accuracy: 0.5052\n",
      "Epoch 219/500\n",
      "577/577 [==============================] - 1s 959us/step - loss: 0.2788 - accuracy: 0.5011 - val_loss: 0.2782 - val_accuracy: 0.5054\n",
      "Epoch 220/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2786 - accuracy: 0.5050 - val_loss: 0.2767 - val_accuracy: 0.5056\n",
      "Epoch 221/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2789 - accuracy: 0.5047 - val_loss: 0.2771 - val_accuracy: 0.5030\n",
      "Epoch 222/500\n",
      "577/577 [==============================] - 0s 814us/step - loss: 0.2786 - accuracy: 0.5014 - val_loss: 0.2784 - val_accuracy: 0.5013\n",
      "Epoch 223/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2786 - accuracy: 0.5023 - val_loss: 0.2785 - val_accuracy: 0.5002\n",
      "Epoch 224/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2788 - accuracy: 0.5063 - val_loss: 0.2776 - val_accuracy: 0.4970\n",
      "Epoch 225/500\n",
      "577/577 [==============================] - 0s 802us/step - loss: 0.2793 - accuracy: 0.5042 - val_loss: 0.2784 - val_accuracy: 0.5020\n",
      "Epoch 226/500\n",
      "577/577 [==============================] - 0s 797us/step - loss: 0.2791 - accuracy: 0.5028 - val_loss: 0.2783 - val_accuracy: 0.4993\n",
      "Epoch 227/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2794 - accuracy: 0.5021 - val_loss: 0.2795 - val_accuracy: 0.4978\n",
      "Epoch 228/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2784 - accuracy: 0.5044 - val_loss: 0.2784 - val_accuracy: 0.5028\n",
      "Epoch 229/500\n",
      "577/577 [==============================] - 1s 951us/step - loss: 0.2788 - accuracy: 0.5051 - val_loss: 0.2786 - val_accuracy: 0.5061\n",
      "Epoch 230/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2792 - accuracy: 0.5039 - val_loss: 0.2773 - val_accuracy: 0.5104\n",
      "Epoch 231/500\n",
      "577/577 [==============================] - 0s 821us/step - loss: 0.2783 - accuracy: 0.5046 - val_loss: 0.2774 - val_accuracy: 0.5046\n",
      "Epoch 232/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2786 - accuracy: 0.5033 - val_loss: 0.2767 - val_accuracy: 0.5037\n",
      "Epoch 233/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2787 - accuracy: 0.5061 - val_loss: 0.2769 - val_accuracy: 0.5059\n",
      "Epoch 234/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2787 - accuracy: 0.5038 - val_loss: 0.2773 - val_accuracy: 0.5054\n",
      "Epoch 235/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2782 - accuracy: 0.5066 - val_loss: 0.2786 - val_accuracy: 0.5050\n",
      "Epoch 236/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2789 - accuracy: 0.5007 - val_loss: 0.2782 - val_accuracy: 0.5087\n",
      "Epoch 237/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2791 - accuracy: 0.5023 - val_loss: 0.2772 - val_accuracy: 0.5078\n",
      "Epoch 238/500\n",
      "577/577 [==============================] - 0s 813us/step - loss: 0.2787 - accuracy: 0.5079 - val_loss: 0.2764 - val_accuracy: 0.5111\n",
      "Epoch 239/500\n",
      "577/577 [==============================] - 1s 971us/step - loss: 0.2783 - accuracy: 0.5060 - val_loss: 0.2772 - val_accuracy: 0.5093\n",
      "Epoch 240/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2786 - accuracy: 0.5049 - val_loss: 0.2782 - val_accuracy: 0.4993\n",
      "Epoch 241/500\n",
      "577/577 [==============================] - 0s 801us/step - loss: 0.2787 - accuracy: 0.5041 - val_loss: 0.2786 - val_accuracy: 0.5017\n",
      "Epoch 242/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2787 - accuracy: 0.5030 - val_loss: 0.2776 - val_accuracy: 0.5072\n",
      "Epoch 243/500\n",
      "577/577 [==============================] - 0s 814us/step - loss: 0.2783 - accuracy: 0.5069 - val_loss: 0.2784 - val_accuracy: 0.5067\n",
      "Epoch 244/500\n",
      "577/577 [==============================] - 0s 840us/step - loss: 0.2782 - accuracy: 0.5089 - val_loss: 0.2785 - val_accuracy: 0.4998\n",
      "Epoch 245/500\n",
      "577/577 [==============================] - 1s 911us/step - loss: 0.2785 - accuracy: 0.5049 - val_loss: 0.2764 - val_accuracy: 0.5061\n",
      "Epoch 246/500\n",
      "577/577 [==============================] - 1s 876us/step - loss: 0.2786 - accuracy: 0.5054 - val_loss: 0.2779 - val_accuracy: 0.5041\n",
      "Epoch 247/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2789 - accuracy: 0.5037 - val_loss: 0.2793 - val_accuracy: 0.4998\n",
      "Epoch 248/500\n",
      "577/577 [==============================] - 1s 969us/step - loss: 0.2789 - accuracy: 0.5063 - val_loss: 0.2786 - val_accuracy: 0.5063\n",
      "Epoch 249/500\n",
      "577/577 [==============================] - 0s 855us/step - loss: 0.2790 - accuracy: 0.5036 - val_loss: 0.2785 - val_accuracy: 0.5052\n",
      "Epoch 250/500\n",
      "577/577 [==============================] - 0s 840us/step - loss: 0.2789 - accuracy: 0.5075 - val_loss: 0.2779 - val_accuracy: 0.5048\n",
      "Epoch 251/500\n",
      "577/577 [==============================] - 1s 917us/step - loss: 0.2786 - accuracy: 0.5060 - val_loss: 0.2780 - val_accuracy: 0.5026\n",
      "Epoch 252/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2787 - accuracy: 0.5043 - val_loss: 0.2781 - val_accuracy: 0.5050\n",
      "Epoch 253/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2779 - accuracy: 0.5068 - val_loss: 0.2788 - val_accuracy: 0.5048\n",
      "Epoch 254/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2783 - accuracy: 0.5074 - val_loss: 0.2773 - val_accuracy: 0.5037\n",
      "Epoch 255/500\n",
      "577/577 [==============================] - 0s 817us/step - loss: 0.2786 - accuracy: 0.5049 - val_loss: 0.2787 - val_accuracy: 0.5030\n",
      "Epoch 256/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2781 - accuracy: 0.5060 - val_loss: 0.2766 - val_accuracy: 0.5095\n",
      "Epoch 257/500\n",
      "577/577 [==============================] - 1s 955us/step - loss: 0.2788 - accuracy: 0.5065 - val_loss: 0.2773 - val_accuracy: 0.5076\n",
      "Epoch 258/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2778 - accuracy: 0.5099 - val_loss: 0.2774 - val_accuracy: 0.5108\n",
      "Epoch 259/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2782 - accuracy: 0.5041 - val_loss: 0.2775 - val_accuracy: 0.5100\n",
      "Epoch 260/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2783 - accuracy: 0.5035 - val_loss: 0.2766 - val_accuracy: 0.5100\n",
      "Epoch 261/500\n",
      "577/577 [==============================] - 0s 809us/step - loss: 0.2782 - accuracy: 0.5055 - val_loss: 0.2771 - val_accuracy: 0.5089\n",
      "Epoch 262/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2782 - accuracy: 0.5045 - val_loss: 0.2781 - val_accuracy: 0.5015\n",
      "Epoch 263/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2785 - accuracy: 0.5021 - val_loss: 0.2771 - val_accuracy: 0.5085\n",
      "Epoch 264/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2790 - accuracy: 0.5044 - val_loss: 0.2782 - val_accuracy: 0.5076\n",
      "Epoch 265/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2779 - accuracy: 0.5074 - val_loss: 0.2773 - val_accuracy: 0.5100\n",
      "Epoch 266/500\n",
      "577/577 [==============================] - 1s 956us/step - loss: 0.2786 - accuracy: 0.5053 - val_loss: 0.2777 - val_accuracy: 0.5082\n",
      "Epoch 267/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2782 - accuracy: 0.5050 - val_loss: 0.2784 - val_accuracy: 0.4989\n",
      "Epoch 268/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2785 - accuracy: 0.5051 - val_loss: 0.2780 - val_accuracy: 0.5020\n",
      "Epoch 269/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2777 - accuracy: 0.5050 - val_loss: 0.2778 - val_accuracy: 0.5052\n",
      "Epoch 270/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2787 - accuracy: 0.5065 - val_loss: 0.2769 - val_accuracy: 0.5082\n",
      "Epoch 271/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2781 - accuracy: 0.5041 - val_loss: 0.2761 - val_accuracy: 0.5100\n",
      "Epoch 272/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2780 - accuracy: 0.5066 - val_loss: 0.2780 - val_accuracy: 0.5037\n",
      "Epoch 273/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2778 - accuracy: 0.5083 - val_loss: 0.2782 - val_accuracy: 0.5072\n",
      "Epoch 274/500\n",
      "577/577 [==============================] - 1s 957us/step - loss: 0.2789 - accuracy: 0.5038 - val_loss: 0.2767 - val_accuracy: 0.5063\n",
      "Epoch 275/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2776 - accuracy: 0.5105 - val_loss: 0.2772 - val_accuracy: 0.5059\n",
      "Epoch 276/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2790 - accuracy: 0.5061 - val_loss: 0.2773 - val_accuracy: 0.5072\n",
      "Epoch 277/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2777 - accuracy: 0.5068 - val_loss: 0.2772 - val_accuracy: 0.5052\n",
      "Epoch 278/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2780 - accuracy: 0.5088 - val_loss: 0.2771 - val_accuracy: 0.5078\n",
      "Epoch 279/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2780 - accuracy: 0.5047 - val_loss: 0.2770 - val_accuracy: 0.5072\n",
      "Epoch 280/500\n",
      "577/577 [==============================] - 0s 821us/step - loss: 0.2788 - accuracy: 0.5073 - val_loss: 0.2782 - val_accuracy: 0.5039\n",
      "Epoch 281/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2784 - accuracy: 0.5068 - val_loss: 0.2763 - val_accuracy: 0.5117\n",
      "Epoch 282/500\n",
      "577/577 [==============================] - 1s 968us/step - loss: 0.2778 - accuracy: 0.5040 - val_loss: 0.2773 - val_accuracy: 0.5043\n",
      "Epoch 283/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2777 - accuracy: 0.5104 - val_loss: 0.2769 - val_accuracy: 0.5041\n",
      "Epoch 284/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2778 - accuracy: 0.5025 - val_loss: 0.2774 - val_accuracy: 0.5039\n",
      "Epoch 285/500\n",
      "577/577 [==============================] - 0s 844us/step - loss: 0.2782 - accuracy: 0.5066 - val_loss: 0.2784 - val_accuracy: 0.5035\n",
      "Epoch 286/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2776 - accuracy: 0.5062 - val_loss: 0.2770 - val_accuracy: 0.5059\n",
      "Epoch 287/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2781 - accuracy: 0.5054 - val_loss: 0.2771 - val_accuracy: 0.5037\n",
      "Epoch 288/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2784 - accuracy: 0.5050 - val_loss: 0.2774 - val_accuracy: 0.5078\n",
      "Epoch 289/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2777 - accuracy: 0.5083 - val_loss: 0.2772 - val_accuracy: 0.4993\n",
      "Epoch 290/500\n",
      "577/577 [==============================] - 1s 944us/step - loss: 0.2778 - accuracy: 0.5059 - val_loss: 0.2759 - val_accuracy: 0.5052\n",
      "Epoch 291/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2787 - accuracy: 0.5057 - val_loss: 0.2758 - val_accuracy: 0.5039\n",
      "Epoch 292/500\n",
      "577/577 [==============================] - 0s 811us/step - loss: 0.2781 - accuracy: 0.5054 - val_loss: 0.2761 - val_accuracy: 0.5087\n",
      "Epoch 293/500\n",
      "577/577 [==============================] - 0s 813us/step - loss: 0.2774 - accuracy: 0.5073 - val_loss: 0.2780 - val_accuracy: 0.5004\n",
      "Epoch 294/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2778 - accuracy: 0.5072 - val_loss: 0.2771 - val_accuracy: 0.5061\n",
      "Epoch 295/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2776 - accuracy: 0.5079 - val_loss: 0.2779 - val_accuracy: 0.5063\n",
      "Epoch 296/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2782 - accuracy: 0.5046 - val_loss: 0.2764 - val_accuracy: 0.5089\n",
      "Epoch 297/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2784 - accuracy: 0.5086 - val_loss: 0.2786 - val_accuracy: 0.5082\n",
      "Epoch 298/500\n",
      "577/577 [==============================] - 1s 947us/step - loss: 0.2780 - accuracy: 0.5068 - val_loss: 0.2781 - val_accuracy: 0.5067\n",
      "Epoch 299/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2771 - accuracy: 0.5074 - val_loss: 0.2770 - val_accuracy: 0.5052\n",
      "Epoch 300/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2781 - accuracy: 0.5088 - val_loss: 0.2767 - val_accuracy: 0.5065\n",
      "Epoch 301/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2780 - accuracy: 0.5032 - val_loss: 0.2780 - val_accuracy: 0.5085\n",
      "Epoch 302/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2774 - accuracy: 0.5066 - val_loss: 0.2751 - val_accuracy: 0.5154\n",
      "Epoch 303/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2784 - accuracy: 0.5055 - val_loss: 0.2768 - val_accuracy: 0.5013\n",
      "Epoch 304/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2776 - accuracy: 0.5076 - val_loss: 0.2775 - val_accuracy: 0.5033\n",
      "Epoch 305/500\n",
      "577/577 [==============================] - 1s 952us/step - loss: 0.2784 - accuracy: 0.5071 - val_loss: 0.2768 - val_accuracy: 0.5076\n",
      "Epoch 306/500\n",
      "577/577 [==============================] - 0s 805us/step - loss: 0.2776 - accuracy: 0.5092 - val_loss: 0.2763 - val_accuracy: 0.5052\n",
      "Epoch 307/500\n",
      "577/577 [==============================] - 0s 803us/step - loss: 0.2782 - accuracy: 0.5046 - val_loss: 0.2770 - val_accuracy: 0.5130\n",
      "Epoch 308/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2779 - accuracy: 0.5073 - val_loss: 0.2763 - val_accuracy: 0.5091\n",
      "Epoch 309/500\n",
      "577/577 [==============================] - 0s 839us/step - loss: 0.2783 - accuracy: 0.5096 - val_loss: 0.2768 - val_accuracy: 0.5117\n",
      "Epoch 310/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2775 - accuracy: 0.5098 - val_loss: 0.2757 - val_accuracy: 0.5113\n",
      "Epoch 311/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2769 - accuracy: 0.5079 - val_loss: 0.2762 - val_accuracy: 0.5085\n",
      "Epoch 312/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2777 - accuracy: 0.5100 - val_loss: 0.2767 - val_accuracy: 0.5108\n",
      "Epoch 313/500\n",
      "577/577 [==============================] - 1s 970us/step - loss: 0.2779 - accuracy: 0.5046 - val_loss: 0.2762 - val_accuracy: 0.5091\n",
      "Epoch 314/500\n",
      "577/577 [==============================] - 0s 846us/step - loss: 0.2773 - accuracy: 0.5107 - val_loss: 0.2768 - val_accuracy: 0.5093\n",
      "Epoch 315/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2779 - accuracy: 0.5064 - val_loss: 0.2756 - val_accuracy: 0.5087\n",
      "Epoch 316/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2781 - accuracy: 0.5055 - val_loss: 0.2770 - val_accuracy: 0.5056\n",
      "Epoch 317/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2774 - accuracy: 0.5073 - val_loss: 0.2761 - val_accuracy: 0.5098\n",
      "Epoch 318/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2780 - accuracy: 0.5060 - val_loss: 0.2764 - val_accuracy: 0.5091\n",
      "Epoch 319/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2776 - accuracy: 0.5079 - val_loss: 0.2778 - val_accuracy: 0.5056\n",
      "Epoch 320/500\n",
      "577/577 [==============================] - 1s 954us/step - loss: 0.2776 - accuracy: 0.5060 - val_loss: 0.2768 - val_accuracy: 0.5104\n",
      "Epoch 321/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2776 - accuracy: 0.5076 - val_loss: 0.2746 - val_accuracy: 0.5126\n",
      "Epoch 322/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2782 - accuracy: 0.5044 - val_loss: 0.2772 - val_accuracy: 0.5050\n",
      "Epoch 323/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2774 - accuracy: 0.5092 - val_loss: 0.2764 - val_accuracy: 0.5041\n",
      "Epoch 324/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2778 - accuracy: 0.5088 - val_loss: 0.2749 - val_accuracy: 0.5124\n",
      "Epoch 325/500\n",
      "577/577 [==============================] - 0s 805us/step - loss: 0.2779 - accuracy: 0.5084 - val_loss: 0.2771 - val_accuracy: 0.5063\n",
      "Epoch 326/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2775 - accuracy: 0.5083 - val_loss: 0.2755 - val_accuracy: 0.5078\n",
      "Epoch 327/500\n",
      "577/577 [==============================] - 1s 929us/step - loss: 0.2771 - accuracy: 0.5078 - val_loss: 0.2767 - val_accuracy: 0.5104\n",
      "Epoch 328/500\n",
      "577/577 [==============================] - 0s 839us/step - loss: 0.2780 - accuracy: 0.5071 - val_loss: 0.2785 - val_accuracy: 0.5041\n",
      "Epoch 329/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2771 - accuracy: 0.5089 - val_loss: 0.2755 - val_accuracy: 0.5095\n",
      "Epoch 330/500\n",
      "577/577 [==============================] - 0s 812us/step - loss: 0.2772 - accuracy: 0.5098 - val_loss: 0.2762 - val_accuracy: 0.5076\n",
      "Epoch 331/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2772 - accuracy: 0.5087 - val_loss: 0.2756 - val_accuracy: 0.5080\n",
      "Epoch 332/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2780 - accuracy: 0.5037 - val_loss: 0.2770 - val_accuracy: 0.5108\n",
      "Epoch 333/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2771 - accuracy: 0.5084 - val_loss: 0.2760 - val_accuracy: 0.5087\n",
      "Epoch 334/500\n",
      "577/577 [==============================] - 1s 946us/step - loss: 0.2773 - accuracy: 0.5060 - val_loss: 0.2769 - val_accuracy: 0.5113\n",
      "Epoch 335/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2771 - accuracy: 0.5072 - val_loss: 0.2756 - val_accuracy: 0.5143\n",
      "Epoch 336/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2774 - accuracy: 0.5056 - val_loss: 0.2771 - val_accuracy: 0.5022\n",
      "Epoch 337/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2779 - accuracy: 0.5055 - val_loss: 0.2774 - val_accuracy: 0.5035\n",
      "Epoch 338/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2771 - accuracy: 0.5074 - val_loss: 0.2757 - val_accuracy: 0.5102\n",
      "Epoch 339/500\n",
      "577/577 [==============================] - 0s 794us/step - loss: 0.2770 - accuracy: 0.5085 - val_loss: 0.2779 - val_accuracy: 0.5052\n",
      "Epoch 340/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2770 - accuracy: 0.5091 - val_loss: 0.2761 - val_accuracy: 0.5102\n",
      "Epoch 341/500\n",
      "577/577 [==============================] - 1s 961us/step - loss: 0.2772 - accuracy: 0.5086 - val_loss: 0.2750 - val_accuracy: 0.5134\n",
      "Epoch 342/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2774 - accuracy: 0.5075 - val_loss: 0.2763 - val_accuracy: 0.5091\n",
      "Epoch 343/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2778 - accuracy: 0.5030 - val_loss: 0.2758 - val_accuracy: 0.5091\n",
      "Epoch 344/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2774 - accuracy: 0.5091 - val_loss: 0.2763 - val_accuracy: 0.5121\n",
      "Epoch 345/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2773 - accuracy: 0.5110 - val_loss: 0.2756 - val_accuracy: 0.5134\n",
      "Epoch 346/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2777 - accuracy: 0.5070 - val_loss: 0.2769 - val_accuracy: 0.5074\n",
      "Epoch 347/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2773 - accuracy: 0.5094 - val_loss: 0.2755 - val_accuracy: 0.5128\n",
      "Epoch 348/500\n",
      "577/577 [==============================] - 1s 965us/step - loss: 0.2777 - accuracy: 0.5059 - val_loss: 0.2751 - val_accuracy: 0.5108\n",
      "Epoch 349/500\n",
      "577/577 [==============================] - 0s 840us/step - loss: 0.2775 - accuracy: 0.5104 - val_loss: 0.2750 - val_accuracy: 0.5145\n",
      "Epoch 350/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2781 - accuracy: 0.5073 - val_loss: 0.2758 - val_accuracy: 0.5089\n",
      "Epoch 351/500\n",
      "577/577 [==============================] - 0s 816us/step - loss: 0.2771 - accuracy: 0.5066 - val_loss: 0.2755 - val_accuracy: 0.5113\n",
      "Epoch 352/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2770 - accuracy: 0.5053 - val_loss: 0.2773 - val_accuracy: 0.5039\n",
      "Epoch 353/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2773 - accuracy: 0.5093 - val_loss: 0.2770 - val_accuracy: 0.5091\n",
      "Epoch 354/500\n",
      "577/577 [==============================] - 1s 931us/step - loss: 0.2769 - accuracy: 0.5088 - val_loss: 0.2766 - val_accuracy: 0.5063\n",
      "Epoch 355/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2779 - accuracy: 0.5089 - val_loss: 0.2768 - val_accuracy: 0.5043\n",
      "Epoch 356/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2778 - accuracy: 0.5072 - val_loss: 0.2765 - val_accuracy: 0.5106\n",
      "Epoch 357/500\n",
      "577/577 [==============================] - 0s 814us/step - loss: 0.2777 - accuracy: 0.5093 - val_loss: 0.2773 - val_accuracy: 0.5087\n",
      "Epoch 358/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2774 - accuracy: 0.5078 - val_loss: 0.2760 - val_accuracy: 0.5117\n",
      "Epoch 359/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2775 - accuracy: 0.5091 - val_loss: 0.2766 - val_accuracy: 0.5050\n",
      "Epoch 360/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2771 - accuracy: 0.5092 - val_loss: 0.2766 - val_accuracy: 0.5076\n",
      "Epoch 361/500\n",
      "577/577 [==============================] - 1s 960us/step - loss: 0.2770 - accuracy: 0.5073 - val_loss: 0.2767 - val_accuracy: 0.5072\n",
      "Epoch 362/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2770 - accuracy: 0.5088 - val_loss: 0.2768 - val_accuracy: 0.5069\n",
      "Epoch 363/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2770 - accuracy: 0.5069 - val_loss: 0.2763 - val_accuracy: 0.5108\n",
      "Epoch 364/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2768 - accuracy: 0.5080 - val_loss: 0.2765 - val_accuracy: 0.5085\n",
      "Epoch 365/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2772 - accuracy: 0.5074 - val_loss: 0.2765 - val_accuracy: 0.5087\n",
      "Epoch 366/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2772 - accuracy: 0.5091 - val_loss: 0.2768 - val_accuracy: 0.5074\n",
      "Epoch 367/500\n",
      "577/577 [==============================] - 1s 951us/step - loss: 0.2778 - accuracy: 0.5062 - val_loss: 0.2762 - val_accuracy: 0.5093\n",
      "Epoch 368/500\n",
      "577/577 [==============================] - 1s 868us/step - loss: 0.2773 - accuracy: 0.5057 - val_loss: 0.2780 - val_accuracy: 0.5046\n",
      "Epoch 369/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2784 - accuracy: 0.5032 - val_loss: 0.2774 - val_accuracy: 0.5059\n",
      "Epoch 370/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2775 - accuracy: 0.5083 - val_loss: 0.2772 - val_accuracy: 0.5065\n",
      "Epoch 371/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2769 - accuracy: 0.5110 - val_loss: 0.2771 - val_accuracy: 0.5098\n",
      "Epoch 372/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2768 - accuracy: 0.5097 - val_loss: 0.2768 - val_accuracy: 0.5078\n",
      "Epoch 373/500\n",
      "577/577 [==============================] - 1s 961us/step - loss: 0.2774 - accuracy: 0.5068 - val_loss: 0.2766 - val_accuracy: 0.5046\n",
      "Epoch 374/500\n",
      "577/577 [==============================] - 0s 817us/step - loss: 0.2771 - accuracy: 0.5092 - val_loss: 0.2755 - val_accuracy: 0.5152\n",
      "Epoch 375/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2774 - accuracy: 0.5082 - val_loss: 0.2758 - val_accuracy: 0.5098\n",
      "Epoch 376/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2764 - accuracy: 0.5101 - val_loss: 0.2766 - val_accuracy: 0.5095\n",
      "Epoch 377/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2768 - accuracy: 0.5075 - val_loss: 0.2770 - val_accuracy: 0.5065\n",
      "Epoch 378/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2769 - accuracy: 0.5102 - val_loss: 0.2772 - val_accuracy: 0.5024\n",
      "Epoch 379/500\n",
      "577/577 [==============================] - 1s 943us/step - loss: 0.2771 - accuracy: 0.5117 - val_loss: 0.2772 - val_accuracy: 0.5076\n",
      "Epoch 380/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2771 - accuracy: 0.5080 - val_loss: 0.2770 - val_accuracy: 0.5061\n",
      "Epoch 381/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2771 - accuracy: 0.5078 - val_loss: 0.2767 - val_accuracy: 0.5132\n",
      "Epoch 382/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2771 - accuracy: 0.5109 - val_loss: 0.2766 - val_accuracy: 0.5145\n",
      "Epoch 383/500\n",
      "577/577 [==============================] - 0s 843us/step - loss: 0.2769 - accuracy: 0.5089 - val_loss: 0.2754 - val_accuracy: 0.5113\n",
      "Epoch 384/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2769 - accuracy: 0.5113 - val_loss: 0.2756 - val_accuracy: 0.5074\n",
      "Epoch 385/500\n",
      "577/577 [==============================] - 1s 953us/step - loss: 0.2775 - accuracy: 0.5091 - val_loss: 0.2756 - val_accuracy: 0.5065\n",
      "Epoch 386/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2767 - accuracy: 0.5126 - val_loss: 0.2755 - val_accuracy: 0.5074\n",
      "Epoch 387/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2774 - accuracy: 0.5063 - val_loss: 0.2761 - val_accuracy: 0.5098\n",
      "Epoch 388/500\n",
      "577/577 [==============================] - 0s 844us/step - loss: 0.2768 - accuracy: 0.5093 - val_loss: 0.2770 - val_accuracy: 0.5063\n",
      "Epoch 389/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2772 - accuracy: 0.5088 - val_loss: 0.2757 - val_accuracy: 0.5067\n",
      "Epoch 390/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2769 - accuracy: 0.5104 - val_loss: 0.2758 - val_accuracy: 0.5080\n",
      "Epoch 391/500\n",
      "577/577 [==============================] - 1s 971us/step - loss: 0.2764 - accuracy: 0.5119 - val_loss: 0.2757 - val_accuracy: 0.5059\n",
      "Epoch 392/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2775 - accuracy: 0.5032 - val_loss: 0.2769 - val_accuracy: 0.5085\n",
      "Epoch 393/500\n",
      "577/577 [==============================] - 0s 815us/step - loss: 0.2768 - accuracy: 0.5081 - val_loss: 0.2776 - val_accuracy: 0.5035\n",
      "Epoch 394/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2768 - accuracy: 0.5088 - val_loss: 0.2768 - val_accuracy: 0.5115\n",
      "Epoch 395/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2772 - accuracy: 0.5080 - val_loss: 0.2767 - val_accuracy: 0.5074\n",
      "Epoch 396/500\n",
      "577/577 [==============================] - 0s 821us/step - loss: 0.2765 - accuracy: 0.5094 - val_loss: 0.2767 - val_accuracy: 0.5059\n",
      "Epoch 397/500\n",
      "577/577 [==============================] - 1s 953us/step - loss: 0.2766 - accuracy: 0.5103 - val_loss: 0.2754 - val_accuracy: 0.5132\n",
      "Epoch 398/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2766 - accuracy: 0.5110 - val_loss: 0.2762 - val_accuracy: 0.5022\n",
      "Epoch 399/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2766 - accuracy: 0.5082 - val_loss: 0.2764 - val_accuracy: 0.5100\n",
      "Epoch 400/500\n",
      "577/577 [==============================] - 0s 821us/step - loss: 0.2764 - accuracy: 0.5082 - val_loss: 0.2762 - val_accuracy: 0.5063\n",
      "Epoch 401/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2768 - accuracy: 0.5115 - val_loss: 0.2767 - val_accuracy: 0.5072\n",
      "Epoch 402/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2769 - accuracy: 0.5087 - val_loss: 0.2758 - val_accuracy: 0.5139\n",
      "Epoch 403/500\n",
      "577/577 [==============================] - 1s 980us/step - loss: 0.2771 - accuracy: 0.5101 - val_loss: 0.2766 - val_accuracy: 0.5054\n",
      "Epoch 404/500\n",
      "577/577 [==============================] - 0s 814us/step - loss: 0.2774 - accuracy: 0.5070 - val_loss: 0.2771 - val_accuracy: 0.5082\n",
      "Epoch 405/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2774 - accuracy: 0.5075 - val_loss: 0.2763 - val_accuracy: 0.5080\n",
      "Epoch 406/500\n",
      "577/577 [==============================] - 0s 803us/step - loss: 0.2769 - accuracy: 0.5094 - val_loss: 0.2762 - val_accuracy: 0.5039\n",
      "Epoch 407/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2768 - accuracy: 0.5096 - val_loss: 0.2765 - val_accuracy: 0.5098\n",
      "Epoch 408/500\n",
      "577/577 [==============================] - 0s 839us/step - loss: 0.2768 - accuracy: 0.5098 - val_loss: 0.2758 - val_accuracy: 0.5080\n",
      "Epoch 409/500\n",
      "577/577 [==============================] - 1s 996us/step - loss: 0.2766 - accuracy: 0.5083 - val_loss: 0.2778 - val_accuracy: 0.5037\n",
      "Epoch 410/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2763 - accuracy: 0.5118 - val_loss: 0.2756 - val_accuracy: 0.5091\n",
      "Epoch 411/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2771 - accuracy: 0.5095 - val_loss: 0.2760 - val_accuracy: 0.5052\n",
      "Epoch 412/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2768 - accuracy: 0.5067 - val_loss: 0.2758 - val_accuracy: 0.5095\n",
      "Epoch 413/500\n",
      "577/577 [==============================] - 0s 842us/step - loss: 0.2766 - accuracy: 0.5120 - val_loss: 0.2782 - val_accuracy: 0.5033\n",
      "Epoch 414/500\n",
      "577/577 [==============================] - 1s 954us/step - loss: 0.2767 - accuracy: 0.5106 - val_loss: 0.2770 - val_accuracy: 0.5063\n",
      "Epoch 415/500\n",
      "577/577 [==============================] - 0s 839us/step - loss: 0.2768 - accuracy: 0.5076 - val_loss: 0.2757 - val_accuracy: 0.5100\n",
      "Epoch 416/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2764 - accuracy: 0.5111 - val_loss: 0.2748 - val_accuracy: 0.5104\n",
      "Epoch 417/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2768 - accuracy: 0.5093 - val_loss: 0.2765 - val_accuracy: 0.5078\n",
      "Epoch 418/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2763 - accuracy: 0.5117 - val_loss: 0.2760 - val_accuracy: 0.5104\n",
      "Epoch 419/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2765 - accuracy: 0.5100 - val_loss: 0.2751 - val_accuracy: 0.5052\n",
      "Epoch 420/500\n",
      "577/577 [==============================] - 1s 972us/step - loss: 0.2767 - accuracy: 0.5120 - val_loss: 0.2754 - val_accuracy: 0.5132\n",
      "Epoch 421/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2775 - accuracy: 0.5057 - val_loss: 0.2759 - val_accuracy: 0.5069\n",
      "Epoch 422/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2762 - accuracy: 0.5104 - val_loss: 0.2758 - val_accuracy: 0.5111\n",
      "Epoch 423/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2768 - accuracy: 0.5065 - val_loss: 0.2758 - val_accuracy: 0.5072\n",
      "Epoch 424/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2771 - accuracy: 0.5112 - val_loss: 0.2754 - val_accuracy: 0.5126\n",
      "Epoch 425/500\n",
      "577/577 [==============================] - 1s 942us/step - loss: 0.2769 - accuracy: 0.5052 - val_loss: 0.2769 - val_accuracy: 0.5078\n",
      "Epoch 426/500\n",
      "577/577 [==============================] - 0s 823us/step - loss: 0.2764 - accuracy: 0.5111 - val_loss: 0.2758 - val_accuracy: 0.5117\n",
      "Epoch 427/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2769 - accuracy: 0.5119 - val_loss: 0.2758 - val_accuracy: 0.5100\n",
      "Epoch 428/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2765 - accuracy: 0.5146 - val_loss: 0.2751 - val_accuracy: 0.5100\n",
      "Epoch 429/500\n",
      "577/577 [==============================] - 0s 847us/step - loss: 0.2770 - accuracy: 0.5091 - val_loss: 0.2756 - val_accuracy: 0.5069\n",
      "Epoch 430/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2768 - accuracy: 0.5069 - val_loss: 0.2748 - val_accuracy: 0.5106\n",
      "Epoch 431/500\n",
      "577/577 [==============================] - 1s 975us/step - loss: 0.2773 - accuracy: 0.5107 - val_loss: 0.2753 - val_accuracy: 0.5141\n",
      "Epoch 432/500\n",
      "577/577 [==============================] - 0s 832us/step - loss: 0.2768 - accuracy: 0.5084 - val_loss: 0.2767 - val_accuracy: 0.5067\n",
      "Epoch 433/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2764 - accuracy: 0.5092 - val_loss: 0.2762 - val_accuracy: 0.5100\n",
      "Epoch 434/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2771 - accuracy: 0.5116 - val_loss: 0.2768 - val_accuracy: 0.5054\n",
      "Epoch 435/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2774 - accuracy: 0.5098 - val_loss: 0.2744 - val_accuracy: 0.5098\n",
      "Epoch 436/500\n",
      "577/577 [==============================] - 0s 845us/step - loss: 0.2763 - accuracy: 0.5123 - val_loss: 0.2769 - val_accuracy: 0.5065\n",
      "Epoch 437/500\n",
      "577/577 [==============================] - 1s 959us/step - loss: 0.2761 - accuracy: 0.5144 - val_loss: 0.2762 - val_accuracy: 0.5108\n",
      "Epoch 438/500\n",
      "577/577 [==============================] - 0s 842us/step - loss: 0.2767 - accuracy: 0.5116 - val_loss: 0.2748 - val_accuracy: 0.5173\n",
      "Epoch 439/500\n",
      "577/577 [==============================] - 0s 821us/step - loss: 0.2774 - accuracy: 0.5099 - val_loss: 0.2766 - val_accuracy: 0.5072\n",
      "Epoch 440/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2763 - accuracy: 0.5122 - val_loss: 0.2755 - val_accuracy: 0.5156\n",
      "Epoch 441/500\n",
      "577/577 [==============================] - 0s 837us/step - loss: 0.2769 - accuracy: 0.5078 - val_loss: 0.2766 - val_accuracy: 0.5048\n",
      "Epoch 442/500\n",
      "577/577 [==============================] - 1s 962us/step - loss: 0.2769 - accuracy: 0.5080 - val_loss: 0.2762 - val_accuracy: 0.5078\n",
      "Epoch 443/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2766 - accuracy: 0.5136 - val_loss: 0.2760 - val_accuracy: 0.5026\n",
      "Epoch 444/500\n",
      "577/577 [==============================] - 0s 822us/step - loss: 0.2774 - accuracy: 0.5053 - val_loss: 0.2757 - val_accuracy: 0.5069\n",
      "Epoch 445/500\n",
      "577/577 [==============================] - 0s 838us/step - loss: 0.2767 - accuracy: 0.5090 - val_loss: 0.2762 - val_accuracy: 0.5121\n",
      "Epoch 446/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2765 - accuracy: 0.5101 - val_loss: 0.2759 - val_accuracy: 0.5076\n",
      "Epoch 447/500\n",
      "577/577 [==============================] - 1s 957us/step - loss: 0.2762 - accuracy: 0.5093 - val_loss: 0.2760 - val_accuracy: 0.5093\n",
      "Epoch 448/500\n",
      "577/577 [==============================] - 0s 829us/step - loss: 0.2773 - accuracy: 0.5068 - val_loss: 0.2755 - val_accuracy: 0.5082\n",
      "Epoch 449/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2771 - accuracy: 0.5094 - val_loss: 0.2750 - val_accuracy: 0.5087\n",
      "Epoch 450/500\n",
      "577/577 [==============================] - 0s 842us/step - loss: 0.2768 - accuracy: 0.5093 - val_loss: 0.2774 - val_accuracy: 0.5043\n",
      "Epoch 451/500\n",
      "577/577 [==============================] - 0s 828us/step - loss: 0.2759 - accuracy: 0.5113 - val_loss: 0.2764 - val_accuracy: 0.5093\n",
      "Epoch 452/500\n",
      "577/577 [==============================] - 1s 959us/step - loss: 0.2771 - accuracy: 0.5101 - val_loss: 0.2751 - val_accuracy: 0.5078\n",
      "Epoch 453/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2762 - accuracy: 0.5102 - val_loss: 0.2758 - val_accuracy: 0.5069\n",
      "Epoch 454/500\n",
      "577/577 [==============================] - 0s 834us/step - loss: 0.2769 - accuracy: 0.5089 - val_loss: 0.2769 - val_accuracy: 0.5091\n",
      "Epoch 455/500\n",
      "577/577 [==============================] - 0s 831us/step - loss: 0.2762 - accuracy: 0.5127 - val_loss: 0.2747 - val_accuracy: 0.5119\n",
      "Epoch 456/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2763 - accuracy: 0.5109 - val_loss: 0.2757 - val_accuracy: 0.5078\n",
      "Epoch 457/500\n",
      "577/577 [==============================] - 1s 967us/step - loss: 0.2765 - accuracy: 0.5094 - val_loss: 0.2757 - val_accuracy: 0.5154\n",
      "Epoch 458/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2757 - accuracy: 0.5127 - val_loss: 0.2756 - val_accuracy: 0.5082\n",
      "Epoch 459/500\n",
      "577/577 [==============================] - 0s 814us/step - loss: 0.2766 - accuracy: 0.5092 - val_loss: 0.2758 - val_accuracy: 0.5113\n",
      "Epoch 460/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2760 - accuracy: 0.5125 - val_loss: 0.2774 - val_accuracy: 0.5043\n",
      "Epoch 461/500\n",
      "577/577 [==============================] - 0s 827us/step - loss: 0.2775 - accuracy: 0.5113 - val_loss: 0.2766 - val_accuracy: 0.5080\n",
      "Epoch 462/500\n",
      "577/577 [==============================] - 1s 977us/step - loss: 0.2766 - accuracy: 0.5089 - val_loss: 0.2756 - val_accuracy: 0.5108\n",
      "Epoch 463/500\n",
      "577/577 [==============================] - 0s 842us/step - loss: 0.2760 - accuracy: 0.5106 - val_loss: 0.2776 - val_accuracy: 0.5069\n",
      "Epoch 464/500\n",
      "577/577 [==============================] - 0s 839us/step - loss: 0.2765 - accuracy: 0.5088 - val_loss: 0.2769 - val_accuracy: 0.5063\n",
      "Epoch 465/500\n",
      "577/577 [==============================] - 0s 830us/step - loss: 0.2763 - accuracy: 0.5104 - val_loss: 0.2769 - val_accuracy: 0.5052\n",
      "Epoch 466/500\n",
      "577/577 [==============================] - 0s 842us/step - loss: 0.2765 - accuracy: 0.5068 - val_loss: 0.2757 - val_accuracy: 0.5126\n",
      "Epoch 467/500\n",
      "577/577 [==============================] - 1s 975us/step - loss: 0.2770 - accuracy: 0.5090 - val_loss: 0.2768 - val_accuracy: 0.5072\n",
      "Epoch 468/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2770 - accuracy: 0.5101 - val_loss: 0.2764 - val_accuracy: 0.5061\n",
      "Epoch 469/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2767 - accuracy: 0.5058 - val_loss: 0.2749 - val_accuracy: 0.5056\n",
      "Epoch 470/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2765 - accuracy: 0.5128 - val_loss: 0.2762 - val_accuracy: 0.5091\n",
      "Epoch 471/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2771 - accuracy: 0.5083 - val_loss: 0.2761 - val_accuracy: 0.5115\n",
      "Epoch 472/500\n",
      "577/577 [==============================] - 1s 966us/step - loss: 0.2769 - accuracy: 0.5068 - val_loss: 0.2775 - val_accuracy: 0.5046\n",
      "Epoch 473/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2761 - accuracy: 0.5120 - val_loss: 0.2757 - val_accuracy: 0.5056\n",
      "Epoch 474/500\n",
      "577/577 [==============================] - 0s 839us/step - loss: 0.2764 - accuracy: 0.5101 - val_loss: 0.2764 - val_accuracy: 0.5108\n",
      "Epoch 475/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2755 - accuracy: 0.5132 - val_loss: 0.2746 - val_accuracy: 0.5141\n",
      "Epoch 476/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2759 - accuracy: 0.5144 - val_loss: 0.2759 - val_accuracy: 0.5117\n",
      "Epoch 477/500\n",
      "577/577 [==============================] - 1s 956us/step - loss: 0.2764 - accuracy: 0.5098 - val_loss: 0.2759 - val_accuracy: 0.5111\n",
      "Epoch 478/500\n",
      "577/577 [==============================] - 0s 846us/step - loss: 0.2765 - accuracy: 0.5119 - val_loss: 0.2761 - val_accuracy: 0.5048\n",
      "Epoch 479/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2758 - accuracy: 0.5139 - val_loss: 0.2754 - val_accuracy: 0.5074\n",
      "Epoch 480/500\n",
      "577/577 [==============================] - 0s 825us/step - loss: 0.2765 - accuracy: 0.5121 - val_loss: 0.2778 - val_accuracy: 0.5041\n",
      "Epoch 481/500\n",
      "577/577 [==============================] - 0s 818us/step - loss: 0.2765 - accuracy: 0.5066 - val_loss: 0.2766 - val_accuracy: 0.5059\n",
      "Epoch 482/500\n",
      "577/577 [==============================] - 1s 974us/step - loss: 0.2762 - accuracy: 0.5087 - val_loss: 0.2751 - val_accuracy: 0.5117\n",
      "Epoch 483/500\n",
      "577/577 [==============================] - 0s 824us/step - loss: 0.2771 - accuracy: 0.5075 - val_loss: 0.2759 - val_accuracy: 0.5108\n",
      "Epoch 484/500\n",
      "577/577 [==============================] - 0s 802us/step - loss: 0.2760 - accuracy: 0.5095 - val_loss: 0.2765 - val_accuracy: 0.5041\n",
      "Epoch 485/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2768 - accuracy: 0.5100 - val_loss: 0.2759 - val_accuracy: 0.5113\n",
      "Epoch 486/500\n",
      "577/577 [==============================] - 0s 819us/step - loss: 0.2766 - accuracy: 0.5074 - val_loss: 0.2760 - val_accuracy: 0.5098\n",
      "Epoch 487/500\n",
      "577/577 [==============================] - 1s 977us/step - loss: 0.2759 - accuracy: 0.5134 - val_loss: 0.2750 - val_accuracy: 0.5089\n",
      "Epoch 488/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2768 - accuracy: 0.5093 - val_loss: 0.2777 - val_accuracy: 0.5013\n",
      "Epoch 489/500\n",
      "577/577 [==============================] - 0s 861us/step - loss: 0.2761 - accuracy: 0.5128 - val_loss: 0.2768 - val_accuracy: 0.5048\n",
      "Epoch 490/500\n",
      "577/577 [==============================] - 0s 847us/step - loss: 0.2759 - accuracy: 0.5097 - val_loss: 0.2771 - val_accuracy: 0.5059\n",
      "Epoch 491/500\n",
      "577/577 [==============================] - 0s 833us/step - loss: 0.2760 - accuracy: 0.5118 - val_loss: 0.2757 - val_accuracy: 0.5076\n",
      "Epoch 492/500\n",
      "577/577 [==============================] - 1s 971us/step - loss: 0.2766 - accuracy: 0.5085 - val_loss: 0.2750 - val_accuracy: 0.5108\n",
      "Epoch 493/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2760 - accuracy: 0.5131 - val_loss: 0.2757 - val_accuracy: 0.5069\n",
      "Epoch 494/500\n",
      "577/577 [==============================] - 0s 841us/step - loss: 0.2758 - accuracy: 0.5119 - val_loss: 0.2754 - val_accuracy: 0.5093\n",
      "Epoch 495/500\n",
      "577/577 [==============================] - 0s 835us/step - loss: 0.2775 - accuracy: 0.5084 - val_loss: 0.2757 - val_accuracy: 0.5065\n",
      "Epoch 496/500\n",
      "577/577 [==============================] - 0s 826us/step - loss: 0.2763 - accuracy: 0.5121 - val_loss: 0.2764 - val_accuracy: 0.5063\n",
      "Epoch 497/500\n",
      "577/577 [==============================] - 1s 968us/step - loss: 0.2769 - accuracy: 0.5088 - val_loss: 0.2759 - val_accuracy: 0.5082\n",
      "Epoch 498/500\n",
      "577/577 [==============================] - 0s 836us/step - loss: 0.2763 - accuracy: 0.5105 - val_loss: 0.2752 - val_accuracy: 0.5091\n",
      "Epoch 499/500\n",
      "577/577 [==============================] - 0s 820us/step - loss: 0.2764 - accuracy: 0.5079 - val_loss: 0.2761 - val_accuracy: 0.5076\n",
      "Epoch 500/500\n",
      "577/577 [==============================] - 0s 844us/step - loss: 0.2765 - accuracy: 0.5114 - val_loss: 0.2750 - val_accuracy: 0.5069\n",
      "145/145 [==============================] - 0s 466us/step - loss: 0.2750 - accuracy: 0.5069\n",
      "Precisión del modelo: 0.5069383978843689\n",
      "577/577 [==============================] - 0s 401us/step\n",
      "Predicciones:\n",
      "[[6.2592584e-01 6.7565024e-02 2.3888725e-01 ... 6.1167903e-02\n",
      "  5.2235909e-03 8.6715136e-04]\n",
      " [8.6669199e-02 2.1040768e-03 2.4475540e-01 ... 1.6996478e-01\n",
      "  2.7479538e-01 4.7173010e-08]\n",
      " [3.6829452e-03 9.0941989e-01 1.5672982e-02 ... 1.6238078e-02\n",
      "  4.7679787e-05 1.7897283e-01]\n",
      " ...\n",
      " [1.5808359e-01 2.7083394e-01 2.3263916e-01 ... 4.2521913e-02\n",
      "  6.5125083e-03 1.5882858e-04]\n",
      " [1.9564834e-01 1.5533246e-02 1.3769776e-01 ... 2.8336981e-01\n",
      "  1.5634653e-01 4.1971365e-03]\n",
      " [1.7569855e-02 3.4589984e-02 8.8143237e-02 ... 3.7691513e-01\n",
      "  3.6370224e-01 1.5727257e-03]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Modelo de red neuronal\n",
    "model = models.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(5,), name='Layer_in'),    \n",
    "#    layers.Dense(32, activation='relu', input_shape=(5,), kernel_regularizer=l2(0.01),name='Layer_in'),        \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.1),\n",
    "#    layers.Dense(32, activation='relu'),\n",
    "#    layers.BatchNormalization(),\n",
    "#    layers.Dropout(0.1),\n",
    "#    layers.Dense(128, activation='relu'),\n",
    "#    layers.BatchNormalization(),\n",
    "#    layers.Dropout(0.1),\n",
    "#    layers.Dense(264, activation='relu'),\n",
    "#    layers.BatchNormalization(),\n",
    "#    layers.Dropout(0.1),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "#    layers.BatchNormalization(),\n",
    "#    layers.Dropout(0.1),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "#    layers.BatchNormalization(),\n",
    "#    layers.Dropout(0.5),\n",
    "    layers.Dense(7, activation='sigmoid', name='Layer_out')  # Capa de salida con 7 neuronas para las 7 categorías\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Función de pérdida para clasificación multiclase\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Función para detener el entrenamiento si durante varias épocas no hay mejora\n",
    "#early_stopping = EarlyStopping(monitor='val_accuracy', patience=50, mode='max')\n",
    "\n",
    "# Entrenar el modelo\n",
    "#H = model.fit(X_training, y_training_oh, validation_data=(X_test, y_test_oh), epochs=10000, callbacks=[early_stopping])\n",
    "H = model.fit(X_training, y_training_oh, validation_data=(X_test, y_test_oh), epochs=500)\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test_oh)\n",
    "print(\"Precisión del modelo:\", accuracy)\n",
    "\n",
    "# Hacer predicciones\n",
    "predicciones = model.predict(X_training)\n",
    "print(\"Predicciones:\")\n",
    "print(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "27cfb8e6-9d61-4758-a742-5c58e9f2226d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_107\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Layer_in (Dense)            (None, 32)                192       \n",
      "                                                                 \n",
      " batch_normalization_83 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " dense_290 (Dense)           (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_291 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " Layer_out (Dense)           (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4743 (18.53 KB)\n",
      "Trainable params: 4679 (18.28 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "af0ee80b-01a1-4970-9757-64344ed5b3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2e2191070>"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAAHMCAYAAADWN6wLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC4KklEQVR4nOzdd3xT9f4/8NfJHm2T7pbuAS2U0rL3KHsvERDHBRUUx71evaLiQLni/Xm9+sXruHrVK+ICZW+QvQuFMsqGttC905E0+/z+CDlNSFpa0jaFvp+PBw/aMz/5JE3eeX8Ww7IsC0IIIYSQdorn7gIQQgghhLgTBUOEEEIIadcoGCKEEEJIu0bBECGEEELaNQqGCCGEENKuUTBECCGEkHaNgiFCCCGEtGsUDBFCCCGkXaNgiBBCCCHtGgVDhLQChmEwbNgwl68zbNgwMAzjeoFImxQZGYnIyEh3F4OQdoeCIdIuMAzTpH8rVqxwd5HvG/v372+2YI/cu59//pl7/e7atcvdxSHkviJwdwEIaQ1Llixx2LZ8+XJUVlbiL3/5C5RKpd2+5OTkZr3/pUuXIJPJXL7OypUrodFomqFE5EHz3//+FwzDgGVZ/Pe//8Xo0aPdXSRC7hsMLdRK2qvIyEjcvHkTWVlZ1DThgv379yMlJQVDhw7F/v373V2c+5r1dZidnd2k865cuYL4+HiMHDkSFRUVOHfuHHJychAYGNj8hSTkAUTNZITcwdovR6/XY+nSpYiLi4NYLMbcuXMBAJWVlfjoo48wfPhwhIaGQiQSwd/fH5MnT8axY8ecXtNZM9K7774LhmGwf/9+rFmzBn369IFMJoOPjw9mz56NvLy8estmy9pM9e677+LMmTOYMGEClEolZDIZhg4diqNHjzotU0FBAebNm4eAgABIpVIkJyfjhx9+sLteSygoKMDzzz+PyMhIru6mT5+OU6dOORyr1+vx73//Gz169IC3tzdkMhkiIyMxZcoU7N692+7YQ4cOYdKkSQgNDYVYLEZQUBD69euH9957r1Hl0uv1+PzzzzF+/HhERERALBbDx8cHI0eOxPbt252eY+3jo1ar8eqrryI8PBxisRixsbH48MMP4ey7Jsuy+Pzzz5GQkACJRIKQkBC88MILqKysbFQ5nfnmm28AAPPmzcPcuXNhMBgabOotLy/Hm2++ia5du0Imk0GhUCApKQmvv/461Gr1PR3bUH8n29e6LevfRWFhIZ5++mmEhISAz+dzZb969Spef/119OrVC/7+/hCLxYiIiMCCBQuQm5tb7+PbtWsXJk2ahICAAIjFYoSFhdm9Znbu3AmGYTBv3jyn5+t0Ovj5+cHPzw86na7e+5AHBzWTEVKPhx56CCdPnsS4ceMwdepUBAQEALA0eb355psYMmQIJkyYAG9vb9y6dQubNm3C9u3bsXnzZowdO7bR9/nyyy+xadMmTJ48GUOHDkVqaipWr16Ns2fP4syZMxCLxY26TlpaGv75z3+if//+ePrpp3Hr1i2sXbsWI0aMwJkzZxAXF8cdW1xcjP79++PmzZsYMmQIBgwYgMLCQjz33HMt2rySlZWFQYMGIT8/H8OHD8cjjzyCnJwc/P7779i6dSvWrl2LiRMncsfPnTsXv/76K7p27YonnngCUqkU+fn5OHz4MHbs2IGRI0cCAHbs2IEJEybAy8sLkydPRkhICMrLy3Hp0iV8+eWXTptJ71ReXo6//OUvGDBgAEaNGgV/f38UFBRg8+bNGD9+PL755hs8/fTTDucZDAaMGTMG+fn5GDduHAQCATZs2IDXX38dWq3W4d4vvfQS/v3vfyM4OBgLFiyAUCjExo0bkZqaCr1eD5FI1KQ61ev1+OGHH6BQKDBt2jTU1tbilVdewbfffotFixY5BM9ZWVlISUnBzZs30bNnTyxcuBBmsxlXr17F//3f/+HZZ5+FXC5v8rH3qry8HP369YOHhwemT58OHo/HZbTWrVuHr776CikpKRgwYABEIhEuXLiAb7/9Fps3b0ZaWhpCQkLsrrdkyRIsXboUHh4emDp1KsLCwpCfn4+jR4/ip59+wsiRIzF69GjExMTgt99+w/Lly6FQKOyusXbtWpSVleGVV15p9N8fuc+xhLRTERERLAA2KyvLbvvQoUNZAGxiYiJbUlLicJ5KpXK6PScnhw0ODmbj4+Md9gFghw4dardtyZIlLADW09OTPXfunN2+Rx55hAXArl692mnZbO3bt48FwAJgv//+e7t9X331FQuAXbhwod32J598kgXALlq0yG77mTNnWJFIxAJglyxZ4vA4nLHe/87H58zo0aNZAOz7779vt/3IkSMsn89nfXx82OrqapZlLfXMMAzbs2dP1mg0OlyrtLSU+3n69OksAPbMmTMOxzl7rpzRarVsTk6Ow3aVSsUmJCSw3t7erEajsdtnfQ2NGzfObl9RURGrUChYhULB6vV6u8cJgI2JiWHLysq47bW1tWy/fv1YAGxERESjymv166+/sgDYBQsWcNseeughFgC7e/duh+P79+/PAmA/+OADh30lJSVsbW3tPR0bERFRb9mtr/V9+/bZbbe+bh9//HHWYDA4nJebm8tqtVqH7Tt37mR5PB777LPPOmwHwEZFRbG5ubkO59k+vx999BELgP3ss88cjrP+nV25csXp4yEPHgqGSLt1t2Bow4YNTb7miy++yAJgb968abe9oWDozTffdLjO3r17WQDsK6+84rRstqzByMCBAx2uo9frWYFAwPbs2ZPbptPpWKlUyioUCraqqsrhnKeffrpFgqGcnBwWABseHm4XIFg99thjLAD2hx9+YFmWZSsrK1kA7IABA1iz2dzgta3BUEt9eH388ccsAPbAgQN2262voWvXrjmc88QTT7AA2PPnz3PbrHX7v//9z+F4az02NRgaPnw4C4A9evQot23z5s0sAHbmzJl2x6alpbEA2OTkZNZkMjV43aYcy7L3HgyJRCK2qKjorte/U2JiIhsVFWW3beLEiSwAdt26dXc9v7S0lJVIJGzXrl3ttl++fJkFwKakpDS5TOT+RX2GCKlHnz596t135MgRzJw5E2FhYRCLxdyQ5s8++wwAnPb3qU+vXr0ctoWFhQEAKioqXLqOUChEYGCg3XWuXLmC2tpadOvWDZ6eng7nDBo0qNH3bIr09HQAwODBgyEUCh32Dx8+3O44Ly8vTJo0CUePHkVycjKWLl2Kffv2OR1N9+ijjwIA+vbti2effRarV69usE9JfS5cuIC5c+ciOjoaUqmUe15feeUVAM6fV4VCgdjYWIftzp7D06dPAwCGDh3qcPygQYPA5/ObVN7r169j3759iIuLQ//+/bntY8eORVBQEDZs2IDS0lJu+/HjxwEAY8aMAY/X8Nt/U451RWRkJNcEfSeWZbmmLX9/fwgEAu45OX/+vMPzcfz4cTAM06hmal9fX8ycORMZGRl2/er++9//AgCeffZZFx4Vud9QnyFC6hEUFOR0+/r16zFjxgxIJBKMGjUKMTExkMvl4PF42L9/Pw4cONCkTpd3DusHAIHA8qdpMplcuo71WrbXsXbUrW+kUUuNQLLeNzg42Ol+63aVSsVtW716NT788EP88ssvXN8biUSCGTNm4F//+hdX1unTp2PLli34+OOP8b///Q9ff/01AKBnz574xz/+gVGjRt21fMePH8fw4cNhNBoxYsQITJ48GV5eXuDxeDhz5gw2btzo9HltqN4BNLruBQIB/Pz87lpOW9988w1YluU699te69FHH8XHH3+MFStW4G9/+xuAurq9s5+NM0051hX1/Z0BwMsvv4zly5cjODgYY8aMQUhICKRSKQBgxYoVuHnzpt3xKpUK3t7e3DF389xzz2HlypX4+uuvMWDAAOh0Ovzwww8ICAjAtGnT7v1BkfsOBUOE1KO+mZ7ffvttiEQipKWloXPnznb7nnnmGRw4cKA1infPvLy8AABFRUVO99e33VXWTqqFhYVO9xcUFNgdBwBSqRTvvvsu3n33XeTk5ODgwYNYsWIFfvrpJ2RnZ+PQoUPcsRMmTMCECROgVquRmpqKLVu24D//+Q8mTpyI9PR0dOnSpcHyvf/++6itrcW+ffscRv794x//wMaNG+/lYduxPraioiJER0fb7TMajSgtLUVoaGijrmU7YuyNN97AG2+84fS4b775hguGrIFbYzKXTTkWAHg8HvR6vdN9tgHuner7OysuLsa///1vdO3aFUePHnXIYv76669Oy1xWVoba2tpGBUR9+/ZF9+7duY7U27dvR1lZGV577TWn2Uvy4KJmMkKa6Pr16+jSpYtDIGQ2m3H48GE3larx4uPjIZVKce7cOVRXVzvsb6nH0L17d+76RqPRYf++ffsAAD169HB6flhYGB599FHs3LkTsbGxOHz4MMrKyhyOk8vlGD58OD755BMsXrwYer2+3qHxtq5fvw4fHx+nM2k3V4BrfWzOrnf48OEmZQI3btyI4uJixMXF4amnnnL6Lzo6GlevXuXu169fPwCWoeVms7nB6zflWADw9vZGUVERDAaDw760tLRGPy6rzMxMmM1mjB492iEQys3NRWZmptMysyyLHTt2NPo+zz33HLRaLVauXMlNXLlgwYIml5fc3ygYIqSJIiMjce3aNeTn53PbWJbFu+++i4sXL7qxZI0jEokwa9YsVFZW4v3337fbd/bsWaxcubJF7hsaGopRo0YhOzsby5cvt9uXmpqKX375Bd7e3lzzRElJCc6fP+9wHbVajZqaGggEAm4Y+sGDB50GWNYsV2Nm/46MjER5eTnOnTtnt/27777Dzp07G/UY78banLVs2TKUl5dz27Vabb2ZnfpY+7YsXboU3377rdN/ixcvtju2Z8+eGDBgAM6cOYMPP/zQ4ZplZWXQarVNPhaw9LEzGo34/vvv7Y5bsWIFjhw50qTHBtRNQHlnkFhTU4P58+c7fb5ffPFFAMArr7ziNKPlbNucOXOgUCjwz3/+EwcOHMCoUaMcsnbkwUfNZIQ00V//+lc8++yz6N69Ox566CEIhUIcOXIEFy9exKRJk7B582Z3F/Gu/t//+3/Yu3cv/vnPfyI1NRUDBgxAQUEBfvvtN4wfPx4bNmxocqfZy5cvO/RdsQoPD8fSpUvx1VdfYeDAgXj11Vexa9cu9OrVi5tniMfj4fvvv+eyAHl5eejevTsSExPRrVs3hIWFoaqqClu2bEFhYSH+/Oc/c8f++c9/Rl5eHgYOHMhN5njq1Cns3bsXERERmD179l3L/9JLL2Hnzp0YNGgQZs6cCYVCgbS0NBw+fBgzZszAmjVrmlQfzgwcOBAvvvgiPvvsM3Tt2hUzZszg5hny9vautz/VnbKysrB79274+flh6tSp9R43a9YsvPTSS1i7di0+++wz+Pj44KeffsKwYcOwePFirF27FsOGDQPLsrh27Rp27dqFy5cvc4FIU4598cUX8f3332PhwoXYs2cPwsLCcObMGRw7dgwTJ07Eli1bmlRXQUFBmD17NlatWoXk5GSMHj0alZWV+OOPPyCRSJCcnIwzZ87YnTN69Gi89dZbeP/999G5c2dunqGioiIcPnwY/fr1c5iMUiaT4U9/+hP+/e9/A7A0dZN2yJ1D2Qhxp7sNrW/I999/zyYlJbEymYz19fVlp06dyp47d67BIcT1Da2/81iWZdmsrCwWAPunP/3prmWzDsmubyh8fUOec3Nz2SeeeIL18/NjJRIJm5SUxK5YsYL9/fffWQDs//3f/zVYB3fev6F/SUlJdvd99tln2fDwcFYoFLK+vr7slClT2BMnTthdt6Kign3vvffYlJQUtkOHDqxIJGKDgoLYoUOHsr/88ovdcPvVq1ezs2fPZmNjY1m5XM56enqyCQkJ7OLFi9ni4uJGPQ6WtQxJ79u3L+vh4cEqFAp21KhR7IEDB9jvv//e6TxO9zKc3Gw2s5999hkbHx/PikQiNjg4mH3uuedYlUrV4PVsLV68mAXA/vWvf73rsfPnz2cBsJ988gm3rbS0lF20aBHbqVMnViwWswqFgk1KSmIXL17MqtVqu/ObcuyhQ4fYwYMHs1KplPX09GTHjx/Pnj17tkl/F7bUajW7ePFiNiYmhhWLxWxoaCj73HPPsaWlpQ3+nW7dupUdM2YM6+3tzYpEIjY0NJSdOnUqu2fPHqfHnzlzhgXABgcHO53viDz4aG0yQoidN998Ex988AF27NiBMWPGuLs4hLS4FStWYN68eXjrrbfw97//3d3FIW5AwRAh7VR+fj46dOhgt+38+fPcsgd5eXmQSCRuKh0hrcNoNKJHjx64dOkSsrKyGj2ajzxYqM8QIe1Ur169EBsbi65du0Iul+PatWvYunUrzGYzvv76awqEyAPt8OHDOHDgAPbv34/z58/jhRdeoECoHaPMECHt1HvvvYcNGzYgOzsb1dXVUCqV6NevH/72t785HV5OyIPk3XffxXvvvQcfHx889NBD+PTTTxs9WSN58FAwRAghhJB2jeYZIoQQQki7RsEQIYQQQto1CoYIIYQQ0q5RMEQIIYSQdo2G1jdBRUWF0/VwXOHv74+SkpJmvSZxjuq6dVA9tx6q69ZB9dw6WqKeBQIBvL29735cs971AWc0Gp2uyHyvGIbhrkuD+loW1XXroHpuPVTXrYPquXW4u56pmYwQQggh7RoFQ4QQQghp1ygYIoQQQki7RsEQIYQQQto1CoYIIYQQ0q5RMEQIIYSQdo2CIUIIIYS0axQMEUIIIaRdo2CIEEIIIe0aBUOEEEIIadcoGCKEEEJIu0bBECGEEELaNQqGCCGEkDauORcJJ44oGCKEEELasKNHj+Lrr79GUVGRu4vywKJgiBBCCGnD0tLSYDabcezYMXcX5YFFwRAhhNyHdDodzp8/D6PR6O6iuFV7aj66desWDh06BJZlm3yuXq/HtWvXoNfrW6Bk9z8Khggh5D60ZcsW/Pzzz/dFtkCj0bTIh/CVK1fw1Vdf4fLly07319TUtPlg0WhgUV1lqnf/nYFPeno6bt261eT77N+/H9u3b8f+/fubfG57QMEQIYTch3JzcwEAFy9ebNX7pqen49dff4VGo2nU8bW1tfjuu++wevXqZi/Lzp07wbIsdu3a5bAvJycHK1aswN69e12+T35+Pmpra12+jjMnj6ixf3s1ykuNuHTpEi5cuGC3//rlKodztFptk+9jDRjrCxzvhmVZHD50Ept+v4asqzoYjSwqyoz3lKVqiygYIoSQ+5hQKOR+NhqNMJvNLXq/Q4cOoaSkBJcuXeK2GQwG7Nu3D/n5+QAszTl79+6FwWBATk4OWJZFRUVFqzVpsSyLTZs2wWw24/Lly036wK6pqcGNGze4c4qKivDvf/8bP/300z2Xp6SkhKsbW2Yzi9IiS+bqxtVq7N69G3v37rXLop07Ve5wHssyOPRHNS6kt0yA5szly5dxOv0Ysgu24/xpDS6k1+Lw7hrkZjtm/LS1ZqSnqlFRZp+V02nN0Na27OvzXlEwRAgh9zGRSAQAMJlM+Omnn7Bq1apGf/ibTCZkZGSgpqYGZrMZ1dXVDR5fU1PD/SwQCLifjxw5gvPnz2PNmjXQ6/XYsGEDMjIysGrVKuzYscPp+c3BNhC0VVpaCpOprumpqqoK6hoTsq7pYDI1XDc///wztm7diqtXrwIAMjMzAaDRmbA7sSyLX3/9FWvWrEFNTQ1MJhPOnj0LlUqFyoq6Mmp15WBZFizLQq1WAwDUNSYYzY73LS3WQlVuQuZV3V3vbzSwOJNqf43KChMqSu0DFaPRiLNnz6KqypKJyrqqw6E/qqHXWYKXWzfrRrIZTdW4lWkJgs6ccAzILp6pRW62AYd31+DQH9WorjKBNbM4+Ec19m6rQq2m7QVEgrsfQgghpDkYjUaUlJQgMDAQPN69fxe1DXasAUFlZSX3QZaZmYng4GDIZLIGr7Nv3z5cvHgRYWFhkMlkuHLlCqZOnYrw8HCnxxcWFjotg23W4/z589zPFRUVdudXV1fD29vb4bpVVVUwmUxO9zVELBZz2SaWZcEwDDRqM0pLKu2OKy4uxo3zgMHAwmRiERsvAcuyyL6mh9yLh4AgIXe+TmcJMG7duoW4uDi7oMp6jN1jqjTBbAY8PHk4m6ZBUIgQHcIsAarRyKKmuq5Jq7KyElevXsXhw4fB5/PRt+cksKwnGIZBRUUpd1xtbS085AoU5BpgMjsGGxq1pYwGYxV+/nkrevTogc6dOzuto+tXanE+I81u28FdlqC35wAZV9aTJ0/i5MmTSEtLw1NPPYWM21mn65d0kMh4yM0pqyufPh9CgRf3e1FhFUTiuuevqrKuzlTlJhzdW4MuSVJoNZbXzPlTGuj1LELCRYjqKHZar62NgiFCyAPFbDYjKysLoaGhEIvFLl3LYDBAIBA02xv1oUOHcP78efTp0wf9+vW75+tYP7CBumDIdtvWrVshEokwYcIEBAcH22VxbFn7G+Xk5HDbTp486TQYMplMdsGQbVOO7c8N9UnZunUrJk6ciLCwMLvrrlixAgDw7LPPcpkus9lcb8CorjZBJOHZZYbUajVEQhn2batCtdY+CDt7Og9i+AMAyoqNiI0HivKNyEivhUTKoEvPGmzZsgVDhgzhzjGbGBgNLLKv1wUzer3e7jVlMrHYv8MSWHTuJkHeTQPybhrgPUkAVbkROdl65N6sK8ulS9dw82Ym97iPntgAhawrfDx7oKq6rjmstLgap4/IwJrhNBhSVdRCygfKa05DoyvDH3/8YRcMZV/XoVZjRnyiBJevpKFCfcbu/JLKI/D17I30VDMCOyjB5/Nw8+ZNrh65clQdQ2FqKQK8xqJWWxesVWkuQy6OAJ8vBQBs2boeanUlpkyZgps3b6Ja4w2g7jnW61ikp1quyzAMivItWamK0lpEdRQj43QtiguM6DNQCi8fh4fbKigYIqQeVVVVyMrKQkJCQr0fJsQ9rM9Nly5dHJpKLly4gH379iEkJAQPPfTQPd+juLgYq1evRlxcHEaNGtXkgCg/Rw+jgUV4dN2HpzVrcuLECQT5dUdEtAgMr+mBlm2TjbWP0J3NOHq9HuvXrwcA9EweAbMuHL0HySGR8hyOl0gkXKdck8mE3NxcmM1mLijKzMzEli1bHK5fW1vr0LxWVlaG+hgMBqxfvx5//vOfAVgCpxMnTnD7q6ur4evri5s3b2Ljxo1ISUlBYmKi3TWqVCYc3FUNhTffrg+SqqIKtdUCmM2AXm8fQFRUlCLodtJJKLLUd9Y1S/Co07LYu3cvdDod/vjjD+6cglwzsq/r7ILM2tpau2CoxmYUWI5N35nt63Oh0eVCIgpAde11bvvFi+cc6qRSkwFvj2SoNXX1lnOzCqw5EABgNDk2k2k0Okg9nQdKOq0Z509ZtrMsUFx60+GYGu0NCPhyaHQ5+Pa/ZgwZOANGQ13gqdeZYTJrUV177fbxWTCzlnrg8SQwmKqg0mQgLLgvaqp0UKstmbiNGzdy1wj3nw0+T8T9XqTaC72xHCG+U+y2nz+lQVG+AbUaFjy++7JD9A5PSD2OHTuGK1euQCAQICEhod7j2kKKt71Zu3YtqquroVarMWDAALt91oAjLy8PtbW1kEqlTb6+SqXCmTPnwLIsLl++jOvXr2P8+PGIjIzkRi+ZzWaMHTuWe+6zsrJw7NgxjBkzBt7ePjh11PIh5hcohEzumOE4f6oWDANExDQ9e2X77d0aEDQ02unUmT2ICnwCVzK0EMqzYTKZ7D7UbTMwGo0G69atAwBMmzYDRblipJ3d7XBN6yixe+mwbf2buXMUmEajga+vL/bt2wfA0ox3ZzBUkKtHRU0GanX+0NbWBSp/7DgDX8/+YBiGCxIkwiBoDYXQG1UAAK2hBDdzihHbuS/XcZllLR2Z71SluYz9hyph+/AunFVh4FAlsjKLcPHCdUAfD4APACgrK4WAJ4XRrEZ++bYm1cfN4l/Aou5GN24eg1JueY5r9c46Xluec8am2+/ZtEok9vBC9vW6OrlxWQeDwfnIs1p9AfRGS9bq4rliaOpeUti+vgy1epssoNESqAn5CkSEJ+J61mEYzVUIjRAi46x9Fs6qpvYaFHLL+6bJrEetPo97PB6SSO647Ot1QaSvnxg6w731zXIVBUOE1MP6zVmlUtV7zIULF3DkyBFMmjQJwcHBrVSypikpKYFer0dISEizX7s5m6SawpqJyMrKsguGjEajXR+Pq1evIikpCYAlo2A2s1D6NPy2p1ar8eOPP9r1iTEajdi7dy8ee+wxVFZW4sqVKwCAhIQEhIeHg2VZbN68GYAliB4xfDx3rqbGBJZlIRY7BkQVZSZExDgvh8Fg4LJeRUVFMJvN3GusvKyuI7K1iSrnZsOdn7OKVoIRDUVmzgGHfbZZImu/IwBYv34NeDwJWLPjiKHS0tJ6AyEeI4KZtZwjl0RDKgpEaVXdfEg/fLcdMVHdHc47nVoGvcYfrLnuy0Xm9TKcOnUKWn0RZs6ciRs3bqCi5rTDudW11yETh0MmDoXJbAkAJCJLMGQya2A261FQvh0AsGW9GJ7SWO5csVji9HFotAV2v+ferEHWNR2279wCo1kND0klRAIFdIYyqHXZ4PMkkIkjnF6rIbaBkJVK7ZhFsrLWrfV/ADhw9AdcvzYMAgSjtOooDKZqBCiGOM0eAYDOUNfspTepwLJ1fzdGkxq1unyHYz09PeHv74XrWQDDq4VMzofJZBNF2ahQn4NMHA6hwJMLpgCgpPIg1NosBCpToDdWQqU+D4WsC6RiHyh9xHDXiiMUDJF2raioCNXV1YiNjXXYZ/2Qsf1wuNOePXsAALt378bjjz/eMoV0gXUkCwA8+eST8PDwaNbrHzhwAOfPn0diYiJSUlKa9dr1sf0Atm2+rK6uxvfff293bHm5pR+GQW/GgZ2WYGHsNC8IRfV3Xi4tLbULhPy9BqFan4aamhqsX7/ebn2oS5cuITw83G6bXs/izIm64CInS4/cmwYEhzqOfLLtEmM2s8i8okNAsBDXM8/iyJEjmDJlCoKCgrBu7ToYjAZ0jBqMLl264Pzpum/jRqMRmhoTigrqAiSGEQJgwbL2I4acBUJ3YzY7zyxUVlY63Q4AHtIYVGksQ+8FPCn4PPuO3FWa6zhzIcvhvKqqGlxIr4VaXfcBvmXbz9zPN2/eRFlZicN5PEYMM6uDVl90OxiynC8UeIHPk8JkroVGl8sdrzdWwGTWgmXNKK8+CbWu0OGazlTUnMWJYwyMZksAUKO9brffZNZy2ZbGiomJx40bTZv7x8zqwbIsDCb70Xl5JfvtflfpDjZwlbrXuMFYyQWQgCUY0hmKud+tjykkzBuR0QocOwGYzBpI5YzT0W4AwLIGVNWex+DBw3H9RhUKbapFo8uB3qhCQfkOmFk9DMZKRAZNBO8emoybCw2tJ+0Wy7JYvXo1tm3bhoKCAof9jQmG7jzWVTqdDoWFhfc0kZlOp8PRo0dRWmo/KsWqob4c98raJGU7gqil2fZPsW3esU5CaMva36Mgt65vSXVlXTCl15uRk6XnhltXqUwoLbb/piuThKNjx44A4LBQZlaW5QP9xo0b3LayYi1KCuvudzOzCnllm5FxyXGmaGvrqk6nw48rV+HYsZM4sLMahw8fBsuy2Ld3P/buzITBaLne9awjSD9RYfetXqfTY+vGK1zw4SGJRqjvFPh5Wjpoe8m6IFCZAgFP7nD/phLwPeGntDR93PmaV8qTEKgcjgDlMHh71GV9GIYPqaiD3TYAYOE463JFzWlUai7YZTxslZfWQKe3DzYYRgAfz54ALBkMVniT+yDn86RQKiw9cvWoCzi0+mIUqDYip3QN1DrHPjX10RvLUKTa0+AxtkFEY8THxXE/83jOM1R30uoLUVy5Dyzb8LxNNTWOcxQ5wxdV2QVDBqMKBpPj+56Xlxc8vTwtZdBqUVlVCKOTzJCQrwQAKHx1iImTwMw4lqO06gj3POuNZdAZSx2OaU0UDJE2y2hs2dlNbYMcZxOiWd/s7zb3iisMBoPdY1yzZg1+++03u9E9VllZWfjmm2+QnZ3t9FrHjx9HWloafvnlF26bbd+SXbt2cc07zcF2zhiFQlHvcQaDARq1yeG5LCk0oLjAAKPRiP379zd6iQHbZkvbx1dcXPdmytxOemu1Whw8eBBbdvyAmlrLKB7bpQ+unNfizAkNzqRqkJ+jx4Gd1biUUffGLeB7gMcIIBI573ek1+sdRlnV6guQU7oWWn0x8sq24Fbp79AbK1ClsZ8pmmVNqNWYodOZkZ6ejsqqElTUpNsdU6thUFSUV3cOzKjUXLLLchgMBhSU1fXpkYiCIRTIkDKqK0J8p8DHowdk4jDIJU1vvqnDIEAxBGF+08BHkNMjAgO9IROHQi4OB4+py9gJeHIwDAOlPBECvmNAJuQr4OPRi/vd2gQm4Hsi2HuM3bHlFSrojPZBPY8RISbW0nyoNRQhO7cu+xUY5IGwCMsossoqm2YhYxkMhrvP0XPvGIR16HbXo7w9uiM0tK4+RQJlo+9g+xoA4JB9s9W7d28AQNeuXZ2OFNQZSu0Cq/oCRE9PT4jFYvD5ln5SW7etR6XGcQZ0kVAJwPJlzNoh3/Ge9s9jSdWBFvnC1lgUDJE2h2VZbNu2Df/5z3/sJmxrbsXFdd/g7vzGD9QFQxqNxuX1jVQqFc6ePWt3ncrKSnzzzTd2I1isbwa2mQarzZs3o7a2FocPH3Z6D2cBnW3AUltbi507d97zY7hTY4KXkpISfPXV1/j15224klGXpTKZWBw/oEbqQTXS0tJx7tw5bNiwweF8lmWRcVqDy+frzrWdu6ampgaFeWpcv1yFa1csz2FEaG/4KwYBsMzHcuHCBRiNWpRUHUaV5ipycvJRWlyFFd+txYUMSz3n5xiQftyS7jeabjex8BUIUo4CAAj49sFQgGIY93NtbS0KC+1fPyazBgUVO6A31v/N3GTWoijfiB0bSpB1w3b+nrrMlcFYhUqNZXkGicjygV+pPg8WRvAY64gc+yCTz5NA4c1HUIgIU2aGg2Esb/Niob/Tcli/xdcnNDQMIb6TIL/d6ZXHOJ/osEOY/RxB4UGD4SGJgYc0uq5sjGNQKRbJ0K2n4/xCEmEAJKJAxITVNb9mZV9x6APD4zHoM7ADhELRnZdAn0G+9c6/05IUXkpMmjIEDz/8sMM+hhHCUxqHcP9ZUMi6QiwRw8vLMmePp8SxuR6wZECTk5Od7hMJfDB44EjEhE6Fr2fddA3WJmRPT0/069cPCxYsQEpKit30AQKBADwez2EyTNvMoy0vLy8wDAO5vC6otQZRQkFdMBbg7wfA8t558+ZNbhSes4EmjzzyCLy9vaHR1OD48eNO79saqM8QaXMqKytx/bqlLf7WrVuora1Feno6unbtyr1p3KmkpAQ7d+5E//79ERNTT4/UO9gGQwUFBXajwliWtRu2e+dkcfn5+XbZkLtlsNauXQu1Wg2dToc+ffoAsHTuNRqNuHz5MkaOHGk3hPfOEVC235jqm0jP2RuNsxl/rfO3lJWV4fLly+jZsyckEkt63jocOzIyEn379m3wMVn74wD1z85rWdbADLU2C6fSMhCfaHnsOpsp+S9n1AUCqampXD+uiRMngs/zQNY1S1AaFimC3JNvd1+z2Yy163+GyazjRtZIRAHQ8SxBZ3W1xu55LKs+jrJzQFZWAqrUeahCHsKED0PAl3Kjhky3gyFPaUcIBZYmAU11XQAgEIggl4SDV2XpJJyVmQeTqenBssmsBY8nQm7pZphs+l3UaDO5n22bkvy8+qOgfBvXnOEli3fayZbPE8M3wPLWLhDWvSbEQj/uZ5HAhwvUhAIvGEwqu2vEx8dz8wUlJXXDxVNKLuaqLxgKDPRG9mVLPTAMMH5qEmoqE3Fkr+U1OGC4B9au4TucFxqhgI+vJ/f7wIED4efrB9bkg9BwDwiESmxZJ0Jm7k6YTJbn0t8vEiWl2QAAg1ENhmHg7+/n8IVAIhFDKpVg1KhROHXqFIL9euNaZhr0xjJIpdJGrTcmEokQFRXVpKxqYJA/BEIefH19uW0KWQI8pR0hlXrCaLD/W505cyaKi6rg5emHzGwzjh49yu1TKpVISUlBWFgYkpOTuTmZuPIJlOiW3BnaODMyzvqh7JRle7du3dCpUydIJBIwDMP9jdsGMsHBwYiLi8Pu3XWZxYCAQBQXW4J7pVcoVFV1WR3r+6+zL4ehYUHIyrK8drsmByMrx/JF4ezZswCALl26oFu3bqitrcWuXbugUqkQFRUFf39/TJ8+HefOncO4ceOcfjFtDZQZIm2O7RuUXq/Hpk2bkJaW1uBqyzt37kR5eTm2bt2KtLQ0fP/991CpVA0GKbbBkFqttmtyubM/hG2T2o0bN7BmzRq7zrp3W3PJem1rkAeASzUDlk67th/ytiOiAPssTH0T0dkGQ9bH7SwYss4ns3btWpw6dcou03Tp0iUUFRUhNTW1wccD2AdDBoMBmZmZ2L9/PwwGA8xmFlcvapGbU1fHZdUn8Mcff0Cj0UCrZaEzlENnKINWr+KOSU1NRXZ2NsrKyrB/z1lU28xkW5BnaVK8mXVnFkYLgOUCB53aC/zbWROd3nkTZ5W6LvNWULEdxaqDuFm8CqVVR2G83Sk1qIMX1+m5tLDue6PwdpaIx7OMnjt53HItiTDQ7h5ySTQaYjJrodUX2QVCAFBaddTh2ABFCoR8D3TqFM9t85J1AQPH4ILPk8DX3/F7rkgkg0TkDz5Phq6dh4HH48PPJwJ8Xl3gHRcXh3nz5nF9pABLZsE2+RQW6TwY9/at287jAyIRDz7+AsR2FiM2XgxffwF4fMd+QlKp1C7Aj46ORkRkBCJjPLlgrme/AG6/UKBE757DHa7j42M/W9+0adO4v4nOnTvjsccew/DRnTDnsel44oknMG/ePAQG2D9HkydPtvvCFR0djT/96U/o0aMHADR6vrGgIEvTl3UCSQBQKALgH+CNsdOU8Pa1f95kMhkio4Lg4ydAr169MGqUJSMpkUjwxBNPcJNUWgMaW0KBAnw+A7kHH12T616DcrkcAQEBDl8gbcskk8nQpUsXBAZazhOLxRg3biyUCksWMbl7F7vrWb+kOfvyExUVyf1sDQJZlkVOTg54PB4SExOhUCgQFBSExx9/HI8++ijGjh3LXXvAgAEuzcruKsoMkTbH9g+NZVnum0J9fWUA+1Wcrd+qVq5cCblcjscffxxisRh6vR5nzpxBVFQUvLy8HEbDlJeXc6Ot7gyGbPsNWTsL245qMhgMdkOhbdkeZ/uz7ePMz8+3eyOwPp7a2loIBAK7rJF1n16vh9FodJop0ul0kEgkdgGe7fkymYy7jnXm2Tsft9FodHjzP3LkCHQ6HVJSUhyWWrBOyufr6wujOho52XoUldgGLmZcunQJ165dg69PMIrKHftFAYCnPBTV6lwUFuXjxuW6x12QY4BQyKJGbcmS8XkSLksiFChhNusgEviAgRA8nmOTiS37kTM1XABkO0FeXBdvVJXxbt+rLmBgzZYPJJFIDGNtNTcPjFjoB62h6PbxcgQoBqH7mBG4kX0CMHnjbMZ+uzKUV6fBYKp/RJYtqdjSRNa3b2+w0KK6LAh8nggMI7AbEq2UJ0HA94C3X92HrVDEwKBnEREtxrCxM2A0slAoReg94GkIhUL8/vMZVNdash4SiQSenp52QbTlw7Suvrr1UuC4zch2hUKBHj16QCise/3axvKdu9XVnURmhuaOwWksy0KhUCAwMBAikQhKpdLh8QcG1WVhlfJu8PISIyIiAjdv3rQEa4Bd5jY5OdlulmsrhsfAy0sKwFKmnkkj8cfe1dzzEBkZiUceeQRff/0199hkMhmioqJQUVGBoKAgh8wMYPkw1+l0XMbEGlwAwMiRI1FQUIChQ7uAz+eBYRgk95Xh/KladOzsfDqK+Ph48Hg8h+k6nL2/dOlW1/xp+15Q37pttl+arIHSlClTcPjwYcTExEChUODxJ2ZDq9VCLBZj/wHLXFD9+/fnzu3Tp4/dZJleXl5295bL5RCLxdz7VnJyst3zyjCMXdasLaBgiLQ59aWueTweTCaTXUbFqr5JD9VqNYqKihAeHo7du3fj4MGDOH36NObOncu94fv7+6OkpAQVFRVc50JnmSGVSoWampp6+8ocPHgQw4cPh9lsxvXr13Hy5El06dLFbti+bQbJNhjKy8uz+wDSarVQq9X4+eefwbKs3RtNcXExfvnlF5SVlUEgEGDatGnw8PCwK/Pu3bsxcuRILojr0KED14RgnTXYGdv0d01Njd0b2KljVTh16tTta+i4YJJheHb9XDJvZAG1HZBfvs3pHCdGoxFFxfaBEAMBYmLikZwcjxOHTKhW50JnKEVZqY7rjKsqN6G8ogQszOAxIvh49EJJlSWrpZAlwMMmE1PXn6ZhcnEk1Lpsp/s8veTgsZbXGt9mlA/DCMHjA35+MtzKAZfZCQsPQuVlS/8esdCSpZDKhBg6dChYM4vikmwUFFnvxTQ+EJJK0W+IAmYzCy+FCKNHj8bW31Uwmy1NVtaZgQcPHgwfry4QCBiIbKYOGDTSA/k5BkR3FNs3m92eF2rk2ERs3nwTVTU56NChA4C6LItAIIBYLIaHpx411Zbn2DazAAATJ050/GCrJyEbERGB8vJySKVS9O/fH2fOnEH37t3B5/Mxa9aseuuAx+OhT8+RuH5FBbk4AlI5D6NGjcLJkyfRtWtXuzIDqLc5/U5GIwuGsf8YtH181vcaHo+HuLg4LnCrrKxE165dkZGRAQAYMWIE8vLyuL8Pf/+6AKVLly7o0qULbHl48tF/WP3TXDAMgzibUWa22x9//HGcPn0aFy5YXmsRkX52+3v06IFbt27ZZffu1KdPH9y4cYPrhySRSDBy5Ei761izQGPGjIFGo7Hre9WrVy+EhYUhIyMDV69exciRI7n6t3awlslkXDAUEeFK5/3WQcEQaXPq639iNptRXl5u90Zj5SxAsrJ+aFvXYaquroZGo4HZbAbDMAgLC0NJSQnX7GMymRyCoYqKCqxatYrbHhQUZDeCCLBMwCgRhuF61jHunidPnrQrb3V1NZdBss3a3NlhWqvVIjMzk8ve2GaGAHDD5w0GA3777Tfw+Xy7LE5mZib27NmDSpUlGOrTpw+OHz+OwsJCaLVau2Y/tVqN31ftRrB/b6iNdRmwixk3UaM5gbCQJBTnSlFWWvfhfePGNe5nsdAbWr3NpGqlpVCIK7g+KSKBLySiQIfRVLY8pNHw8eiDS2fM4MEEPk8Gk1kDrb4QMnEol91Q384K+fv7o0dSFxw7Wg2doRSdOsagwGbAikQqBI/Hu+vsyP6+sVDnZwOw9M1QKpVcBlIul0OhEKBSJUamTXcRhgF8/QVQ1do3WfToEwZv39G4kZWBHknDYDJK4HM7Q8PwGEyaMhoZGRmIjuqE6krg8IFLqFCfBY8xITQsxC7z6ePjw70eJRIJAjvYf8vvEC5EbrYBQpEQRm3dORERjpkGD08+OnWp/+/D11+IP82bCpVKxQW/YrEYTz75JLcuW4/+cmSc1iAuUerQlGEbeIglDHRaFp4K580dffv2hUwmQ0xMDJRKJRfINEZS93iU5FpetzIZD3yBDEOHDuX222aGGjuflpeSD1/P3iio2ME1hdl+sXL2vjJt2jRcu3YNXbt2hVwuR0lJCcLCwrjXGo/Ha9Hle7y9vREUFMQFQ3dm0gYNGnTXa/Tr16/Ra+M5C8oEAgFCQkIQEBCAfv36cf0n582bxwWTtq8TZ+/ZbU2bC4Z27NiBzZs3Q6VSISIiAk8++aTTCfEAYP/+/fjyyy/ttgmFQvz8c90kXSzL4rfffsOePXugVqsRHx+Pp59+us3OFkwaXlZgy5YtUCgU6N+/PwIDA7F37174+vo2uByGdSi27R+nNQsjk8m4b7UVFRUoKCjA2rVruTZ/q5ycHC4QYhgGKSkp3GSGti5fvgq1ti5o0Ol0SE+3Hy69efNmyOVypzNbK5VKqFQq5OXlIS8vz2F/fUwmk0M/o7oAi4GAUXL9DWpra5F13X7iuoLiizDrgwBRXZCUdtoyRPlWlgaBymEOfVsAQCoKxp1dD9XqaoiYunmbAhSDwedLwbImrjnmTnJJBEoKrZ1vGcjFYaiqvYKa2kxIRR1g4KehUu3BTfAW3MEfHTtLEBwyCOoaMwI7CHHpXC2uX7IEjTI5H2KxmHstSSVeqNU6zpsyaHgQhKkdce3aNfTr1w/R0dE4evQoZDIZ18zQJUmK+EQJPv/cehYDpQ8f2rK6YEgqlUKh8ET3nvHo3jPe4T6AJajp1csyhNzHFzh3Mg6e0lj0GSJFUAcZtmzZgsxMSwfUESNG4PfffwfgvJ9KQrIUCm8BsnaouG2uzDDOMIzDivG2AYXCm4+BIzzvPA3R0dF2zTH9hnrg6kUt4ro6ny9HJBKhZ8+e91RGqYyHvkPl4DEAX+D4925tLruz7A0JDhWid/8IyL2ehp+/40i3O7NggCX4sz4G20EGUVFRGDt2rF0TWUuxfn61dOB1N0Kh0G4gie1zYPtlz1lfp7amTQVDR48excqVKzF//nx07NgRW7duxbJly7B8+fJ65zGRSqX49NNP673mxo0bsX37djz//PMICAjA6tWrsWzZMnzyySdOX+jE/ZxlhuRyOdRqNaqrq1FdXY3169dj6NChXLanobR4ZmYmkpOT7b7lWTMjnp6e3IdAaWkp1q9fD7PZzDUp8fl8h0zRuHHj4O/vz7Wb236Lr70990doaCgEAgGys7Md+jo5m3PDijGFAVDVu/9eSEXB0NaKubT3lQuVqHUyg77BWImqaseAQaO7hbyyLfCQRNltFwl84a8YjPJqx6URrHPFSEUhEAq8ENVRhCB1L6SmOwZDCoUCSq8g6Gz6kvj5dkRV7hVodLdg4t1CTrZlZJNMEsKdAwAeXnx4eFmeV6msLijzCxRAXFAXDIVHBOPKFcfHJpfLMWLECHTr1g0dOnQAwzB2Q4+tbGfGFQpkiIgRQ6Wue4MPDAxs8vp0KeM9LYFcsCWYsF3OxPbD3NmHnUjMQ0ycBNjBNnhcS+nVqxdyc3MxYsQIu+1eSj56DXB9csf6BAQ57wcDWAK6sWPHorKystEBCcMwiIx1zKb16tUL2dnZDs1bd7tWp06dGn28K3x8fDBr1qx6R5a2BXdms9u6NjWabMuWLRgxYgRSUlIQGhqK+fPnQyQScYv2OcMwDJfetv6zss5XM336dPTu3RsRERF44YUXUFFRgZMnT7bCIyKNZTuU3VlmaOjQoXj44YcxZcoU8Hg8GI1G7ls04DhLdP/+/TF16lQAlszQ77//bjeyrKTEkhnx8PCAr68vt2r3nUNG7xyhEhMTw2Uq+/Tpg0cffRSPPDIH3bsNBlC3VpCPjw8iIyPtzu3W7e6TsAl59t/OO3dOrOdIy1DrxvCUdkTWNR1MBkvwX1VVA73Rsb9KtfYG15H4TnpjOcprTtlt85J1QlyCAh7SaG7mXNvJ84C6jscRMWL0GWRflwAQ1ykJs2bNwtAxCnRJksDrdvNKQmIHyGV+YGFGfknd6CqN1pItcxb8isR1wUhEjP2cJrbZZdugWCQSQSQSISQk5K7BzOjRoxESEoKHHxkMqYxnF7zcmUlsDA9PPhcIAfad622HPzcU5IwYMQI8Hg/Tpk1r8v1dMWDAAMycOfOeFsFtSZ06dULv3r1dXjh5wIABmDNnTquut9dUgYGBdpmYtsbaB6m1lulxVZvJDFk/3KwfYAC44XhXr16t9zytVovnnnsOLMsiKioKjzzyCDeKoLi4GCqVyu5DSCaTITY2FlevXsXAgQOdXtM6MsjKtjNZc65Obr0WrXhuGaWUnp6OmTNncsGQh4cH15zl6enJfeCEhYXh5s2bdqOg7uTv72+X9rdmlKzS0tK464pEIkyZMgXr16936Cvk7e2N8vJyrgnKOukYYPlQ9fPzw9mTahTcsk8D+/j4oGvXrhCJROjQoQMkEglEIhFqampQXFwMqVTKBWS2i1qKBHUBg1gYAFbTA0LBFRiMjssTCPnOs6UMI4SQ7wGDsQoKeVfIxOHQ1JihUluCANumKn+vQWBhQmnVMRhur+zdWEK+Eh27SHH9UhDC/WaAZY3oM8gb6zdd5oIq/u1h6J4KvtPXeVBQEPe3FdtZiqhOEpQVG+EXKMA4+TCsWbPG6Rw+CoXC4XoBQSJ4KXXwDxJA7sG3G+1m7RgMWJoirfM2NWUob+fOne06kdoGAkFBQS7/Hds2c/L5fAQEBKC4uBgJCQlOr80wDEaOHIn4+Hi3NpU86Oh9+t506dIF0dHRjW4ic3c9t5m/oKqqKpjNZofOYEql0unMuoDlDW7hwoWIiIiARqPBpk2b8NZbb+GTTz6Br68v1yfjziY2hULR4Erk69evx5o1a7jfo6Ki8OGHH7ZYJ7B7+Vb5oLGOwjh8+DDXaTgoKIiblycyMpILbvz9/XHz5s0GO8cmJibCw8MDCQkJXEdDZ4KDg7l/fn5++P333+3mH1IqlQgICODWLgsNDbXrb8ayLDbduMRNzmcVGxuLkJAQsEYlAoKkEEssgcj8+fOxa3Mu8vMKUMpsgEToD51BxZ0n4Ns0j/Dl0GlZsKwYgJNgSOCYHVHKkxHs3x3aWhNY1oygDnIUFViCSz7P8VuuUKCAUChEqU1iLdA/BuDVoGNMNxw++ofDOVZR0cEID++AvoNFSD1UjEHDw9E12QcnTgfh5k3L8xYd449BgyPQoYMl0zFp0iQcOXKEa1aMiQ1x6L8XGmr5PySkAw4ePGj3fFh16tTJaTN3+Ly6n61DexUKBaKi6pr4pk2bhm+//RadOnVyqe+g7XtIt27dXG6y8PX15V7vwcHBePbZZ1FYWIioqKgGPyCcDSEnzY/ep1uHu+q5zQRD96JTp052bbSdOnXCX//6V/zxxx+YPXv2PV932rRpmDhxIve79Y2opKTE5WUZbDEMw41Kask1uNylvnl3GmLbn8b2225NTQ0XJDXm23xNTQ1qamowcuRIKBQKuxldbXl6enKBjkAgwCOPPIKffvqJyxzk59RCVxMAoK5DsO2irpUqy+uBz5ODAZ+b+I9lWRw7mI3zp2sRECxAv6GWYKm60oTsG9UAPBDqOx08RoCc0nXc9axLJwB1gRGfEcMIx8kD/QM84BXYDRXlWvD0iQB4SO7tg+BQEUqLDLhxRYeEHkLwzhpRUmQAU+s4Mmbw8A7w9hXhK8u0KvDzGoie3buiY2fLt7ni0ptOM7NJSd3Rs78HCgoKENCBxegpCkiklkVmQ0MDuWAoOFQCnqAKBQWWaCs6OhrR0dE4fvw4SktLIZfLnS6Sa+Xj4+M0GGrMGkbjxo1DamoqRowYgaKiIixYsABmsxlyuRx/+tOf4OHh0eC978b6XuDj44PKysoGV3FvjMTEROTl5aFr165cuaRSqcOoRasH/f2jraB6bh0tVc8CgaBRiYw2Ewx5eXmBx+M5ZGxsh3vejUAgQFRUFPfmYT2vsrLSrsmksrLSoT+HLaFQWO+HeEv8MbAs22b/yPR6PQwGA8RiMXbu3InQ0FAkJSXd9bysrCxs3rwZQ4cO5Y63Tkpm7Q9hNBpx4cIFREc7ztQbHh7uMN+HtY5s+1PUx7Y+6/vm/Mwzz0AsFnPHamvNOHlYDR4jB2D5sNVUiyEVdwBgmVLew8PD7tqlRXUjoHw8e0KtvQmpOBAymQzXLlsCgOKCugVniwrqMjwCviWTwNpMyuIXIIDUtwuysrKhkN0elcQ4Bn8CgRADR3gAGAZ1jQl7t1ZD6cNHVEdL9ic0UoTQSEv99Rpoqa+qyjj89ns6NJq63tOBHSxNPb17DsHVS6XwkERBJme48qakpCA6Ohr79+/ngtFp06ZxdWo9TiypO8f2jUcmkzl9bduOwmnotR8QEMAtC2GrMX8v4eHh3LxRLMty6XrrXDGNvU59fH19MWHCBHh7ezfL369MJsP06dObXK62/P7xIKF6bh3uquc204FaIBAgOjqam8QKsHQozMjIaHQPfbPZjFu3bnGBT0BAAJRKJTdjMGAZqXT9+vVW6/V/v/v555/x3Xff4fTp07hx4wYOHDhw95MAbN++HQBw4MAB5OXlcVMcfP/99zh92jLS6I8//sCBAwccrsnj8TB69GiHoeJWtsGQs5Rq//72HYsDAgLsfvf29sbUqVMhFIqg19c1tV29oIWq3ISaqrrsn4c0GiKBEsGBnRAZGQkfHx/k3dKjKN+A1IM1uJBuaYKKiBFh1NieCPEfA6U8GZfPa6HV1P1B52TrYdCzKMhxXLbD06OuuatHfxlGjhyJJ5+ch7gEJQCAgc2MsVJLgDRkyOC6+vDgY8REL/Qb2nCQ6KWQ46mnnnSaWUvslggfz15gGB7kHnX7xWIxOnXqhMRES0duoVB415lj/fzqJoFrjqYjq4ceegi+vr4OI5jcKSYmxqGTPSHk/tNmMkOAZSbTL774AtHR0YiNjcW2bdug0+kwbNgwAMDnn38OHx8fzJkzBwCwZs0adOzYEUFBQVCr1di0aRNKSkq4N0uGYTB+/HisW7cOwcHBCAgIwKpVq+Dt7Y3evXu762HeN1iW5TodO1uksKCgAJcuXcLAgQO5URfW6fFt+/OsXbsWycnJXIfWw4cPIyAgANeuWSbusx0VBlgyOTKZDN27d8eFCxcQH28/b4vtsOOgoCCUlJRwgdOjjz5q9+Gk05rBspbFH48cOYLw8HCuk/6po2oU5hswcLgHpDIecrIsWRtPaRxq9fnw9ujBzTzsIewHpZcA29Y4NlfxBUBcVwnEEh4Cg4UoyDVw891YnUmtmy6AYSzztqjKLWXu22cELlw6jL59+0Isub38A5+Pzt2kkHvwULCrLjjp03sgvAN6IijY/gNYJm/c9xqGYTBp0iRs3LjRbgi5RFp3vtzDsTmtf//+3ECEuwU4tgGMq8FQcHAwN7V/hw4d8Oijj7p0PUIIcaZNBUMDBgxAVVUVfvvtN6hUKkRGRmLx4sVcc1dpaaldR8Kamhp8/fXXUKlUkMvliI6Oxvvvv49Qaw9MWNZc0el0+Prrr6HRaBAfH4/Fixe3+zmGDAYDdDodZDIZdu/eDaVSya2mDlhGttiOvrId7m5d9Xzt2rUwm82ora3FhAkTUFxcjI0bNwJwHBFw5swZu9/XrVsHZ+RyORf8+vj44JlnnnF4rmyDIX9/f3h5eXGBlu0HsdnEYt/2apiMLMZM62E3QZzZxKIw3wCzCbh6UYuAICHMZkAgBOQIQ4RoNng8EeISJbhyXgujoa5J7E7desq4IKZDuCUYqo9QxCC5jwxVKhMXDHXo4IfOCTOcHu8fJATPppmsS7IcgGvzuERERGDhwoV2fbIEAgYDhlvq1XbJBluNaZ4ELJm3Pn36gM/nu/x3JhAI8MQTT4BhGBrNQwhpMW0qGAKAsWPHcivZ3undd9+1+33u3LmYO3dug9djGAazZs1qcN2b9ui3335DWVkZRo8ezfXJiIyM5JqUdu3axWVuAPuFUPV6PSQSCZf9uXHjBlavXm031Li+Nl+pVMoFVkKh0G4KA29vbzz22GNgGAZmM4uzJzXw8RMgIsbyIWg2s+DxGLv7BAYGYuDAgdiyZQvi4+NRkKtHcYERPn4CKH35MOgt5ahSmdG1WwIKCgrAsiwqVSaYb7fCFeUZoSqz/NKxswSXzmm5hT5DwoS4cr7usYdFipCTXdfvZ/wMy4rRXHk6COEbIIC6xgSDjrVbsLJrDylCwoUQiXnQ1trMKeMkE8PVl4yHgGARGlij9p446xPnbKXze9W/f/9ma/dvaid8QghpqjYXDJGWx7IsNxrHdvLJkydPYsKECTCZTHaB0J10Op3DZGTWleXvZsCAAdzSFr169UJaWho3Q7NUKuW+/efdNCA32/IvIkaMmzd0OH+qFt37yRASLsLkyZOh0+ng4+MDHx8fPP7441CVipF2xNIcdStTj6iOdVmJ4gIDdmbnwDfADL4AOHHIfgpmndbywR0cJsStLD3UtxeltG1+Co0UIrmvDFGdRDiytwZRHcV2gRAA8PkMBqRYMixmEwuDgUXmVR0iY8V2MyR7KesCoPoyMVb9+vVFdnZWk9ZxIoQQ0ngUDLVDtlke24nprFkTZ/2DbOl0ugbXD6uPRCJBZGQkEhISoNOakZ6qgUTsCyAbgP0kduqaupTK5fO1yL1pAMsCF9JrERgsRGRkJPJu6VGQq4dfoBAKLyVOH7Hvz1OYV5d1unZRC0CLnGxAahPgBIUKUXi7WSskXAi5h2U5gTMnNOjcTQKGxyAgWIDyEiM6JVj6Dym8BRj/kPKuj5fHZyDmM+jczXGWXh8/AZL7yCD3vHtfn4CAAKfNhYQQQpoHBUNtCMuy2LJlC0QiEcaMGdOkc2/cuIGjR49izJgxCAgIgNls5hYEtU6Lbr2HbV8gWxqNBmfOnMGhQ4cavJftmjMMw2DGjBm4cuUKzp07V+85U6dORVBQEPeBfvm8FiWFRmj1dSO9bD/sdbV1TSzXLtbdT6e1ZFoiYkQ4fcxxDTOBEAiPEiPzqg61GsdmGpMJqKmyZH2EIgYJyVJ4+/Ch17OIv724pJeSjyGj6yZR7DVQDpORhUjcvIMvw6IaH9y05WUBCCHkftdmhtYTy/xHWVlZuHLlisOyEFZlZWVOVzPfunUrKioqsHv3bgCWpUhu3ryJixcvciOtrl27hm+++QZnz56ttwy2UxvUR6fTcQFVQEAAgoOD7ZY7cObOeYOqqyxlEgvrOjwXFZXj/CkNTCaW2+/MlQwtdm1yXHQTsPTp8VTc/WUtk/MwdpoCMjkPsZ0l6JIkBY/vvLmKz2eaPRAihBDSdtA7fBtiGwA5a4bSarVYvXo11q1bxy1ncCfriu+2TWHWn0+dOgWtVotLly7ZnSMUCrm5YazNZhEREfWWc9u2bdxq8daRXbYj+BrDZLBkbRiGxy2VwDd2RPZ1PbKu6uoNhrx9b/e1cdI3VyrnIS5R6jDM3HbenOBQS2fcgGBKihJCCLGgYKgNsQYyd/5slZ6eDqPRMpux7RIJtnP6WFfkti5wCgCHDh1CYWFhvYs5ent7O6zfZruWkzNZWVkAwK2aLJPJ8Pjjjzc4AR3LsjCZLFGMwWaU+qiRYzFy+BTIJZZ7Xr+kg9HJ6HRvPz76DvWAVGafwfHw4iGxpxT9h8khFDKQ3TE6q0c/Gbx9+ejexw/d+8qR2FOKuMTGLR5ICCHkwUdfj9sQ22yQs2DIdoTXiRMnoFKpMHbsWFRV1TUZWYcz2267evUqrl69arckiS1vb2+7yfHEYrHdfD1xcXEwGo24ceOG03Ntf/b393eataqsMCLtqAZmE4veg+SoVdcFcAYDD9oaPzCM4fbvjmmfsEjLnD9CIYOYOAkybs/8HNtZjNh4MYSiurheKq0LliRSBkpfAQaP8kJwsGXB1chY6n9DCCGkDmWG2hDbYKi+ZjJbV69ehdlsthsRplarYTabnXaStj3Olo+PD7y8vOx+t67jBAAKhQITJkxwOmu3de0nK9vzrIRCIU4eVkNTY4a2lsWhP2rs9l86W4u8m5ZASCxx3m8nqY+UG5qu8KnL/Pj6C+wCIQBgeAx4tw+J7UwZIEIIIQ2jYKgNaSgzxLIsFww99NBD3Ha1Ws3137EeV1NTU++IMQCYPHkyt9YUYAl2IiIiuOxQWFiY3TB366R3zia/u7N5zTYY8pBEw9NTgUEDxjsd2WVVlG9pM+vcTXJ78VEADBDdqS6DYzv7sO0cPfUNTR+Q4oHEnlJExtJwdEIIIQ2jZrI2pKFgyHY4e1BQEDw8PFBTU4Nz5845NF9VV1fXGwwJhUJEREQgIiKCW8DWy8sLSqUS8+bNQ2VlpUOAY216sy0DAHTs2NHu95JCA0yGuoBJIUuASOiNbMdFxyGVMZBIeai4PfMzXwBEdhRDIGAwcLgHzCwLbx8BTCYWQSH2QZhAwKD3IDkMenO9szd7+wrg7Usvb0IIIXdHnxZtiG0AVFxcDIPBwGVjrFkhoVAIPp8PuVyOmpoabvZm62iu3NxcFBUV2XWgtiUWi7ksy+DBg1FTU4PAwEAAls7XzjpAm0xmHN5dDZW6LssyZswYwNABO9ZXot9QOcQSHo4fUEOlrpvZWSjwsrtOxy5ibs6gTgkSVFaYuGAosIMQAoGlXD42y0J06+V8oc87AyRCCCHkXlEzWRtimxkqLCzEypUruWUurFkZ6+R71iHt1mU1OnTowPX7OXbsWL3rQtkGSd27d8fgwYPvugBmdaUlg2OqjUZycg/MmDEDcXFxuHrBBIPe0gfoXJolkBPy6wKgUZPrOlfzBUBIeF0wpfQRQGYz5L1TF+rbQwghxD0oGGpD7mwaU6vVOHr0KIC6zJC1T86dK4jLZDJumLt1ksU7Ozc31bBhwyzzDemiAQA8ho/YqD4wG/yg05rtji0usPT7kYnD4ePZG317ToNUxuOGwYdHiSD35EHpw4e3Lx+eXjyERogQHi3CwBEe8FTUv1gpIYQQ0pKomayNOHHihNN+PtZh6ncGQ9bMkJVcLneYRygyMhK3bt0CAEyaOAU7duzAkCHDGl2mbt26oWNsV+zeXDdM/9RRS8AmqKeVimEYKGSd0TnBEpj1G+aB/FsGRMeJweMxGDyqbpkLsYRBUm/nzWCEEEJIa6HMUBuQl5eH48ePAwACAwMxe/ZsPProowAs2SG9Xs8FQ9ZmsoYyQ9b9AQF1636pSvwQ6jsLZfmOy2aUlxpRU21CabERW39XIft6XUfp+maCtp0UMSLGfsSWrz+fWxLDw5OPTgkSrj8QIYQQ0tZQZqgNOHHiBAAgPj4eo0aN4vrwSKVS1NbW4sqVKzhw4ACA+jNDtpMmApa5gjp06IDhw4fDx8cH6Uct0UtlhX1wU11pwpG9NRAKLfc0m4Hzp2q5iQlrKi3Hyz15UFebIRACiT1kSE+1ZIi8fflI7CmF2QwYDSySesvA4+Ou/ZAIIYSQtoKCoTZApVIBABITE+2CCG9vb9TW1mLfvn3cNmswZDtDNGAJhng8nt3vANC1a1cAwDleJcwmx07VuTf1AAsY9Pb7jAYWxYUGXDhjyUh1CBMiIFgIqYwHsYRBeqrlOL2eBcMwSO5DzV2EEELuTxQMuRnLslDfHo5+Z3ZHqVQiPz/fbps1GJLJZGAYhhs1dueEiLYrxAOwzMh8u2mLNbNgeJZzC3KdLAIGYPu6SrvfPbz48PGre7l4ePJQU21GYDANcSeEEHJ/oz5DblZbW8uN/rqzH5B1JXlbtkty3Dk5ImBZR4zP56N79+4N3NMSQN28oYe62jIqTCpv+KXg6WU/2mvAcA90SZbQgqeEEELue5QZcjPrCDKxWOwwGqxr164wGo0oLi5GZmYmzGaz3WryMTExOHXqlN05o0ePxrBhwyAQiGA0sBAILRkgva6uGUyjNoNlWVw8a5nXqEuyBFEdxSgvNYLPZ5B5VQezCTCbWS4b5KW0D5bEEh5i4igQIoQQcv+jYMiNqqqquGDmziYyABAIBOjVqxcAy6SLKpWKmy0aAPr27QuWZRETE8NtYxgGIqEI+3ZUw2hgMXiUJ3g8wHYORk2NCVcy9DAZAR9/PqI7WWal9guwNHn17E8vC0IIIe0Hfeq50YEDB5CZmQnAsYnsTmKx2C4QAizB0qBBgxyOVZWbuOavMyc0iI0X2+0/e9KSEeILgO59ZDTyixBCSLtGfYbcyHaG6LsFQ01RXFjXKbq0yIjjB9ROj0tIlkJWz0KnhBBCSHtBwZAbRUREcD/fOfrLFSWFRqfb/YPqEoEMA4RHN989CSGEkPsVBUNuZDsaTK/X3/N1yoqN2LO1CiWFBtRqzNxK8B271DWPBYYI0LmbFLGdxWAYoPcgOTWPEUIIIaA+Q27FMAwmTZqE3bt3o3fv3o0+r0plCXa8lJYmrqP7awAWOHlEjbgEywgvbz8+YuLEKCk0QuHNR7destvnSBDbWcLNOE0IIYS0dxQMudnAgQMRHR3NTZ54NyYjiyN7q2E0AEIRg5g4McBa9wEXz1pnjBZBKOLZLYwKWAIwIc2TSAghhHComew+o1GbuUVSDXoWl89rHY7xUvAQFkn9gQghhJDGoMzQfUZdY77rMYNHe4LHo2YwQgghpDEoM3Sf0dRY+gsFhwrRo7+lH5Dcg4fIWEsmqEuShAIhQgghpAkoM3QfUVebkH3DMupM5sFDhzAhBAI5lD58CIQMQiNFUPrQvEGEEEJIU1BmqI2qrjJhx/pKXLto6RPEsixOHFJzM0vLPXhgGAaBHYQQS3jg8xl4+wpouDwhhBDSRBQMtVFXM7R2HaRrqs2oqa7rLyS7yyrzhBBCCGkc+kRto2xH2tdqzCjOr1tig8cDPBXUHEYIIYQ0B+oz1EZpa+uyQOnH1dDWWqKjqE5ihEWKIJFSHEsIIYQ0BwqG2iCWZe2axMpKLCPIeDygY2cxxBIKhAghhJDmQp+qbZBex8Kgt2SCvJR1T1FURwqECCGEkOZGmaE2qPL22mNSOQ9Dx3hBU2NCQZ4BETHiu5xJCCGEkKaiYKgNys22zCXkH2h5emQefMTEUYdpQgghpCVQMNSGmE0s9HoWBbmWkWPh0bS+GCGEENLSKBhqIyorjDhxWA2txtJXSObBo9mkCSGEkFZAvXHbiPRUDRcIAYC3L59mkyaEEEJaAQVDbYDJxKK6yn41eqU3ZYUIIYSQ1kDBUBtQqzYDrP02hQ+1YBJCCCGtgYKhNkBdY8kKCUV1zWIKJWWGCCGEkNZA6Yc2QF1tmVfIL0CAsCgReHxAIKT+QoQQQkhroGCoDbBmhuSePAR2ELq5NIQQQkj7Qs1kbYC6xpIZksnp6SCEEEJaG336tgHq6rrMECGEEEJaF336upnZzEKjvh0MeVCnaUIIIaS1UTDkZjVVBrAswOMDEil1miaEEEJaGwVDblZZaVmUVS7n0YzThBBCiBtQMORmVSpLMCTzoKeCEEIIcQf6BHazytvBEPUXIoQQQtyDgiE3q64yAKDMECGEEOIu9AnsZmaTZVEyPiWGCCGEELegYMjNWNYSDFHfaUIIIcQ9KBhyM9Z8+weKhgghhBC3aHNrk+3YsQObN2+GSqVCREQEnnzyScTGxt71vCNHjuDTTz9Fr169sGjRIm77F198gQMHDtgdm5SUhDfffLPZy34vzJQZIoQQQtyqTQVDR48excqVKzF//nx07NgRW7duxbJly7B8+XIoFIp6zysuLsaPP/6Izp07O92fnJyM5557jvtdIGg7D/t2LETBECGEEOImbaqZbMuWLRgxYgRSUlIQGhqK+fPnQyQSYd++ffWeYzab8dlnn2HmzJkICAhweoxAIIBSqeT+eXh4tNRDaDLWTJkhQgghxJ3aTIrEaDQiMzMTU6dO5bbxeDwkJibi6tWr9Z63Zs0aeHl5Yfjw4bh06ZLTYy5evIinn34acrkcXbt2xezZs+Hp6VnvNQ0GAwwGA/c7wzCQSqXcz82FYRguM8TjMTQDdQuy1i3Vccuiem49VNetg+q5dbi7nttMMFRVVQWz2QylUmm3XalUIj8/3+k5ly9fxt69e/HPf/6z3usmJyejb9++CAgIQGFhIX799Vd88MEHWLZsGXg854mx9evXY82aNdzvUVFR+PDDD+Hv79/0B3YXLJsFAPDx8UFwcP0BGmkeQUFB7i5Cu0D13HqorlsH1XPrcFc9t5lgqKlqa2vx2Wef4ZlnnoGXl1e9xw0cOJD7OTw8HBEREXjxxRdx4cIFJCYmOj1n2rRpmDhxIve7NVItKSmB0WhspkdgzQxZUkMVFeUQF9Q027WJPYZhEBQUhMLCQq7OSfOjem49VNetg+q5dbRUPQsEgkYlMtpMMOTl5QUejweVSmW3XaVSOWSLAKCoqAglJSX48MMPuW3WCpw9ezaWL1/uNMIMDAyEp6cnCgsL6w2GhEIhhEKh033N/cfAXY5p/msTRyzLUj23Aqrn1kN13TqonluHu+q5zQRDAoEA0dHRyMjIQJ8+fQBYOkdnZGRg7NixDsd36NAB//rXv+y2rVq1ClqtFnPnzoWfn5/T+5SVlaGmpgbe3t7N/yDugZk6UBNCCCFu1WaCIQCYOHEivvjiC0RHRyM2Nhbbtm2DTqfDsGHDAACff/45fHx8MGfOHIhEIoSHh9udL5fLAYDbrtVq8fvvv6Nv375QKpUoKirCTz/9hKCgICQlJbXqY6sPDa0nhBBC3KtNBUMDBgxAVVUVfvvtN6hUKkRGRmLx4sVcM1lpaWmTeprzeDzcunULBw4cgFqtho+PD7p164ZZs2bV2wzW2mg5DkIIIcS9GJYaQRutpKTEbsi9qxiGwYGdalRW6DEgxQO+AW0qNn2gMAyD4OBgFBQUULt/C6J6bj1U162D6rl1tFQ9C4XCRnWgblOTLrZHNOkiIYQQ4l4UDLkZ9RkihBBC3IuCITejPkOEEEKIe1Ew5GZm8+0fKBgihBBC3IKCIXfjmskoGiKEEELcgYIhNzNTMxkhhBDiVhQMuRl1oCaEEELci4IhN6MO1IQQQoh7UTDkZuztDtQUDBFCCCHuQcGQm1FmiBBCCHEvCobcjJt1nKIhQgghxC0oGHIzygwRQggh7uVSMLRhwwaUl5c3V1naJTP1GSKEEELcyqVl0letWoVVq1ahc+fOGDJkCPr16wepVNpcZXvg2a7MS8EQIYQQ4h4uZYa+/PJLzJkzBzU1Nfjqq6+wYMECLF++HKdPn4aZW2eC1McmFqJgiBBCCHETlzJDPj4+mDx5MiZPnoxbt27h8OHDOHLkCI4dOwZPT08MGDAAgwcPRseOHZurvA8WCoYIIYQQt3MpGLIVHh6OOXPmYM6cObh06RK2bt2KnTt3YufOnQgKCsKQIUMwcuRIKBSK5rrlfc8+M0TRECGEEOIOzTqaTK/X48iRI9i4cSNOnToFHo+H7t27IywsDGvXrsWLL76IEydONOct72u2wRCtWk8IIYS4h8uZIZZlce7cORw6dAgnT56EVqtFZGQkHnvsMQwaNIjLBFVUVODTTz/FypUr0adPH5cL/iCgPkOEEEKI+7kUDK1YsQLHjh2DSqWCt7c3Ro0ahaFDhyIsLMzhWG9vbwwfPhxffPGFK7d8oNBoMkIIIcT9XAqG9uzZgz59+mDo0KFITEy8a7+X+Ph4LFy40JVbPlAoM0QIIYS4n0vB0DfffAOJRNLo4wMCAhAQEODKLR8odl2GKBoihBBC3MKlDtRGoxE3b96sd/+tW7dQU1Pjyi0ebLejIYqDCCGEEPdxKRhasWIF/vvf/9a7/7///S9+/PFHV27xQGNpKQ5CCCHE7VxqJrtw4QJGjRpV7/6ePXvijz/+cOUWDzSuAzUFQ4QQ0up0Oh10Ot1dj6utrYVer2+FErVv91rPYrEYYrHYpXu7FAxVVVXBy8ur3v2enp6orKx05RYPNJaayQghxC3UajUYhoGnp+dd+2wKhUIYDIZWKln7dS/1zLIsamtroVarIZfL7/neLjWTKZVKZGVl1bs/MzOzwWCpvaNgiBBC3MNoNEImk9HglfscwzCQyWQwGo0uXcelYKh3797Yu3cv0tLSHPadPHkS+/btowkWG2AdTUZ/jIQQ0rrofffB4urz6VIz2cyZM3H+/Hl89NFHiIyM5CZbzMnJQXZ2NkJDQzFz5kyXCvggo8wQIYQQ4n4uBUMymQzLli3Dpk2bkJqaiuPHjwMAAgMD8dBDD2Hy5MlNmoeovbF2oKZgiBBCCHEfl9cmk0gkmDlzJmWA7gV790MIIYSQltC3b188/fTTmD9/vsvXOnr0KB5++GFcvHiRW5P0fuJyMETuHTWTEUIIaYoZM2agS5cuWLp0qcvX2rZtG2QyWTOU6v7ncjCk1+uRmpqKrKwsaDQamM1mu/0Mw9B6ZPWoC4YoGiKEEOI6lmVhMpkgENz9493X17cVSnR/cGk0WUlJCV5++WV8/vnn2LdvH/bt24dTp07h0KFDOHDgAE6fPo0LFy40V1kfOJQZIoQQ92NZFqxO655/bOP7S7z00ks4duwYvvvuO4SEhCAkJASrV69GSEgI9u7di7FjxyIqKgonTpxAdnY25s2bh6SkJHTs2BHjx4/HwYMH7a7Xt29ffPPNN9zvISEh+OWXX/DUU08hJiYGAwcOxK5du+65Xrdu3YqUlBRERUWhb9+++Oqrr+z2r1ixAgMHDkR0dDSSkpLw5JNPcvu2bNmCESNGICYmBgkJCZg1axY0Gs09l+VuXMoM/fjjj9BoNFi2bBkCAgIwf/58/PWvf0VcXBy2b9+OHTt24M0332yusj5wuGDIpZCUEEKIS/Q6mF+ov9/r3eeovne8z38DxI0baLR06VJkZmYiPj4ef/vb3wAAV65cAQB88MEHeOeddxAeHg6FQoH8/HwMHz4cr732GkQiEdasWYN58+bh4MGDCAkJqfcen3zyCd566y289dZb+P777/HCCy8gNTUV3t7eTXpc586dw7PPPouXX34ZkydPRlpaGhYvXgxvb2/MmjULZ8+exTvvvIN///vf6NWrF1QqFTdNT1FREZ5//nm8+eabGDduHGpqapCamtqkwLGpXF6OY/To0YiNjeUWZGVZFkKhEJMnT0Zubi5WrFiBN954o1kK+6Ch0WSEEEIay8vLCyKRCBKJBAEBAQCA69evAwBeffVVDBkyhDvW29sbCQkJ3O+LFi3Cjh07sGvXLsybN6/ee8ycORNTp04FALz++uv47rvvcObMGaSkpDSprP/9738xaNAg/PWvfwUAxMTE4Nq1a/jqq68wa9Ys5OXlQSaTYeTIkfDw8EBoaCi6d+8Og8GA4uJiGI1GjB8/HqGhoQCAzp07N+n+TeVSMKTT6bgnRCqVAoBdGqtTp060UGsDaGkyQghpA0RiS4amHi26HIfItTW1rLp162b3u1qtxscff4w9e/ZwwYVWq0VeXl6D17ENOmQyGTw9PVFaWtrk8ly7dg1jxoyx29a7d298++23MJlMGDJkCEJDQ9G/f38MGzYMKSkpmDRpEoRCIbp06YJBgwZhxIgRGDp0KIYOHYoJEyZAqVQ2uRyN5VIDjZ+fH8rKygAAfD4fPj4+uHbtGrc/NzcXIpHItRI+wNi6KajdWg5CCGnPGIYBI5a4518zvf/fOSps6dKl2LFjB15//XWsW7cOu3btQnx8/F0XQhUKhQ51c+fAqObg4eGBHTt24IsvvkBgYCD+9a9/ISUlBZWVleDz+Vi1ahV++ukndOrUCd9//z2GDBmCW7duNXs5rFwKhrp27Wq3FMewYcOwdetWfPXVV/jPf/6DnTt3omfPni4X8oFFHagJIYQ0gVAobFRwkpaWhocffhjjxo1D586dERAQgNzc3FYooUXHjh1x8uRJu20nT55EdHQ0+Hw+AEAgEGDIkCF46623sHv3buTk5ODIkSMALEFY79698be//Q07d+6EUCjE9u3bW6y8LjWTTZ06FdevX4fBYIBQKMS0adNQUVGB1NRU8Hg8DBo0CE888URzlfWBQ6PJCCGENEVYWBjS09ORk5MDuVxeb2AUFRWF7du3Y9SoUWAYBh999FGLZHjq88wzz2D8+PH4v//7P0yePBmnTp3C999/jw8++AAA8Mcff+DWrVvo27cvlEol9uzZA7PZjJiYGJw+fRqHDx/G0KFD4efnh9OnT6O8vBwdO3ZssfK6FAz5+fnBz8+P+10kEuHZZ5/Fs88+63LB2gPqQE0IIaQpnnnmGbz00ksYNmwYtFotPvnkE6fHLVmyBC+//DKmTJkCHx8fPP/889xAp9aQmJiIr776Cv/617/w6aefIiAgAK+++ipmzZoFAFAoFNi+fTs++eQTaLVaREVF4euvv0ZcXByuXbuG1NRUfPvtt6ipqUFISAjeeecdDB8+vMXKy7D3OFZNp9Nh4cKFmDp1KiZPntzc5WqTSkpKmrUTXWGeAScPq+Hty8egkZ7Ndl3iiGEYBAcHo6CgoEWHZ7Z3VM+th+raNVVVVfDy8mrUsS3agZpwXKnn+p5PoVAIf3//u55/z32GxGIx+Hw+xOLm6QnfHlEzGSGEEOJ+LnWg7tu3L44fP07fSu4VLcdBCCHkPvDaa6+hY8eOTv+99tpr7i6ey1zqMzRgwAB89913eO+99zBixAj4+/s7HUofHR3tym0eWJQZIoQQcj949dVX6+0P7Ol5/3fzcCkYeu+997ifL126VO9xq1evduU2DyyWZl0khBByH7hzwNSDxqVgiFajdw1lhgghhBD3cykYGjZsWDMVo32iYIgQQghxP1ov3Y1Y6kBNCCGEuJ1LmaEvv/zyrscwDEPNafWgzBAhhBDifi4FQxcuXHDYZjaboVKpYDab4eXlRfMQNYCCIUIIIcT9XAqGvvjiC6fbjUYjdu/eja1bt+Ltt9925RYPNlqOgxBCSCvq27cvnn76acyfP/+ux4aEhOC7777D2LFjW6Fk7tUifYYEAgHGjh2LpKQkfPfddy1xiwcCZYYIIYQQ92vRDtQRERENzj/U3nETd1M0RAghhLhNiwZD586doz5DDaDMECGEuB/LstAazfX/MzSwz8V/TVnO6qeffkKPHj1gNpvtts+bNw8vv/wysrOzMW/ePCQlJaFjx44YP348Dh482Gz1dOnSJTz88MOIiYlBQkICFi1aBLVaze0/evQoJkyYgNjYWHTu3BlTpkxBbm4uAEsf4xkzZqBTp06Ii4vD2LFjcfbs2WYrm6tc6jO0Zs0ap9vVajUuXbqErKwsTJkyxZVbPNAoMUQIIe6nM7GYtfqqW+69elYnSASN+xCYOHEi3n77bRw5cgSDBw8GAFRUVGD//v1YuXIl1Go1hg8fjtdeew0ikQhr1qzBvHnzcPDgQYSEhLhUTo1Gg0cffRQ9e/bE1q1bUVpaildffRVvvvkmli9fDqPRiKeeegpz5szBF198AYPBgPT0dG7qmBdffBEJCQn4f//v/4HH4+HChQsQCFwKQZqVSyX5/fffnW6Xy+UIDAzE/PnzMWLECFdu8UBjzdSBmhBCSOMolUqkpKRgw4YNXDC0detW+Pj4YODAgeDxeEhISOCOX7RoEXbs2IFdu3Zh3rx5Lt17/fr10Ol0+PTTTyGTyQAA77//PubOnYs333wTAoEAVVVVGDlyJCIjIwEAHTt25M7Py8vDs88+i9jYWABtb81Sl4IhWnPMNdRMRggh7ifmM1g9q1O9+4UCIQxGQ4vduymmTZuGRYsW4YMPPoBYLMb69esxefJk8Hg8qNVqfPzxx9izZw+Ki4thNBqh1WqRl5fncjmvXbuGzp07c4EQAPTu3Rtmsxk3btxAv379MHPmTDz66KMYPHgwBg8ejEmTJiEwMBAAsGDBArz66qtYu3YtBg8ejIkTJ3JBU1vQ5mag3rFjB55//nk8+uijWLx4Ma5fv96o844cOYKZM2fin//8p912lmWxevVqLFiwAI8++ij+/ve/o6CgoCWK3mQ0AzUhhLgfwzCQCHj1/xM2sM/Ff019/x81ahRYlsWePXuQl5eH1NRUTJ8+HQCwdOlS7NixA6+//jrWrVuHXbt2IT4+Hnq9viWqzcH//d//YdOmTejVqxc2bdqEwYMH49SpUwCAV155BXv37sWIESNw5MgRpKSkYPv27a1SrsZwKRg6d+4cfvnll3r3//rrr8jIyGj09Y4ePYqVK1dixowZ+PDDDxEREYFly5ahsrKywfOKi4vx448/onPnzg77Nm7ciO3bt2P+/PlcJL1s2bJWe3E0iDJDhBBCmkAikWDcuHFYv349Nm7ciJiYGCQmJgIA0tLS8PDDD2PcuHHo3LkzAgICuA7MrurYsSMuXboEjUbDbTt58iR4PB5iYmK4bV27dsWLL76ITZs2IS4uDhs2bOD2xcTEYMGCBfj1118xbty4NtW65FIwtHbtWpSVldW7v7y8HGvXrm309bZs2YIRI0YgJSUFoaGhmD9/PkQiEfbt21fvOWazGZ999hlmzpyJgIAAu30sy2Lbtm2YPn06evfujYiICLzwwguoqKjAyZMnG12ulsKNIaBgiBBCSCNNmzYNe/bswapVqzBt2jRue1RUFLZv346MjAxcuHABzz//vMPIs3s1ffp0iMVi/OUvf8Hly5dx5MgRvP3223jooYfg7++PW7du4R//+AfS0tKQm5uLAwcOICsrC7GxsaitrcWbb76Jo0ePIjc3FydPnsTZs2ft+hS5m0t9hm7duoX+/fvXuz8mJganT59u1LWMRiMyMzMxdepUbhuPx0NiYiKuXq2/l/+aNWvg5eWF4cOHO8xpVFxcDJVKhW7dunHbZDIZYmNjcfXqVQwcONDpNQ0GAwyGuvZhhmEglUq5n5uLtZmMx1BTWUuz1i/Vc8uiem49VNft16BBg6BUKnHjxg27YGjJkiV4+eWXMWXKFPj4+OD5559HTU1Ns9xTKpXi559/xjvvvIMJEyZAIpFgwoQJWLJkCbf/+vXr+P3331FRUYGAgADMnTsXjz/+OIxGIyoqKvCXv/wFpaWl8PHxwbhx4/DKK680S9msXPlbcCkYMhqNMBqNDe7X6XSNulZVVRXMZjOUSqXddqVSifz8fKfnXL58GXv37nXoJ2SlUqkAAAqFwm67QqHg9jmzfv16u2kDoqKi8OGHH8Lf3//uD6QJsq8VAdBC7uGB4ODAZr02cS4oKMjdRWgXqJ5bD9X1vamtrYVQKGz08U05tjWcP3/eYVt0dLRdsxQAh2U3GpugACwJBVvdunVzuL5Vhw4dsHLlSqf7xGIxvvnmm0bd817rWSQSITg4+J7OBVwMhsLCwnDixAlMnDjRYR/LskhNTUVoaKgrt6hXbW0tPvvsMzzzzDPw8vJq1mtPmzbN7jFZo82SkpIGg7+mUtdY2l41GnWb6dT9oGIYBkFBQSgsLGzSJGekaaieWw/VtWv0er1dC0BDhEJho48l986Vetbr9U4/RwUCQaMSGS4FQ2PHjsUXX3yBTz75BDNmzOAmdcrNzcWaNWtw9epVLFy4sFHX8vLyAo/Hc8jYqFQqh2wRABQVFaGkpAQffvght836hjB79mwsX76cO6+yshLe3t7ccZWVlQ0O6RMKhfVGp835pmO26UBNb2atg2VZqutWQPXceqiuyb1Yt24dXnvtNaf7QkNDG+yr21a58nfgUjA0ZMgQFBUVYe3atUhNTQWPZ+mPbTabwTAMHnroIQwbNqxxBREIEB0djYyMDPTp04e7TkZGhtMVczt06IB//etfdttWrVoFrVaLuXPnws/PD3w+H0qlEufPn+eCH41Gg+vXr2P06NH3/sCbCc0zRAghxB1Gjx6N7t27O93X1poEW4PLc2E//PDDGDx4ME6cOMG1LwYGBqJ3795NbsueOHEivvjiC0RHRyM2Nhbbtm2DTqfjAqrPP/8cPj4+mDNnDkQiEcLDw+3Ol8vlAGC3ffz48Vi3bh2Cg4MREBCAVatWwdvbG71793bhUTcT+jJHCCHEDTw8PODh4eHuYrQZzbIwSFBQECZPnuzydQYMGICqqir89ttvUKlUiIyMxOLFi7nmrtLS0ib3Fp8yZQp0Oh2+/vpraDQaxMfHY/HixRCJRC6X11XWlB5lhgghhBD3YVgXGtkyMzNx7do1jBkzxun+nTt3Ii4urk1Nue2KkpKSZu1EV1JohNkog1BSCx8/frNdlzhiGAbBwcEoKCig/hUtiOq59VBdu6aqqqrRg2+oA3XrcKWe63s+hUJhozpQuzTp4qpVq5wO77PKyMjAqlWrXLnFAy0gWIjuffzg6992Vu4lhBBC2huXgqHMzEzEx8fXu79z5864ceOGK7cghBBCCGlRLgVDtbW14PPrb95hGMZuHRNCCCGEkLbGpWAoODgYZ8+erXf/mTNnEBhIMysTQgghbU3fvn0bPTP0g86lYGj48OFIT0/HDz/8ALVazW1Xq9VYsWIFzpw5g+HDh7tcSEIIIYQAM2bMwDvvvNMs19q2bRsee+yxZrnW/c6lnrvjxo1DdnY2tm3bhu3bt3OzPFdUVIBlWQwePBgTJkxoloISQgghpGEsy8JkMkEguPvHu6+vbyuU6P7gUmaIYRg899xzePvttzFq1CiEh4cjPDwco0ePxjvvvIMXXniBVlQmhBBCmsFLL72EY8eO4bvvvkNISAhCQkKwevVqhISEYO/evRg7diyioqJw4sQJZGdnY968eUhKSkLHjh0xfvx4HDx40O56dzaThYSE4JdffsFTTz2FmJgYDBw4ELt27WpU2UwmE1555RX069cPMTExGDx4ML799luH41atWoWUlBRERUWhe/fuePPNN7l9lZWVWLRoEZKSkhAdHY3hw4fjjz/+uMfaappmGdPdtWtXdO3a1WG72WxGeno6evbs2Ry3IYQQQpqdJZtS/36GYWE0tsxcTnw+Gp00WLp0KTeK+29/+xsA4MqVKwCADz74AO+88w7Cw8OhUCiQn5+P4cOH47XXXoNIJMKaNWswb948HDx4kFtH1JlPPvkEb731Ft566y18//33eOGFF5Cammq3vqczZrMZwcHB+Prrr+Ht7Y20tDQsWrQIAQEB3KTMP/zwA5YuXYo33ngDKSkpqK6uxsmTJ7nzZ8+ejZqaGnz22WeIiIjA1atXGxyk1ZxaZIKbK1eu4NChQzh+/Diqq6uxevXqlrgNIYQQ4jKTCdi+ttIt9x73kAKNaNECYFnQXCQSQSKRICAgAABw/fp1AMCrr76KIUOGcMd6e3sjISGB+33RokXYsWMHdu3ahXnz5tV7j5kzZ2Lq1KkAgNdffx3fffcdzpw5g5SUlAbLJhQKuQANsCyLderUKWzevJkLhv79739jwYIFePrpp7njkpOTAQCHDh1Ceno69u/fj5iYGABARETE3aqk2TRbMJSbm4vDhw/j8OHDKCkpgUQiQVJSEmWFCCGEkBbWrVs3u9/VajU+/vhj7NmzB8XFxTAajdBqtcjLy2vwOp07d+Z+lslk8PT0RGlpaaPKsGLFCqxatQp5eXnQarUwGAxcQFZaWorCwkIMGjTI6bkXLlxAhw4duECotbkUDJWXl+PIkSM4fPgwsrOzIRKJoNfrMXv2bEyaNKlRHbgIIYQQd+LzLRma+rTkchzN1Qokk8nsfl+6dCkOHTqEt99+G5GRkZBIJFiwYAH0en2D17lzxXqGYWA2m+96/40bN+Lvf/873n77bfTq1QtyuRz/+c9/kJ6eDgCQSCQNnn+3/S2tydGKRqPB8ePHcfjwYVy6dAkikQg9e/bErFmzEBAQgFdeeQUdOnSgQIgQQsh9gWGYBpuqBAIGLNs2BgMJhcJGBSdpaWl4+OGHMW7cOACWTFFubm6LlevkyZPo2bMn5s6dy227efMm97OHhwfCwsJw+PBhDBw40OH8zp07Iz8/Hzdu3HBLdqjJEcuCBQsAAN27d8ef//xn9OzZk1sBvrCwsHlLRwghhBBOWFgY0tPTkZOTA7lcXm9gFBUVhe3bt2PUqFFgGAYfffRRo4KoexUVFYU1a9Zg//79CAsLw9q1a3H27FmEhYVxx7z88st444034Ofnh5SUFKjVapw8eRJPPvkk+vfvj/79+2PBggVYsmQJIiMjcf36dTAMc9f+Ss2hyUPrDQYD5HI5AgICEBgYyAVChBBCCGlZzzzzDHg8HoYNG4bExMR6+wAtWbIECoUCU6ZMwdy5c7njW8pjjz2GcePGYeHChZg0aRIqKirwpz/9ye6YmTNn4t1338UPP/yA4cOH409/+hOysrK4/f/73/+QlJSE5557DikpKVi2bBlMDQ3za0YMy7JNGi+Yl5eHQ4cOcR2lg4KCMHDgQAwcOBB8Ph9/+ctf8PLLL6Nv374tVWa3KSkpadZ2Y4ZhEBwcjIKCAjTxaSBNRHXdOqieWw/VtWuqqqrg5eXVqGNbss8QqeNKPdf3fAqFQvj7+9/1/CY3k4WEhGD27NmYPXs2Ll++jEOHDmHnzp1Yu3YtN9Svurq6qZclhBBCCHELl3o5x8fHIz4+Hk8++STS09Nx8OBBVFRU4JtvvsGmTZvQq1cv9OzZ026uA0IIIYTcX1577TWsW7fO6b7p06fjww8/bOUSNa8mN5PdTW1tLVJTU3Ho0CFcuHABLMs+MJMuUjPZ/YvqunVQPbceqmvXUDNZ05SWltbb6uPp6Qk/Pz+X73FfNZNVVlZCoah/PgapVIphw4Zh2LBhKC8vx9GjR5t6C0IIIYS0IX5+fs0S8LRV9zS0PiYmBj169ECPHj0QHR1d77E+Pj6YOHGiSwUkhBBCCGlJTQ6GXn31VaSnp2Pv3r34/fffoVAokJycjJ49e6Jbt26QSqUtUU5CCCGEkBbR5GCoV69e6NWrFwDg1q1bOH36NNLT07F8+XIwDIO4uDgua9TQyriEEEIIIW2BS6PJwsPDER4ejqlTp0Kj0eDMmTNIT0/Hpk2b8NNPPyEgIADdu3dHjx49kJCQ4LDmCSGEEEKIuzXbAmIymQwDBgzAgAEDAADXr1/nska7du3CjBkzMGPGjOa6HSGEEEJIs2ix1VRjY2MRGxuLmTNnorKyEhqNpqVuRQghhJBG6Nu3L55++mnMnz/f3UVpU1wKhkpLS1FaWor4+HhuW3Z2NrZs2QKDwYCBAweiT58+UCgUDQ7HJ4QQQghxlyYv1Grrf//7H37//Xfud5VKhffeew+pqam4dOkSPv74Y6SmprpcSEIIIYSQluJSMHTjxg27VXAPHjwIvV6Pjz76CF999RUSExOxefNmlwtJCCGEtHc//fQTevToAbPZbLd93rx5ePnll5GdnY158+YhKSkJHTt2xPjx43Hw4MF7vt/XX3+NESNGIDY2Fr169cIbb7wBtVptd8zJkycxY8YMxMTEoEuXLpgzZw5UKhUAwGw248svv8TAgQMRFRWF3r1749NPP73n8rQkl4Khmpoau+avU6dOoUuXLggKCgKPx0OfPn2Ql5fnciEJIYSQlsKyLAwGg1v+NWUplYkTJ6KiogJHjhzhtlVUVGD//v2YNm0a1Go1hg8fjtWrV2Pnzp0YNmwY5s2bd8+fwzweD0uXLsW+ffuwfPlyHDlyBO+//z63PyMjA7NmzULHjh2xadMmrF+/HqNGjeKCtX/84x/44osv8Je//AX79u3DF1980ailMdzBpT5DXl5eKCkpAQCo1Wpcu3YNc+bM4fabzWaHCJYQQghpS4xGI/7zn/+45d4LFy5s9LQzSqUSKSkp2LBhAwYPHgwA2Lp1K3x8fDBw4EDweDy7hdEXLVqEHTt2YNeuXZg3b16Ty2bbyTosLAyLFi3C66+/jn/84x8AgP/85z/o1q0b9zsAxMXFAbAkS7777ju8//77mDlzJgAgMjISffr0aXI5WoNLwVBiYiK2b98OmUzGLcpq+0Bzc3Ph6+vrciEJIYQQAkybNg2LFi3CBx98ALFYjPXr12Py5Mng8XhQq9X4+OOPsWfPHhQXF8NoNEKr1d5zZujgwYP4/PPPcePGDVRXV8NkMkGr1aK2thZSqRQXLlyod8mta9euQafTYdCgQa483FbjUjA0Z84cFBQU4Mcff4RAIMDjjz+OgIAAAIDBYMCxY8cwcODAZikoIYQQ0hIEAgEWLlxY7/6WXLVeIGjax/CoUaPAsiz27NmDpKQkpKam4t133wUALF26FIcOHcLbb7+NyMhISCQSLFiwAHq9vsnlysnJwdy5c/H444/jtddeg1KpxMmTJ/HKK69Ar9dDKpVCIpHUe35D+9oil4IhpVKJv//979BoNBCJRHZPKsuyePvttx/oVW4JIYTc/xiGabCpqi2tniCRSDBu3DisX78e2dnZiImJ4QYypaWl4eGHH8a4ceMAWLqv5Obm3tN9zp07B7PZjCVLloDHs3QvvnNAVOfOnXH48GH87W9/czg/KioKEokEhw8ftus+01Y1y6SLMpnMYZtIJEJkZGRzXJ4QQgght02bNg1z587FlStXMH36dG57VFQUtm/fjlGjRoFhGHz00Uf33G83MjISBoMB//vf/zBq1CicPHkSP/74o90xL7zwAkaOHIk33ngDjz/+OEQiEY4cOYJJkybBx8cHzz//PJYtWwahUIjevXujrKwMV69exSOPPOLS428JLo0mO3/+PDZt2mS3be/evVi4cCHmz5+PFStWUAdqQgghpBkNGjQISqUSN27cwLRp07jtS5YsgUKhwJQpUzB37lwMGzbMbvqbpkhISMCSJUvw5ZdfYvjw4Vi/fj3eeOMNu2NiYmLwyy+/4OLFi5g4cSImT56MXbt2gc/nAwBeeuklLFiwAP/6178wbNgwLFy4EKWlpff+wFsQwzZlXN8d3nnnHfj5+eHPf/4zAMsq9q+99hrCw8MRFBSE48eP45FHHsHUqVObq7xuVVJS0qztxgzDIDg4GAUFBU0aXkmajuq6dVA9tx6qa9dUVVXBy8urUce2ZJ8hUseVeq7v+RQKhY0azu9SZigvLw8xMTHc7wcPHoRUKsXSpUvx17/+FSNGjHBpwidCCCGEkJbmUp8hrVYLqVTK/X7mzBkkJydDLBYDsCzWeujQIddKSAghhJBmtW7dOrz22mtO94WGhmLfvn2tXCL3cikY8vPzw40bNzB8+HAUFhYiJyfHbs6BmpqaNtULnxBCCCHA6NGj0b17d6f72uPntkvB0KBBg7BmzRqUl5cjNzcXcrkcvXv35vZnZmYiODjY5UISQgghpPl4eHjAw8PD3cVoM1wKhqZPnw6j0Yj09HT4+fnhueeeg1wuB2DJCl24cAHjx49vloISQgghhLQEl4IhPp+PRx55xOmcAR4eHvjmm29cuTwhhBDSYsxmMzehILl/NccUPs0y6SJg6UxtnT/Az8/vvpuKmxBCSPshk8lQXV0NT09PCojuY2azGdXV1Vyr1L1yORi6fv06fv75Z1y+fJmLzng8HuLj4/HYY4/ZDb0nhBBC2gKBQAC5XI6ampq7HisSie5pfS/SNPdaz3K5vMlrvN3JpbOvXbuGd999FwKBAMOHD0dISAgAy/xDR44cwZIlS/Duu+8iNjbWpUISQgghzU0gENx14kWa3LJ1uLueXQqGVq1aBR8fH/z973+HUqm02/fwww/j7bffxq+//oq3337bldsQQgghhLQYlxpKr127hlGjRjkEQoBlRfuRI0fi2rVrrtyCEEIIIaRFuRQMMQwDk8lU736z2QyGYVy5BSGEEEJIi3IpGIqLi8POnTtRUlLisK+0tBS7du1CfHy8K7cghBBCCGlRLvUZeuSRR7BkyRK89NJL6NOnDzfbdH5+PtLS0sDj8ZzOQUQIIYQQ0la4FAxFRUXhgw8+wK+//oq0tDRuSJxIJEJycjIefvhheHp6NktBCSGEEEJagsvzDIWGhuLVV1+F2WxGVVUVAMDLyws8Hg/r1q3D6tWrsXr1apcLSgghhBDSEpptBmoej+d0VBkhhBBCSFtGc5ATQgghpF2jYIgQQggh7RoFQ4QQQghp15rcZygzM7PRx5aXlzf18oQQQgghrarJwdAbb7zREuUghBBCCHGLJgdDCxcubIlycHbs2IHNmzdDpVIhIiICTz75ZL2r3qempmL9+vUoLCyEyWRCUFAQJk2ahCFDhnDHfPHFFzhw4IDdeUlJSXjzzTdb9HEQQggh5P7Q5GBo2LBhLVAMi6NHj2LlypWYP38+OnbsiK1bt2LZsmVYvnw5FAqFw/EeHh6YPn06OnToAIFAgNOnT+PLL7+El5cXkpOTueOSk5Px3HPPcb8LBM02owAhhBBC7nNtqgP1li1bMGLECKSkpCA0NBTz58+HSCTCvn37nB6fkJCAPn36IDQ0FEFBQRg/fjwiIiJw+fJlu+MEAgGUSiX3z8PDozUeDiGEEELuA20mRWI0GpGZmYmpU6dy23g8HhITE3H16tW7ns+yLDIyMpCfn49HH33Ubt/Fixfx9NNPQy6Xo2vXrpg9e3aDy4QYDAYYDAbud4ZhIJVKuZ+bi/VazXlN4hzVdeugem49VNetg+q5dbi7nttMMFRVVQWz2ewwi7VSqUR+fn6952k0GjzzzDMwGo3g8Xh46qmn0K1bN25/cnIy+vbti4CAABQWFuLXX3/FBx98gGXLloHHc54YW79+PdasWcP9HhUVhQ8//BD+/v6uPch6BAUFtch1iSOq69ZB9dx6qK5bB9Vz63BXPbeZYOheSSQSfPTRR9BqtTh//jxWrlyJwMBAJCQkAAAGDhzIHRseHo6IiAi8+OKLuHDhAhITE51ec9q0aZg4cSL3uzVSLSkpgdFobLayMwyDoKAgFBYWgmXZZrsucUR13TqonlsP1XXroHpuHS1VzwKBoFGJjDYTDFkXd1WpVHbbVSpVg2ue8Xg8LpKMjIxEXl4eNmzYwAVDdwoMDISnpycKCwvrDYaEQiGEQqHTfS3xx8CyLP2RtRKq69ZB9dx6qK5bB9Vz63BXPbeZDtQCgQDR0dHIyMjgtpnNZmRkZKBTp06Nvo7ZbLbr73OnsrIy1NTUwNvb26XyEkIIIeTB0GYyQwAwceJEfPHFF4iOjkZsbCy2bdsGnU7HDef//PPP4ePjgzlz5gCw9O2JiYlBYGAgDAYD0tPTcejQITz99NMAAK1Wi99//x19+/aFUqlEUVERfvrpJwQFBSEpKcldD5MQQgghbUibCoYGDBiAqqoq/Pbbb1CpVIiMjMTixYu5ZrLS0lK7nuY6nQ7ffvstysrKIBKJEBISghdffBEDBgwAYGlCu3XrFg4cOAC1Wg0fHx9069YNs2bNqrcZjBBCCCHtC8NSI2ijlZSUNNgE11QMwyA4OBgFBQXUFt3CqK5bB9Vz66G6bh1Uz62jpepZKBQ2qgN1m+kzRAghhBDiDhQMEUIIIaRdo2CIEEIIIe0aBUOEEEIIadcoGCKEEEJIu0bBECGEEELaNQqGCCGEENKuUTBECCGEkHaNgiFCCCGEtGsUDBFCCCGkXaNgiBBCCCHtGgVDhBBCCGnX2tSq9e2N+dRRqIpyYY7sBKZzkruLQwghhLRLlBlyI/bCaVSv+xG4cdndRSGEEELaLQqG3EkgBACwJqObC0IIIYS0XxQMuROfb/nfSMEQIYQQ4i4UDLkT/3aXLZPJveUghBBC2jEKhtzJmhmiZjJCCCHEbSgYciOGMkOEEEKI21Ew5E4CazBEmSFCCCHEXSgYcidqJiOEEELcjoIhd6JmMkIIIcTtKBhyJ8oMEUIIIW5HwZA7WTNDNM8QIYQQ4jYUDLkTnzpQE0IIIe5GwZA7CazNZNRniBBCCHEXCobc6XZmiNYmI4QQQtyHgiF34lNmiBBCCHE3CobciTpQE0IIIW5HwZA7UQdqQgghxO0oGHInmnSREEIIcTsKhtyIoUkXCSGEELejYMidKDNECCGEuB0FQ+5knWeIOlATQgghbkPBkDtRB2pCCCHE7SgYcidqJiOEEELcjoIhd6IO1IQQQojbUTDkTpQZIoQQQtyOgiF3sskMsSzr3rIQQggh7RQFQ+4kENb9TNkhQgghxC0oGHIna2YIoGCIEEIIcRMKhtzJ2mcIoE7UhBBCiJtQMOROlBkihBBC3I6CITdieDyAd/spMBncWxhCCCGknaJgyM0YaydqygwRQgghbkHBkLvRkhyEEEKIW1Ew5GaMgCZeJIQQQtyJgiF3s2aGaOV6QgghxC0oGHKzuswQBUOEEEKIO1Aw5G7UTEYIIYS4FQVDbkaZIUIIIcS9KBhyM4ZWrieEEELcioIhdxNQB2pCCCHEnSgYcjOG5hkihBBC3IqCIXcT0gzUhBBCiDtRMORm1swQS5khQgghxC0oGHIzmoGaEEIIcS8KhtzNulCrkVatJ4QQQtxB4O4C3GnHjh3YvHkzVCoVIiIi8OSTTyI2NtbpsampqVi/fj0KCwthMpkQFBSESZMmYciQIdwxLMvit99+w549e6BWqxEfH4+nn34awcHBrfWQGsT3C7D8UFLo3oIQQggh7VSbCoaOHj2KlStXYv78+ejYsSO2bt2KZcuWYfny5VAoFA7He3h4YPr06ejQoQMEAgFOnz6NL7/8El5eXkhOTgYAbNy4Edu3b8fzzz+PgIAArF69GsuWLcMnn3wCkUjUyo/QkTDCEuixudnuLQghhBDSTrWpZrItW7ZgxIgRSElJQWhoKObPnw+RSIR9+/Y5PT4hIQF9+vRBaGgogoKCMH78eERERODy5csALFmhbdu2Yfr06ejduzciIiLwwgsvoKKiAidPnmzNh1YvUVRHyw952W4tByGEENJetZlgyGg0IjMzE4mJidw2Ho+HxMREXL169a7nsyyL8+fPIz8/H126dAEAFBcXQ6VSoVu3btxxMpkMsbGxjbpmaxBG3m4CLC8Fq65xb2EIIYSQdqjNNJNVVVXBbDZDqVTabVcqlcjPz6/3PI1Gg2eeeQZGoxE8Hg9PPfUUF/yoVCoAcGhiUygU3D5nDAYDDIa6Ds0Mw0AqlXI/NxeGYcCTewC+AUBZMZCbBSa+291PJE1mfd6a8/kjjqieWw/Vdeugem4d7q7nNhMM3SuJRIKPPvoIWq0W58+fx8qVKxEYGIiEhIR7vub69euxZs0a7veoqCh8+OGH8Pf3b44iO5Al9oBm/w7IMy9DmTKmRe5BLIKCgtxdhHaB6rn1UF23Dqrn1uGuem4zwZCXlxd4PJ5DxkalUjlki2zxeDyu8iIjI5GXl4cNGzYgISGBO6+yshLe3t7cOZWVlYiMjKz3mtOmTcPEiRO5362RaklJCYzNuIYYwzAICgqCrnN3YP8OVB/6A5pxD9M3kBZgrevCwkKwLOvu4jywqJ5bD9V166B6bh0tVc8CgaBRiYw2EwwJBAJER0cjIyMDffr0AQCYzWZkZGRg7Nixjb6O2WzmmrgCAgKgVCpx/vx5LvjRaDS4fv06Ro8eXe81hEIhhNZlMu7QIn8MXXsAQhFQUgj23EmgW+/mvwcBYHn+6A2t5VE9tx6q69ZB9dw63FXPbaYDNQBMnDgRe/bswf79+5Gbm4tvv/0WOp0Ow4YNAwB8/vnn+OWXX7jj169fj3PnzqGoqAi5ubnYvHkzDh06hMGDBwOwRJrjx4/HunXrkJaWhlu3buHzzz+Ht7c3evd2f8Dx2/lSzP4+FfvzdGCGjgMAmD9/H+YNP9EfHSGEENJK2kxmCAAGDBiAqqoq/Pbbb1CpVIiMjMTixYu55q7S0lK7JiSdTodvv/0WZWVlEIlECAkJwYsvvogBAwZwx0yZMgU6nQ5ff/01NBoN4uPjsXjx4jYxx1Cl1ogbpWpk+4sxdNpjYG9cArKugt36GxAUCqbfMHcXkRBCCHngMSylIBqtpKTEbpSZq3ZcU+E/JwrRK8QDbw8LBWsygV2zAuzujYCHF3gf/BeMVNZs92vPGIZBcHAwCgoKKOvWgqieWw/Vdeugem4dLVXPQqGwUX2G2lQzWXsTprBkp3IqdQAAhs8H89CfgKAQoKYK5j/Phunz98GWFbuzmIQQQsgDjYIhNwpTiAEAxTUG6IxmAJZV7HkPza076OwJmJe8APPmVTDv3ghWr3NDSQkhhJAHV5vqM9TeKCQCKKRCVNYakFelR7SPBADAJPcF7/V/AqpymHdvAq5fBLvpdsfxW1nAvL/Q8HtCCCGkmVBmyM2ifS19gq6Xa+22MzHxYHoOAO+V94G4uiVK2GN7wW78GaxG3arlJIQQQh5UFAy5Wb9IXwDAlssVMDvpNMYIBOC99B54b/0fmKmPAQDYrb/B/OpcmDevAms2tWp5CSGEkAcNNZO52YzuIViRmo2blTocvlmNIZFeDscwAgEQEQOERQE11WCP77X8v+kXS/OZ0hfoEA5IpeBNngOmQ7gbHgkhhBByf6LMkJt5SYSY1tkHAPCfE4U4kVtd77EMjwferKfA++QnME/+FRBZOmBDVQZcTAdOHYX547fAnj/VGkUnhBBCHgiUGWoDHkrwxaGbVcip1GPZgTz0DfVAn1APjIxROj2eYRj8//buO76t+t7/+OvIkiVLsi3vvUemHYckBEIgQFL26CAphLRs6GX1ctsyA2VzodDyo0BLIYGGslIus4QQZnbIJImzbcex471kWXuc8/tDiYJxAgGCHePP8/HggXR0dPTVR7L9zvf7Pd+jHH8KWm4h6psvQpQexWxBW/kpOOyoT9yDMuFEtMY6MFvQnXsRFI9EOcQlRoQQQoihTBZd/BaO9KKLX15kqscbZPbHdezuOnDq/Am5sex1+LmwLIlJuX2Hz75KczvR3piHtnhh3wdT0lHOvxjqqsHlBGssyhm/QLF+83F/DGThtP4hde4/Uuv+IXXuHwO96KL0DB0lrMYoZo1J4b7P9ka2La8LD5k9/XkzJUkxdHqCDEuOOeQxFLMVLv4vSM9CW78SovRg74TmveGLwD73WK/9tQ/ehIJSdP99d/i5QgghxBAkYegoMjbDwkl5cXiCKkFVwx0IsaPdS49f5cq3qgG4+cRMxqRbsEZHHfQYiqKgTDsfpp0f2aa5nKgvPAFfrILSUSgjx6ItXQQdrbB7J+pvZ8KoseHwFPCDoqDEJ6KcchZk5EB0NIru4K8nhBBCDHYSho4iUTqF303O7LVtS4ub2z+qi9x/ZGkjlmgdj52RT0bswS82u8fuo8Md4JjMcG+PYrGiu/a2cPhJTEHR6dBO/xna50vQ5v0VVBW2bOh1DI3wmkYRecXoLrwKvB5ISkXJyEbzuOXaaUIIIQY9CUNHuVFpZm44Lp1/rGnBFwqPo7r8Krcu2kNijJ7ceCOT8mIpSzNjNkTh8oe448M99PhVZk/JZkL2vkCkKDhjk7HsW7la0RtQTpiKllcIrU1oDju0t6BtXINSOjp8f+PnsH/sdk8V6sO3HKSBY1GGl+8bkuuAaCNKfikUDwezVVbKFkIIcdSTMDQITCuyMa3Ixp0f1bGpxQ2A3RvC7g1R0+Xjs1oHZoOOK8al0uEO0uMPX+fsmTXNBNRUChJMLN7t4JXN7VxSkUKuzcjaBifTRydhSM4hLruASGS54LLI6waDQYI+P0ZXN+or/4BtG8On8/s84d4kgC0b0A7SqwTAyLHofjoLQoFwj1RieBKbVrUVrasDJTUTcgslMAkhhBhQcjbZt/BDnk12OB+DL6jiCah0eoK8s70Td0BF1aCu20eL8/DapfClsAJYo3U8cXYBSWYDuzo8PLqskVljUpicF8sDixvY3OLm8bPCQ3KaGgJFBw21aCs+CS/0WL8bbdki8PshNSPcQ9RUf/AXj08ERQn3IO1XUIoyeVr4dpQexZYEI8aA3wd6PTh7wGRCMfUdjtM07bCDlJwR0j+kzv1Hat0/pM79Q84mE4fNqNdh1Ouwxej570kH5hapmsarm9t5bXM4ZAxLNvGbCenc/mEdnqDa6xhf/Yo5/Sp3fFSHNTqKXR3h66M9uryRgJrBmgYnAE+sbKIw0URCjJ4RKTHoTen8O/U0fjkimZLJP0E77adg7ySYPwy9Dti9E7q7UD96G+prwWKFrnbo7gy/qE4HOYWwpwp270TbvbN3+8xW8LhB29d2RQd5ReE5SxnZUL8b9fUXIOBH99/3hAOWw47WWIcy+hgUS+wRqbcQQoihQXqGvoWB7hn6Jm9t62BlnZMbjksnO96IwxtEpyhsaXWTHW9kcW13JDAdCTZTFGeU2FhZ7+S/jk3j/61swu4JkWo10OUJMn10EhOzraRYDCheD7Q0hCdgp2agJKagrVtB60vP88Soi6iLTuQ2+xKGbV8a7hX6rmLjUcrGo7U2gaML5aezUOJsqC//HVN6Fv6conAQKygJB6iGPWjrV6DEWFBmXRu+9In4zuRf0f1Hat0/pM79Y6B7hiQMfQtHexj6JqqmUdnipssTxBajp87uo6nHT2Wrhz32vgGkONFEVWe4t6gkyYQ3qFLf7T/osXUKqId4C5mx0Vw7MY3ceCNGvY693X7+vKKR4kQTAVVjxb71lE4tjOPGMitrtzfgdzo57t8PQ3oOumv+gPrMI1BXEz6g2QqZOVC1DYB6SzqJugCWnu8X9JTJP0E57WdoqxeHV/N2u8JnzpWNQ9tTjWK2oPz6+sM+g07rcYDFiqILX/VG8/ugxwGJyT/aeVLyh6P/SK37h9S5f0gYGkQGexj6Or6gyn92dPFBlZ0WZ4BYYxQv/qKYzS1ump0BphXFo1MUdnV4eGZNC6oG1fuC0pcVJBg5o8TG31a3fOs2JJii+NMZ+Vz9djWqBhWpRqaPSmR0Zjyaw462bjlK+bEoSfsmYrucrK2z88B6J7YYPfceZyN2y2rau10Uulugpzu84GRHGy1JeaQW5KELeNFqd+Hr7KAlIZdcYxAlvwRtxceRdvh1elYnj2JM5y5ig+7ejTRbIS4eDNGQkg5dHdBYh3LsSWBLBFMMeL1o1dth2xfhs/HyS8Bsgfrd4TalZ6McdzLahlUoWXkoZ09Hq9mBUjIK4hLA54msDK51tkMwEF5BXFEOe56UpqrhnjFb0rf+HL6Po+k7/WMnte4fUuf+IWFoEPkxh6H9mnv8/N/WDn4+MumQ6xgBhFSNez+t54tmN7+ZkMZ7O7vwhzQePysfsyGKd7Z3MmddK+MyLXiDKltaPYc8VrJZj8MXwh86eA1+OiKRc4cnUGf3sXSPgzq7n1xbNHqdwqKq7l777p8gfvawBM4blsAHVXa2t3nY2uYhwWzghBwrJr3CpiYnOzv9XDcxndOKbairl6B9toDW+iY+Kj6V15MnkhLs4d61T5Lm7cJXOIJgawsWZ+ch38fapBHsNadycvM6bAHnIfcLKFHcM+YqLEEPt1b+k17RRq+HYHDfbUM4CEF4CYPcQrTFC1EmTYNgAG3dckjLRElIhowclIlTwGJFW7II7dP3oKsdZdJUlIt/E74PYLbizizkHVc8J+eYyYjRoZgOrGq+f5K8O6Bi0uvQhYLQY4eEw+vNOhq/0z9WUuv+IXXuHxKGBpGhEIa+jaCq0dTjJyfeSGjfGFmULvwHU9M0trd5KEmOQSF8xtsd+yZ033BcBuMyLexs9/LsuhYuLEtmfaOTpXt6Isc26XXYTFE0H8ZZcl83RHc47jw5m50dHlbvdfa6NhyAQQc/SQ7xYbsenQI3D9dRYfKxqjVAbbuTMfEaoR1beI0CtsbnA2DWAlzi20pBqIushm3EeHogKZWPy87l3WAadT3ByPGf+vxhMrydEG0KL1kAvFh4JlviC7m18gVsQTcBdLyZezLjOraT5OtmTfJITmrZgFE9UJtWUwIPlF/Oic0buKDuE77Oi4Vn8WbuyVgDbuasuA9DfHz4zECjCXZtoZo4bht3PVOcVVxX+XK4XcPK0F35O4iNR1v5CaEP32atKZuC4yaQfspUNjQ6Wbizi6tC28hs3IGvcCSMPgbt0/fCPV6lo6CxHpwOKByG9tLf0Bx2dL+5NXyR4WAQvlgVXnLhuFNQYg9+zbxubxBrdFTkezaUDfbfH4OF1Ll/SBgaRCQMfT8NDj/uQIiSpL7XV3MHQtR0+tjY7CKoaswak0KUTmFlXQ9z17fS6gqQGKNnYraVggQT8yvb8QZVfjYiiRPyYlm918nc9a0cn2NlfJaVv69uIaBqjE6NYUpBPKXJMXSqJtZUN7NgZ9d3fg9RCiRbDIe9lIHZoKM0OYZjMiz8a2PbQXu/LioxMzI3iYVbWjg2Rc9fNh8YmitJMFCudfF/divGkJ8KrZPP9ekc217JLZXzaBs+gcW5J/CK/8DZhXNW3ItZr2PPsWdRsvwNlEB4npcGbEwo4d4xV0X2Hduxnd9tfQlz6EAIfHTkxaxIHQPA3OX3oinQbkzg7YKp1MWkcM+Gv/F+1gm8njeVHFczj9g/5KKsXwFwfOsmfrv9VbbGFxAXcFHobDxoXZamVtAUk8wvmpajP+08tMr1ULtr35seie7qP0BXJ+QVwt5a1Ff+wTqSeCjrHE42dHJDtheqtqGcNxPiE8DnDYe5bRvRanehDBuNUjwy/HPl84AxJtKz1eHy8acPqznG6OKC+B7Q61HKxxOIMuJXwRKtCw9JBvygN/TpEdN2bQVXD0rFxN7bgwEUvSF8u70lPD/M5wGjCaWgNLy9oxUSkr7x8jaHMxw61H5/DBSpc/+QMDSISBgaOCFV69UbEFQ1QqqGUb9vcrKmUdXppSDBhF6n0Ojw09jjZ1ymJXy9ti/VurrDw8Jdds4bkcDz61pZ2+giI9bA9FFJfNHsZkmtgzHpZi4YlcT7u+z0+EJ4gyoGncLWtnDvjU6BUalmtrS6I71SI1Ji+N0JmSytdbBgZxd2b4jA9+my+gZFNgP1PcFDDi8CJEQrlCg97NastB187jsAI41eju2poVo1s9SU3+uxr65N9VVjO7azIWl45L5JDeDVGYhSQ9yw/TVOav0CgOqUEj6JH8nkto3cWfEbVEUXef65e5dS0bWLgBLFtvgCRtur2WIr5K28U7D6XST4HbyTMyXyGsaQn7s2PssIxx4AvDoDj42ahTHk57Kqd0nyO/AlZ/JS8nFsM2cx0VlNdVYZOf5OvF12/pM6AYA0Twe/qllAvrOJR8ouoT4mFb0WIt/ZwEPrn0Y3sgJl4knQ2kQgJYOuvU1ELVmIW28kJeji3xUzSFN8THXtRLdjM5x8NjXHn4trzhOUNYTfN4ZodHf/ldDH/6Fy/VaGJRgwXXkTSmoGi9bXYvcEuSBHB2uXoQwrQ+tsQ3v9eZRTz0E59yIUnY5AXQ0PrWjFZDRwzRllxLXVQ6yN1FgLrYvehfRsNEcXSvEI8HrQ9tSglIxAyS3q9VlpPY7wB2o0hdf10unQQiHYuxtyCiIhLaRq/GNNMwkxei4s3zdHLxj8Xmdbal7P977OYWjlpyg6HbqJU7555yPk2/ye3tziIjfeSLxJzkr9tiQMDSIShgavr6t1SNXQKeF9AiGNT3d3U5FuIdVq6LWfqml8sMtOXbeP43NiKU+3UNPpZUOTi9OLbViNUX32397mYVubh3lftAFwYVkSS2p7aOz5mmRC+Ay8r9vnywHFbNDhC6p8TSbq48wSG+OzrNz32d7Df9JXpFr0tLqC37jfmYY2phfFcFNtPN3e0CH3+2VxDE0tXSzpMXFO/VIWZU7EH3XoeWtxfiePrvt/JPu6eTNnCi8WnQ1Aht/OI6v/whPDZ7AmeVSf5+nVIEHdN/+xumPTXCxBDw6DhTJ7NX8aNYsvEocd9DjJ3i6u2vUWu62ZvFpwOgC3b5rLMEcdIUUhPuDi1fzT+Hf+NM7eu5Rf13/EzoIJ3Jl+DgCzNz1HnrMZoxrAGgwH7vl5U1mQdQJWAjRGJ0ReN9/ZyC/2fMJfh8/g2h2vU961iwZzGiO7a3rPP4uxoLvif1A//U94iNLtDPegAT6dgbmjZjA8wcApOz8Kn2gAkJYFwNoTfsmDnekA/OvcbCwblqH9e244nJ16DnicdDz/d3z+IPOO+RU5SRYuLtCjffoeWuV6lONPCc93a6iD2Di0lkaoXA9Fw1Buug8lKgrtgzfQPnoXX0oWwcxcrKXDUbLzUbLyen0OmhpCXfgW99SZadbH8d/bXmHEzIvgmEnQ0gixcdDaBPklKIqCqmko0KtnTXM7YddWGF4e7tVLPPDH0V1bwwfdMYzPTyQn3tjne7D/d0djYyNaYx2EQpCVh6LT8caWDuq6fVw3MYNtbW7u/Lie3PhoHj+roM9QrtawJxxA07MO+Z3TQuGfDyUqKnx7TxXkFKIYDGhuF3S2omQXHNi/vQXiE8OPaxq4XXgMMXiCKklmw6FeBl9QxVlfT6LfwXJTHmaDLnIty69qcwUIhDQy4/r+LK6s72HZHgdXj0/rEwA7PUH+s72T00tspFl7P1erq4E4G4otMbJNwtAgImFo8BroWtd0elnb4OT8EYmoGoQ0jRe/aCMnPpqphTY8QZXEGD1NPX4CIY1cmxGnL8Qti/agAecOS+DzvU7cAZXLj0nF5Q/xYXU3MQYdV49PwxCl8EWTi/s+20uSWU9FuoXGHj+1XT5y4qNJtRrIiotmeHIMhYkmYqOj0Ckw+6M6KvdNbo+OUjgxLw67N8gxmRYKE0x0e0OUJpvY3eWjqsNLQYKRD6u7SY81cMGoJC75vyogPHz4t/MK2dDkJj05gZFxKq9tbueNrR2HnM91cn4cpckx1Hf7eH+X/RtrODIlhunD4ti5eQevdNsi24usCrUurVcYzDBBU9+THSNy4wzcOiWHN7Z28ElNNzog+D2/FsaQHx0anqi+f1CtATdOwzcvyaBoKr+uXsCZjSu48KQHD+t1E3wOuoxx/GLPxxjUEDEhH/nORnJczcQG3DSZU7AG3DSYU2iOSaLNlEB0KMC/is4C4OKa93k/axK/qlmAO8rE+qThaCis39fbd9fGZ8l0tzE//yeUdVWx15KKhsJbuVNQlQP/AHhmzcOkuA4sb7HZVkR1bBbn1i8lal903xJfwN1jribP1cTUpjXEBVy8XHAG9mgrD61/Cr0WorloLN3GOCp8jcR7utjV5mZx2jEszJoUOXa6p4NxnjpO2r2M4p56gkoUHx77S5aYi9mtxmANejils5KJ3j0Um4IorU3hC1UDi9PGUm9O46LATpTMHO73FvNF4jDiNR9XNX1C6sSJlAzLR/G6IT6Rptq9JLfvZfOajbxnGc7pDSsZn2Kgu/x4LmsrBuBm5wq2RCXzXkx4OPSq5G7OHp6M2taMbsyxULMd9S93gT4a5byLcG5Yw7spEzilNJn0jrrwQrRtTWiV62k12og+cRo7N+4gvXkXm8ecxuTzpmF+fDbejg4sJ01Fp+hgbw3s2AwZOeh++0e0j95F++htZk+4kZ2WLO7zLKdE7eKTrOMozE2jpGzfUK2mcecHNWxt83Jh7SJeKjwTCP88nhvnpG3Fcob5mrGNHYersZFrfRX49dE8/dOSXgFL0zR++vIOACZkWri98T+oSlS4N9Vs4R+dNhZUh+eBTsy28l/jU7FFA031qPf/LtxLePKZKOMno+SXgM9LemYmLZ1dEoaOdhKGBq+hUut2d3hulW7fv4pVTYvcPhinP0Sjw09+gpGgqmE2fLshjE3NLp5Z08KsihSOz4ntU+fXt3Tw4r5esXhjFPf/JJeaTi8uv8qZpbZI217a2Mb8yr7rRP3xlGyaegKY9ApTi2yR7R9V23tdvBjCYWnWmBRmf1wXCWBXj0+jLM3Mrg4PqgZPft4MwA3HpTNt3/F8QZXoKAVNDfGnZU2s2OuKHDMpGhxBCPReyB2AwgQj1x+XQaY1ivsXVlHZ8+0ndZujwP2VzjIdGheMSmL+lr5nLh5r9rLabTqsY6f77CR4uthmK/jmnb+GNeBCp2k4og/ec7DfaY2r8MSn4I+x4vb42WzJAeC65o+ZauyClgb+N2kqq1NGH/ZrK5qKtm84dT+dpkaGWAHOrV/CXnNqr6HaLzuleS03bJ8PhAPaHyuuAeDa7f/GFxXNnJLz+zxnSvM6uqOt1JvT6DDZ+rQp091GgyUtsm1i22Y2JZTg0Yc/m9iAi6lNq1mYOYlLq//DaU2f49UZcBrMxPudzC0+lw+yJpHq6eSpzx+OhMVmUyL/M+EmvF8J1LEBF9mu1shnGed3ct7eJYyy17AxoYQcVwuZnnasATdXTZoNQKLPzumNq3il4AxSvJ38fe+rKN1d7CSOW8fd8LV1NwV9zNy9kH/nT6PHYIlsP1ur56JsjbrFS1kSP5yFKeMij91cOY+5xecSG3Bz7t6l/L30F/ijDoSnn3Rv4b92/B9EG2nxqjxb8jOKevZybtNKNqeMYHzDOtJvvo/ukjIJQ0c7CUODl9S6f3y1zpqmsbbBxZZWN6cWxpNr69trst+Odg89vhAK8NluBycXxDEu69B/gDVN490dXWxt9XBcjpUT8+KI0im8saWDf37RxvE5sdxyYmZkuKTHF+Lad2si1+MzROkOelxvUOWeT+pJtRq44bgM1jU6eWVTO2eWJHBifiw9vlCfbv9ub5Cb3q+lwx3knGEJZMdFU93pZcboZBJioqjr9tPg8LOu0clnux3kxRuZWhTP6SU26rt9tDoDDE+J4eGlDexoP9CldXapjTNKErjr4zpU4JnzilhZWceHrRpb2w9Mej+jxMaHVfZvNVT6TXPBjpRUi4GbJmXw4OK9kYtIj7KEaPSCC32fOW+ZhiDukIJd7RvM75uaQ36cgW2fLuO9dj0b9amRxwxqgF97t1CRn0R9fA4ftSus7wof26ioDDd42eEz4FX6Dh/9XN1NZ0hPbTCa2pi0Po9/Gxl+O03Rtl7bRturqYrNwXuIYd9CVyMFBj8hs5XPgsnf+bWTQy7aoyyHfNwacOE09H18TOdONiaWfufX/Tppng5aYsLrneU5mzCoAVpNiX3C9ekNK7n5pDxcx0+VMHS0kzA0eEmt+8fRUuc6u4+suOg+8zacvhA6Hd+6B+xwX3NRlZ3po5MOOYHWF1TZ2uahPM180OUBtrS6eWDxXlx+lXGZFv5nUiZWYxR2b3hulu1Lxz3/pe2R229fPJzmHj8BVaPHF2JHu4cXv2ijMNHEjNFJ1Np9vLk1fHHn43KsFNhMnFFi45I3qg75fi4dm8ILG9oi9w06hZIkEzs7vARVjVtPzOKFDeGhp07P10/k/7KCBCOPnxXu4QipGgFV4/2dXTh8IS4sS8ao1+EPqWxodJETbyTVaqC+O7xa/qTc3ksuPLqsgaV7elCAG8usnFqe3evxJ1c18WF177XIRqTE0Ojw0+0Ld8kNS4jmoTPCc3z8IZVr3q6m0xNidGoMUzP0eDUd/9rupDjRyG0nZbOizoHdG2J5nYM9dh9fvvzj8TlWTi9J4O5PDnGx6sN0Rl4MC/ccem22sjQzUQpsbHajAVY9OL80fS+aEH4O/R2PD7q40b2WxxJPRgn4eUb5nM9TRvPXNhvDkk29Avn0UYl8sK0Nx0HCKcDYGC8bPOEeMavmJ13np0o7EHTe6JjPffpxbIgvOujzv2zOzHGk6NwSho52EoYGL6l1/5A6f3+aFg4I0Yfoudpvca2DZ9e28ofJmYxJ7zsfyekLRZYJgPBE2DZXgJGpB/Z9bFkjS/Y4SIrRU5ocw8r6Hi4dm0KezcgxmVaW1zlItRjo9oYYlhxDrDEKpz9EqzNAYaKJQCh88sHaBif/u7SBKflx/Pb4DDz7Lt0TVDX+saaFWrsPs0HH+SMSOSkv7qCTcb8Lb1Bl+R4HI1LMBz2m0xdifmU7adZoLNE6YvQ6xmdZ8QZVur0hjHoFm0nfK5hub/OwvsnJz0YkEWMI1y8hOZX21ha+nF81LTxPrd0VwBfSyIoLLwQLcN+n9axtdPHzkYm0OANsb/dwTmkCZw9LoNUV4LPdDibnxZJiMfDKpnb+s+PAch8n5Mbyh8mZ3LKojh3t4UBUmGCkpsvHqYXxjEk3MyU/DkVRcPhCWAw6onQKe+w+Hl7aQIPDz4M/yeX59eGgelxObGSo+sGf5BLy+RmWEYdRr6PNFUDVtEhPZ323j4zYaP60rIFV9c7IorQ9vhCLqrqY90U7AC9eUEKPL8TK+h7OGZbAX1Y00tQT4I+nZJNkNrCk1sFfVjQyszyZ6aOT6fYGuXVRHY09fsZnWqjIsHByQTw72j38a2MbTT0BvEGVa08s5Iw8o4Sho52EocFLat0/pM7950jU2uUP8drmdqYV20jbt37W1w1lfp1OT5A4Y1QkEHyZwxvEZNB9Y8A7Gn2XOrsDIVbVO5mcF3vY73lHu4cOdyAy967O7uOhJQ38siyJ8nQLlS1uJufFfu0cwEBIw+4NkmI5MBQYVDXe2trJ+CwL+QmHN9/MHQixu8vHyJQD63MFQiovb2pndKr5a4ev9/MEVEx65UvP1/AF1T5n3UL4+9HQE2DqmCI5m2wwkDA0eEmt+4fUuf9IrfuH1Ll/DPSp9YMvpgshhBBCHEEShoQQQggxpEkYEkIIIcSQJmFICCGEEEOahCEhhBBCDGkShoQQQggxpEkYEkIIIcSQJmFICCGEEEOahCEhhBBCDGkShoQQQggxpEkYEkIIIcSQJmFICCGEEEOahCEhhBBCDGkShoQQQggxpOkHugGDiV7/w5Trhzqu6Etq3T+kzv1Hat0/pM7940jX+XCPp2iaph3RVxZCCCGEGERkmGwAeTwebrnlFjwez0A35UdPat0/pM79R2rdP6TO/WOg6yxhaABpmsbu3buRzrkfntS6f0id+4/Uun9InfvHQNdZwpAQQgghhjQJQ0IIIYQY0iQMDSCDwcAFF1yAwWAY6Kb86Emt+4fUuf9IrfuH1Ll/DHSd5WwyIYQQQgxp0jMkhBBCiCFNwpAQQgghhjQJQ0IIIYQY0iQMCSGEEGJIk4utDKCFCxfy7rvvYrfbycvL4/LLL6e4uHigmzVobN26lXfeeYfdu3fT1dXF73//e4499tjI45qmMX/+fD7++GNcLhfDhw/nyiuvJCMjI7KP0+lk7ty5rFu3DkVRmDhxIpdddhkmk2kg3tJR6c0332T16tU0NDQQHR1NaWkps2bNIjMzM7KP3+9n3rx5rFixgkAgwJgxY7jyyiux2WyRfdrb23n22WfZsmULJpOJKVOmMHPmTKKiogbgXR19Fi1axKJFi2hrawMgOzubCy64gLFjxwJS4x/KW2+9xcsvv8xZZ53FpZdeCkitj5T58+fz+uuv99qWmZnJ448/DhxddZazyQbIihUrePLJJ7nqqqsoKSnhvffeY9WqVTz++OPEx8cPdPMGhQ0bNrBjxw4KCwt59NFH+4Sht956i7feeovrrruO1NRUXnvtNerq6vjzn/9MdHQ0AA8++CBdXV1cffXVhEIhnn76aYqKivjtb387UG/rqPPAAw9wwgknUFRURCgU4pVXXqG+vp4///nPkdD47LPPsn79eq677jrMZjNz5sxBp9Nx3333AaCqKn/4wx+w2Wz86le/oquriyeffJKpU6cyc+bMgXx7R421a9ei0+nIyMhA0zQWL17MO++8wyOPPEJOTo7U+AdQVVXFX/7yF8xmM6NGjYqEIan1kTF//nw+//xz7rzzzsg2nU5HXFwccJTVWRMD4rbbbtOee+65yP1QKKRdffXV2ptvvjlwjRrEpk+frn3++eeR+6qqaldddZX29ttvR7a5XC5t5syZ2rJlyzRN07T6+npt+vTpWlVVVWSfDRs2aDNmzNA6Ojr6r/GDTHd3tzZ9+nRty5YtmqaF63rhhRdqK1eujOyzd+9ebfr06dqOHTs0TdO09evXazNmzNC6uroi+3zwwQfar3/9ay0QCPRr+weTSy+9VPv444+lxj8Aj8ej3XjjjdrGjRu1P/7xj9rzzz+vaZp8n4+k1157Tfv9739/0MeOtjrLnKEBEAwGqampoaysLLJNp9NRVlbGzp07B7BlPx6tra3Y7XbKy8sj28xmM8XFxZEa79y5E4vFQlFRUWSfsrIyFEWhqqqq39s8WLjdbgCsVisANTU1hEKhXt/nrKwskpOTe9U6Nze3V/d3RUUFHo+H+vr6/mv8IKGqKsuXL8fn81FaWio1/gE899xzjB07ttfvCJDv85HW3NzMNddcw/XXX88TTzxBe3s7cPTVWeYMDQCHw4Gqqr0+YACbzUZjY+PANOpHxm63A/QZcoyPj488ZrfbI921+0VFRWG1WiP7iN5UVeWFF15g2LBh5ObmAuE66vV6LBZLr32/Wuuvft/3fzZS6wPq6uq44447CAQCmEwmfv/735OdnU1tba3U+Ahavnw5u3fv5qGHHurzmHyfj5ySkhKuvfZaMjMz6erq4vXXX+euu+7iscceO+rqLGFICHHY5syZQ319Pffee+9AN+VHKTMzkz/96U+43W5WrVrFU089xT333DPQzfpRaW9v54UXXmD27NmRuYPih7F/8j9AXl5eJBytXLnyqKu9hKEBEBcXh06n65NsD5aCxXezv47d3d0kJCREtnd3d5Ofnx/Zx+Fw9HpeKBTC6XTK53AQc+bMYf369dxzzz0kJSVFtttsNoLBIC6Xq9e/8rq7uyN1tNlsfYYeu7u7I4+JML1eT3p6OgCFhYVUV1ezYMECJk2aJDU+Qmpqauju7uaWW26JbFNVlW3btrFw4ULuuOMOqfUPxGKxkJmZSXNzM+Xl5UdVnWXO0ADQ6/UUFhZSWVkZ2aaqKpWVlZSWlg5gy348UlNTsdlsbN68ObLN7XZTVVUVqXFpaSkul4uamprIPpWVlWiaJkscfImmacyZM4fVq1dz1113kZqa2uvxwsJCoqKietW6sbGR9vb2XrWuq6uL/CID2LRpEzExMWRnZ/fPGxmEVFUlEAhIjY+gsrIyHn30UR555JHIf0VFRUyePDlyW2r9w/B6vTQ3N2Oz2Y6677T0DA2Qc845h6eeeorCwkKKi4tZsGABPp+Pk08+eaCbNmjs/8Har7W1ldraWqxWK8nJyZx11lm88cYbZGRkkJqayquvvkpCQgITJkwAwuu4VFRU8Mwzz3DVVVcRDAaZO3cukyZNIjExcaDe1lFnzpw5LFu2jJtvvpmYmJhIj6bZbCY6Ohqz2cypp57KvHnzsFqtmM1m5s6dS2lpaeSX2pgxY8jOzubJJ5/k4osvxm638+qrr3L66afL1cD3efnll6moqCA5ORmv18uyZcvYunUrd9xxh9T4CIqJiYnMd9vPaDQSGxsb2S61PjLmzZvH+PHjSU5Opquri/nz56PT6Zg8efJR952WdYYG0MKFC3nnnXew2+3k5+dz2WWXUVJSMtDNGjS2bNly0PkUU6ZM4brrrossuvjRRx/hdrsZPnw4V1xxRa/FAp1OJ3PmzOm16OLll18uiy5+yYwZMw66/dprr42E9/2Lpy1fvpxgMHjQxdPa2tp47rnn2LJlC0ajkSlTpnDxxRfLInX7/O1vf6OyspKuri7MZjN5eXmcf/75kbOdpMY/nLvvvpv8/Pw+iy5Krb+fxx9/nG3bttHT00NcXBzDhw/nwgsvjAwFH011ljAkhBBCiCFN5gwJIYQQYkiTMCSEEEKIIU3CkBBCCCGGNAlDQgghhBjSJAwJIYQQYkiTMCSEEEKIIU3CkBBCCCGGNAlDQghxCJ999hkzZsygurp6oJsihPgByeU4hBAD5rPPPuPpp58+5OP333//j+p6fWvWrOGxxx7jhRdewGQy8fzzz7Nnzx7uvvvugW6aEEOahCEhxICbMWNGnwvAApFl+38sdu3aRW5ubuRyLzt37mT06NED3CohhIQhIcSAGzt2LEVFRQPdjB9cdXV15PqDfr+f2tpafvaznw1wq4QQEoaEEEe91tZWrr/+embNmoVOp2PBggV0d3dTXFzMFVdc0ecq5JWVlcyfP5/du3cTFRXFyJEjmTlzJtnZ2b326+zs5LXXXuOLL76gp6eHhIQEKioquOyyy9DrD/x6DAQC/POf/2TJkiX4/X7Ky8u55ppriIuL+8a2OxyOyO3q6mrGjx+Pw+GgurqaUChEWloaDocDo9GI0Wj8npUSQnwXcqFWIcSA2T9n6M477yQvL6/XY4qiEBsbCxwIQ7m5uXg8Hk477TQCgQALFixAp9Px6KOPRq50vWnTJh566CFSU1OZOnUqfr+f999/H1VVefjhhyPDcZ2dndx222243W6mTp1KVlYWnZ2drFq1ivvvvx+LxRJpX0FBARaLhWOPPZbW1lYWLFjAxIkTuemmm77xPc6YMeOwanHBBRcc9r5CiCNLeoaEEAPuvvvu67PNYDDw0ksv9drW3NzME088QWJiIgAVFRXcfvvtvP3221xyySUA/Otf/8JqtfLAAw9gtVoBmDBhAjfffDPz58/n+uuvB+Dll1/Gbrfz4IMP9hqi++Uvf8lX/41otVqZPXs2iqIAoGka77//Pm63G7PZ/LXvbfbs2QCsWrWKNWvWcMMNNwDw0ksvkZCQwFlnnQVAWlraYVRKCPFDkDAkhBhwV1xxBRkZGb226XR9V/6YMGFCJAgBFBcXU1JSwoYNG7jkkkvo6uqitraW8847LxKEAPLy8igvL2fDhg0AqKrKmjVrGDdu3EHnKu0PPftNmzat17YRI0bw3nvv0dbW1qdH66vKy8sBWLRoEaNHj6a8vBxVVWlububMM8+MPC6EGDgShoQQA664uPiwJlB/NTDt37Zy5UoA2traAMjMzOyzX1ZWFhs3bsTr9eL1evF4PH3mGh1KcnJyr/sWiwUAl8v1tc9zOp2oqgrA1q1b+fnPf47D4aCuri7y+g6Hg+jo6MgZZkKI/idhSAghvsHBeqmAPsNpX3XLLbdEAhrAvHnzmDdvXuT+rbfeCsCUKVO47rrrjkBLhRDfhYQhIcSg0dTUdNBtKSkpAJH/NzY29tmvsbGR2NhYTCYT0dHRxMTEUFdX94O294YbbsDv97NmzRpWrlzJjTfeCMCrr75KbGwsZ599NkCvoT8hRP+Ty3EIIQaNNWvW0NnZGblfVVXFrl27qKioACAhIYH8/HwWL17cawirrq6OjRs3MnbsWCDc0zNhwgTWrVt30EttHKmTbIcPH055eTkej4fS0lLKy8spLy+nvb2dcePGRe5/9ZR/IUT/kp4hIcSA27BhAw0NDX22Dxs2rNdZVunp6dx55529Tq2PjY3l/PPPj+wza9YsHnroIWbPns0pp5yC3+9n4cKFmM3mXqeuz5w5k02bNnH33XczdepUsrOz6erqYtWqVdx7772ReUFHwo4dO5g2bRoALS0t2O12hg0bdsSOL4T4fiQMCSEG3Pz58w+6/dprr+0Vhk466SR0Oh3vvfceDoeD4uJiLr/8chISEiL7lJeXc/vttzN//nzmz58fWXTx4osv7nXJj8TERB588EFeffVVli1bhsfjITExkYqKiiO6+KHdbqelpSUSfnbu3ElMTAw5OTlH7DWEEN+PLLoohDjqfXkF6vPOO2+gmyOE+JGROUNCCCGEGNIkDAkhhBBiSJMwJIQQQoghTeYMCSGEEGJIk54hIYQQQgxpEoaEEEIIMaRJGBJCCCHEkCZhSAghhBBDmoQhIYQQQgxpEoaEEEIIMaRJGBJCCCHEkCZhSAghhBBDmoQhIYQQQgxp/x9n+kf9uG3FFQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Muestro gráfica de accuracy y losses\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, 500), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, 500), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, 500), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, 500), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "21f70115-2462-4c11-b93a-e90fe1aafd70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "145/145 [==============================] - 0s 434us/step\n",
      "Predicciones:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_click</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>studied_credits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>-1.023614</td>\n",
       "      <td>0.928989</td>\n",
       "      <td>1.113127</td>\n",
       "      <td>0.236378</td>\n",
       "      <td>1.549062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sum_click    gender    region  highest_education  studied_credits\n",
       "2935  -1.023614  0.928989  1.113127           0.236378         1.549062"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.3901169e-01 1.5507549e-01 6.7816421e-02 2.2091545e-01 3.8393565e-02\n",
      " 9.5266990e-02 1.9225590e-05]\n",
      "Real\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2935</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3      4      5      6      7\n",
       "2935  True  False  False  False  False  False  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(type(X_training))\n",
    "# Hacer predicciones\n",
    "predicciones = model.predict(X_test)\n",
    "print(\"Predicciones:\")\n",
    "display(X_training.head(1))\n",
    "print(predicciones[0])\n",
    "print(\"Real\")\n",
    "display(y_training_oh.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "309dd054-3a61-40e8-8e44-a282daf52316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK:  2120\n",
      "NOK:  2492\n",
      "OK 2:  899\n",
      "NOK 2:  1593\n",
      "OK 3:  687\n",
      "NOK 3:  906\n",
      "OK 4:  448\n",
      "NOK 4:  458\n",
      "OK 5:  333\n",
      "NOK 5:  125\n",
      "OK 6:  98\n",
      "NOK 6:  27\n",
      "OK 7:  27\n",
      "NOK 7:  0\n",
      "1 45.96704249783174\n",
      "2 65.45967042497833\n",
      "3 80.35559410234173\n",
      "4 90.06938421509106\n",
      "5 97.2896790980052\n",
      "6 99.41457068516912\n",
      "7 100.0\n"
     ]
    }
   ],
   "source": [
    "#print(np.argmax(predicciones[0]))\n",
    "results=np.array([])\n",
    "x=0\n",
    "ok=0\n",
    "ok2=0\n",
    "ok3=0\n",
    "ok4=0\n",
    "ok5=0\n",
    "ok6=0\n",
    "ok7=0\n",
    "nok=0\n",
    "nok2=0\n",
    "nok3=0\n",
    "nok4=0\n",
    "nok5=0\n",
    "nok6=0\n",
    "nok7=0\n",
    "\n",
    "for i in predicciones:\n",
    "    results = np.append(results, np.argmax(i)+1)\n",
    "    if results[x] == y_test.iloc[x]:\n",
    "        ok=ok+1\n",
    "    else:\n",
    "        nok=nok+1\n",
    "        i[np.argmax(i)] = 0\n",
    "        seg = np.argmax(i)+1\n",
    "        if seg == y_test.iloc[x]:\n",
    "            ok2=ok2+1\n",
    "        else:\n",
    "            nok2 = nok2 + 1\n",
    "            i[np.argmax(i)] = 0\n",
    "            ter = np.argmax(i)+1\n",
    "            if ter == y_test.iloc[x]:\n",
    "                ok3=ok3+1\n",
    "            else:\n",
    "                nok3 = nok3 + 1\n",
    "                i[np.argmax(i)] = 0\n",
    "                cua = np.argmax(i)+1\n",
    "                if cua == y_test.iloc[x]:\n",
    "                    ok4=ok4+1\n",
    "                else:\n",
    "                    nok4 = nok4 + 1\n",
    "                    i[np.argmax(i)] = 0\n",
    "                    qui = np.argmax(i)+1\n",
    "                    if qui == y_test.iloc[x]:\n",
    "                        ok5=ok5+1\n",
    "                    else:\n",
    "                        nok5 = nok5 + 1\n",
    "                        i[np.argmax(i)] = 0\n",
    "                        sext = np.argmax(i)+1\n",
    "                        if sext == y_test.iloc[x]:\n",
    "                            ok6=ok6+1\n",
    "                        else:\n",
    "                            nok6 = nok6 + 1\n",
    "                            i[np.argmax(i)] = 0\n",
    "                            sie = np.argmax(i)+1\n",
    "                            if sie == y_test.iloc[x]:\n",
    "                                ok7=ok7+1\n",
    "                            else:\n",
    "                                nok7 = nok7 + 1\n",
    "    x=x+1\n",
    "\n",
    "\n",
    "print(\"OK: \", ok)\n",
    "print(\"NOK: \", nok)\n",
    "print(\"OK 2: \", ok2)\n",
    "print(\"NOK 2: \", nok2)\n",
    "print(\"OK 3: \", ok3)\n",
    "print(\"NOK 3: \", nok3)\n",
    "print(\"OK 4: \", ok4)\n",
    "print(\"NOK 4: \", nok4)\n",
    "print(\"OK 5: \", ok5)\n",
    "print(\"NOK 5: \", nok5)\n",
    "print(\"OK 6: \", ok6)\n",
    "print(\"NOK 6: \", nok6)\n",
    "print(\"OK 7: \", ok7)\n",
    "print(\"NOK 7: \", nok7)\n",
    "print(\"1\", (ok)/(4612)*100)\n",
    "print(\"2\", (ok+ok2)/(4612)*100)\n",
    "print(\"3\", (ok+ok2+ok3)/(4612)*100)\n",
    "print(\"4\", (ok+ok2+ok3+ok4)/(4612)*100)\n",
    "print(\"5\", (ok+ok2+ok3+ok4+ok5)/(4612)*100)\n",
    "print(\"6\", (ok+ok2+ok3+ok4+ok5+ok6)/(4612)*100)\n",
    "print(\"7\", (ok+ok2+ok3+ok4+ok5+ok6+ok7)/(4612)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "fc96dbfb-f8d5-40b0-9106-3524696a77db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18446, 7)\n"
     ]
    }
   ],
   "source": [
    "# Se carga el resultado de las predicciones del algoritmo DT para comparar con el resultado de la red neuronal\n",
    "results_DT = np.loadtxt('res/results_DT.csv', delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "e936afdb-6d78-4b23-9a92-8c74c488538b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función que permite dejar en 1 las 3 probabilidades más altas en la predicción\n",
    "\n",
    "def convertir_mayores_a_uno(array):\n",
    "    # Crear una copia del array para no modificar el original\n",
    "    result = np.zeros_like(array)\n",
    "    \n",
    "    # Procesar cada registro individualmente\n",
    "    for i in range(array.shape[0]):\n",
    "        # Obtener los índices de los 3 valores mayores\n",
    "        indices_mayores = np.argpartition(array[i], -3)[-3:]\n",
    "        # Asignar el valor 1 a los 3 mayores valores\n",
    "        result[i, indices_mayores] = 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "02b113b2-5022-4782-972e-0c193c87be87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.3694103e-01 3.2264313e-03 5.9053143e-03 4.6591751e-02 4.6212552e-03\n",
      " 2.6919539e-03 2.2242353e-05]\n",
      "[1. 0. 1. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "predicciones_may=convertir_mayores_a_uno(predicciones)\n",
    "print(predicciones[0])\n",
    "print(predicciones_may[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "36c2d85a-1c9a-4b6c-ae57-2b7eb9243856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Función que permite comparar los dos arrays de resultados de los dos modelos, entregando el porcentaje de coincidencia\n",
    "\n",
    "def porcentaje_exito(array1, array2):\n",
    "    # Asegurarse de que ambos arrays tengan la misma forma\n",
    "    assert array1.shape == array2.shape, \"Los arrays deben tener la misma forma\"\n",
    "    \n",
    "    # Crear una máscara booleana donde los valores de ambos arrays sean 1 en la misma posición\n",
    "    coincidencias = (array1 == 1) & (array2 == 1)\n",
    "    \n",
    "    # Contar el número de coincidencias\n",
    "    num_coincidencias = np.sum(coincidencias)\n",
    "    \n",
    "    # Contar el número total de elementos en array1 que son 1\n",
    "    num_total_1s = np.sum(array1 == 1)\n",
    "    \n",
    "    # Calcular el porcentaje de éxito\n",
    "    if num_total_1s == 0:\n",
    "        return 0.0  # Evitar división por cero si no hay 1s en array1\n",
    "    porcentaje = (num_coincidencias / num_total_1s) * 100\n",
    "    \n",
    "    return porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "475b226a-9422-41cf-98f6-ca4c2d9f94e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de casos en los que coincide la sugerencia entre modelos: 90.57%\n"
     ]
    }
   ],
   "source": [
    "# Calcular el porcentaje de éxito\n",
    "porcentaje = porcentaje_exito(results_DT, predicciones_may)\n",
    "\n",
    "print(f\"Porcentaje de casos en los que coincide la sugerencia entre modelos: {porcentaje:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "035993e6-e421-4d48-a228-156ccdc580b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dvelasquez/Library/Python/3.9/lib/python/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo entrenado\n",
    "model.save('modelo_cursos.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "67d3d739-ad5a-4661-9668-369fccf8c5b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BBB\n"
     ]
    }
   ],
   "source": [
    "# Listado de valores\n",
    "val_courses = ['AAA', 'BBB', 'CCC', 'DDD', 'EEE', 'FFF', 'GGG']\n",
    "\n",
    "# Crear un diccionario con números como índices y los elementos del listado como valores\n",
    "dicc_courses = {i + 1: valor for i, valor in enumerate(val_courses)}\n",
    "\n",
    "# Imprimir el diccionario resultante\n",
    "print(dicc_courses[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6c447a7f-34a2-4cf4-b291-d8cb1ab938a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'forumng', 2: 'oucontent', 3: 'subpage', 4: 'url', 5: 'resource', 6: 'dataplus', 7: 'glossary', 8: 'oucollaborate', 9: 'ouwiki', 10: 'folder', 11: 'dualpane', 12: 'ouelluminate', 13: 'htmlactivity'}\n",
      "subpage\n"
     ]
    }
   ],
   "source": [
    "# Listado de valores\n",
    "val_act = ['forumng', 'oucontent', 'subpage', 'url', 'resource',\n",
    "           'dataplus', 'glossary', 'oucollaborate', 'ouwiki',\n",
    "           'folder', 'dualpane', 'ouelluminate', 'htmlactivity']\n",
    "\n",
    "# Crear un diccionario con índices que comienzan en 1 y los elementos del listado como valores\n",
    "dicc_act = {i + 1: valor for i, valor in enumerate(val_act)}\n",
    "\n",
    "# Imprimir el diccionario resultante\n",
    "print(dicc_act)\n",
    "print(dicc_act[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "cba0a78e-9c1a-4ff6-ace5-a715cfa3479c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Cargar el modelo entrenado\n",
    "modelo_courses = tf.keras.models.load_model('modelo_cursos.h5')\n",
    "modelo_act = tf.keras.models.load_model('modelo_actividades.h5')\n",
    "\n",
    "# Listado de valores\n",
    "val_courses = ['AAA', 'BBB', 'CCC', 'DDD', 'EEE', 'FFF', 'GGG']\n",
    "val_act = ['forumng', 'oucontent', 'subpage', 'url', 'resource',\n",
    "           'dataplus', 'glossary', 'oucollaborate', 'ouwiki',\n",
    "           'folder', 'dualpane', 'ouelluminate', 'htmlactivity']\n",
    "\n",
    "# Creación de los diccionarios para los cursos y las actividades y recursos\n",
    "dicc_courses = {i + 1: valor for i, valor in enumerate(val_courses)}\n",
    "dicc_act = {i + 1: valor for i, valor in enumerate(val_act)}\n",
    "\n",
    "\n",
    "def predicc_courses(datos_per):\n",
    "    courses = usar_modelo_cursos(datos_per)\n",
    "    resp_courses = \"Te recomendamos estos cursos: \" + dicc_courses[np.argsort(-courses)[0][0]+1] + \", \" + dicc_courses[np.argsort(-courses)[0][1]+1] + \", \" + dicc_courses[np.argsort(-courses)[0][2]+1] \n",
    "    return resp_courses\n",
    "\n",
    "def usar_modelo_cursos(datos):\n",
    "    # Utilizar el modelo para hacer predicciones de los cursos\n",
    "    predicciones = modelo_courses.predict(datos)\n",
    "    print(predicciones)\n",
    "    return predicciones\n",
    "\n",
    "def predicc_act(datos_per):\n",
    "    activity = usar_modelo_act(datos_per)\n",
    "    resp_courses = \"Te recomendamos estas actividades: \" +  dicc_act[np.argsort(-activity)[0][0]+1] + \", \" + dicc_act[np.argsort(-activity)[0][1]+1] + \", \" + dicc_act[np.argsort(-activity)[0][2]+1] \n",
    "    return resp_courses\n",
    "\n",
    "def usar_modelo_act(datos):\n",
    "    # Utilizar el modelo para hacer predicciones de las actividades y recursos\n",
    "    predicciones = modelo_act.predict(datos)\n",
    "    print(predicciones)\n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "a2855a65-dc0c-4411-aaaf-2bb6177c820f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92724127 1.62788966 0.19426558 0.46224852]]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "[[0.00063608 0.00193326 0.23870032 0.2123628  0.1725504  0.38542804\n",
      "  0.00182835]]\n",
      "Te recomendamos estos cursos: FFF, CCC, DDD\n",
      "[[0.75420397 1.62855384 0.12115486 0.37463477]]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[0.2907376  0.28059638 0.09525326 0.25270396 0.00179308 0.04161149\n",
      "  0.00990828 0.00474818 0.00219371 0.01753383 0.00561457 0.0017632\n",
      "  0.00257307]]\n",
      "Te recomendamos estas actividades: forumng, oucontent, url\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dvelasquez/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/dvelasquez/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "# Cargar los StandardScaler entrenados desde el archivo\n",
    "scaler_courses = load('scaler_courses.joblib')\n",
    "scaler_activity = load('scaler_activity.joblib')\n",
    "\n",
    "# Cargar los SelectPercentile entrenados desde el archivo\n",
    "selector_courses = load('selector_courses.joblib')\n",
    "selector_activity = load('selector_activity.joblib')\n",
    "\n",
    "perfil = \"2,13,3,1,90\"\n",
    "datos_per = perfil.split(',')\n",
    "#print(type(datos_per))\n",
    "\n",
    "# 2      13                  3         1               90\n",
    "#[ 0.92724127  1.62788966  0.19426558 -0.68792434  0.46224852]\n",
    "\n",
    "datos_perfil = np.array(datos_per)\n",
    "datos_perfil_fl = datos_perfil.astype(float)\n",
    "\n",
    "datos_perfil_fl=datos_perfil_fl.reshape(1, -1)\n",
    "\n",
    "#Se realiza la estandarización de los datos\n",
    "datos_perfil_fl_st_co = scaler_courses.transform(datos_perfil_fl)\n",
    "datos_perfil_fl_st_ac = scaler_activity.transform(datos_perfil_fl)\n",
    "\n",
    "#Se elimina el dato que no es utilizado para la predicción\n",
    "#datos_perfil_fl_st= np.delete(datos_perfil_fl_st, 3)\n",
    "datos_perfil_fl_st_sel_co = selector_courses.transform(datos_perfil_fl_st_co)\n",
    "\n",
    "datos_perfil_re=datos_perfil_fl_st_sel_co.reshape(1, 4)\n",
    "print(datos_perfil_re)\n",
    "\n",
    "# Llamar a la función predicc_courses() con los datos de perfil para obtener una predicción de los cursos\n",
    "resultado_cursos = predicc_courses(datos_perfil_re)\n",
    "print(resultado_cursos)\n",
    "\n",
    "#datos_perfil_act= np.delete(datos_perfil_re, 1)\n",
    "datos_perfil_fl_st_sel_ac = selector_courses.transform(datos_perfil_fl_st_ac)\n",
    "datos_perfil_act_re=datos_perfil_fl_st_sel_ac.reshape(1, 4)\n",
    "print(datos_perfil_act_re)\n",
    "\n",
    "resultado_act = predicc_act(datos_perfil_act_re)\n",
    "print(resultado_act)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
